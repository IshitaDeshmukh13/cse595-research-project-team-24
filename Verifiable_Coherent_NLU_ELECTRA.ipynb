{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL9AU7zTgP9n"
      },
      "source": [
        "### **Toward Consistent, Verifiable, and Coherent Commonsense Reasoning in Large LMs**\n",
        "\n",
        "This notebook provides source code for our two papers in Findings of EMNLP 2021:\n",
        "\n",
        "\n",
        "1.  Shane Storks, Qiaozi Gao, Yichi Zhang, and Joyce Y. Chai (2021). *Tiered Reasoning for Intuitive Physics: Toward Verifiable Commonsense Language Understanding.* Findings of EMNLP 2021.\n",
        "2.   Shane Storks and Joyce Y. Chai (2021). *Beyond the Tip of the Iceberg: Assessing Coherence of Text Classifiers.* Findings of EMNLP 2021.\n",
        "\n",
        "*If you have any questions or problems, please open an issue on our [GitHub repo](https://github.com/sled-group/Verifiable-Coherent-NLU) or email Shane Storks.*\n",
        "\n",
        "***First, configure the execution mode by selecting a few settings (expand cell if needed):***\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct4cd2_TFYDk"
      },
      "source": [
        "   0. (Colab only) Insert the path in your Google Drive to the folder where this notebook is located."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vq9-dXJXFWh3"
      },
      "outputs": [],
      "source": [
        "DRIVE_PATH = 'drive/My Drive/TRIP'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YG5A74-81r0I",
        "outputId": "2fa265d4-3611-4dfc-a1ae-d951aaa49149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxzL0hhHAHzN"
      },
      "source": [
        "1.   Model type (choose from BERT large, RoBERTa large, RoBERTa large + MNLI, DeBERTa base, and DeBERTa large).\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFNe6vlTaHsP"
      },
      "outputs": [],
      "source": [
        "# mode = 'bert' # BERT large\n",
        "# mode = 'roberta' # RoBERTa large\n",
        "# mode = 'roberta_mnli' # RoBERTa large pre-trained on MNLI\n",
        "# mode = 'deberta' # DeBERTa base for training on TRIP\n",
        "# mode = 'deberta_large' # DeBERTa large for training on CE and ART\n",
        "#mode = 'albert'\n",
        "#mode = 'bart'\n",
        "mode = 'electra'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbJ-XeY1aCpD"
      },
      "source": [
        "2.   Name of the task we want to train or evaluate on. Set `debug` to `True` to run quick training/evaluation jobs on only a small amount of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAQGu6JMa-o6"
      },
      "outputs": [],
      "source": [
        "task_name = 'trip'\n",
        "# task_name = 'ce'\n",
        "# task_name = 'art'\n",
        "\n",
        "debug = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoWKXfQBd435"
      },
      "source": [
        "3.   (If training models) Training batch size, learning rate, and maximum number of epochs. Settings for results in the paper are provided as examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyFFcZtkeKwT"
      },
      "outputs": [],
      "source": [
        "config_batch_size = 1\n",
        "config_lr = 1e-5 # Selected learning rate for best RoBERTa-based model in TRIP paper\n",
        "config_epochs = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH9a70CTaGpG"
      },
      "source": [
        "4.   (For training TRIP models only) Configure the loss weighting scheme for training models here. We provide the 4 modes from the paper as examples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvQEiNBSACak"
      },
      "outputs": [],
      "source": [
        "# Loss weights for (attributes, preconditions, effects, conflicts, story choices)\n",
        "if task_name != 'trip':\n",
        "  print(\"We do not need a loss weighting scheme for %s dataset. Ignoring this cell.\" % task_name)\n",
        "#loss_weights = [0.0, 0.4, 0.4, 0.1, 0.1] # \"All losses\"\n",
        "#loss_weights = [0.0, 0.4, 0.4, 0.2, 0.0] # \"Omit story choice loss\"\n",
        "#loss_weights = [0.0, 0.4, 0.4, 0.0, 0.2] # \"Omit conflict detection loss\"\n",
        "loss_weights = [0.0, 0.0, 0.0, 0.5, 0.5] # \"Omit state classification losses\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmpchQTIg3HZ"
      },
      "source": [
        "   5. (If evaluating models) Provide the name of the pre-trained model directory here. This should be the name of a directory within the *saved_models* directory, which should be located where this notebook is. Names of provided pre-trained model directories are listed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8tH7UMZhI1N"
      },
      "outputs": [],
      "source": [
        "# TRIP, all losses\n",
        "# eval_model_dir = 'bert-large-uncased_cloze_1_5e-06_4_0.0-0.4-0.4-0.1-0.1_tiered_pipeline_ablate_attributes_states-logits'\n",
        "# eval_model_dir = 'roberta-large_cloze_1_1e-05_7_0.0-0.4-0.4-0.1-0.1_tiered_pipeline_ablate_attributes_states-logits'\n",
        "# eval_model_dir = 'microsoft-deberta-base_cloze_1_5e-06_5_0.0-0.4-0.4-0.1-0.1_tiered_pipeline_ablate_attributes_states-logits'\n",
        "\n",
        "# TRIP, no story classification loss\n",
        "# eval_model_dir = 'bert-large-uncased_cloze_1_5e-05_8_0.0-0.4-0.4-0.2-0.0_tiered_pipeline_ablate_attributes_states-logits'\n",
        "eval_model_dir =  None #'roberta-large_cloze_1_1e-05_5_0.0-0.4-0.4-0.2-0.0_tiered_pipeline_lc_ablate_attributes_states-logits' # Best model trained in the TRIP paper\n",
        "# eval_model_dir = 'microsoft-deberta-base_cloze_1_5e-05_5_0.0-0.4-0.4-0.2-0.0_tiered_pipeline_ablate_attributes_states-logits'\n",
        "\n",
        "# TRIP, no conflict detection loss\n",
        "# eval_model_dir = 'bert-large-uncased_cloze_1_1e-06_1_0.0-0.4-0.4-0.0-0.2_tiered_pipeline_ablate_attributes_states-logits'\n",
        "# eval_model_dir = 'roberta-large_cloze_1_5e-06_8_0.0-0.4-0.4-0.0-0.2_tiered_pipeline_ablate_attributes_states-logits'\n",
        "# eval_model_dir = 'microsoft-deberta-base_cloze_1_1e-06_3_0.0-0.4-0.4-0.0-0.2_tiered_pipeline_ablate_attributes_states-logits'\n",
        "\n",
        "# TRIP, no physical state classification loss\n",
        "# eval_model_dir = 'bert-large-uncased_cloze_1_1e-05_3_0.0-0.0-0.0-0.5-0.5_tiered_pipeline_ablate_attributes_states-logits'\n",
        "# eval_model_dir = 'roberta-large_cloze_1_1e-06_7_0.0-0.0-0.0-0.5-0.5_tiered_pipeline_ablate_attributes_states-logits'\n",
        "# eval_model_dir = 'microsoft-deberta-base_cloze_1_5e-06_9_0.0-0.0-0.0-0.5-0.5_tiered_pipeline_ablate_attributes_states-logits'\n",
        "\n",
        "# CE\n",
        "# eval_model_dir = 'bert-large-uncased_ConvEnt_32_7.5e-06_7_xval'\n",
        "# eval_model_dir = 'roberta-large_ConvEnt_32_7.5e-06_9_xval'\n",
        "# eval_model_dir = 'roberta-large-mnli_ConvEnt_32_7.5e-06_7_xval'\n",
        "# eval_model_dir = 'microsoft-deberta-large_ConvEnt_16_1e-05_9_xval'\n",
        "\n",
        "# ART\n",
        "# eval_model_dir = 'bert-large-uncased_art_64_5e-06_8'\n",
        "# eval_model_dir = 'roberta-large_art_64_2.5e-06_4'\n",
        "# eval_model_dir = 'DeBERTa-deberta-large_art_32_1e-06_8'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GA5VS3Sfgfz"
      },
      "source": [
        "**For more configuration options, scroll down to the Train Models > Configure Hyperparameters cell for the task you're working on.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqvj34KhLL0k"
      },
      "source": [
        "# Setup\n",
        "Run this block every time when starting up the notebook. It will get Colab ready, preprocess the data, and load model packages and classes we'll need later. May take several minutes to run for the first time.\n",
        "\n",
        "**If you get a `ModuleNotFoundError` for the `www` code base, try the following:**\n",
        "\n",
        "\n",
        "1.   Ensure the DRIVE_PATH is set properly above.\n",
        "2.   (Colab only) Verify that this notebook has access to your Google Drive (click the folder icon on the left and then the Google Drive icon).\n",
        "2.   Try to restart the runtime and refresh your browser window.\n",
        "2.   (Colab only) If the problem persists, revoke access to Google Drive and re-enable it.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xm7qzKnAnbU9"
      },
      "source": [
        "## Colab Setup\n",
        "\n",
        "Enable auto reloading of code libraries from Google Drive, set up connection to Google Drive, and import some packages. 🔌"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8h8hUVaqySd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c62387f0-aafb-4514-bbac-3d3f549ce4cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3dNQeNNnkHD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import sys\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import spacy\n",
        "\n",
        "sys.path.append(DRIVE_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jsonlines==2.0.0"
      ],
      "metadata": {
        "id": "yDM6RrxZlVnu",
        "outputId": "7f9d189b-d881-4e7a-a9df-a3a7c899af2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jsonlines==2.0.0 in /usr/local/lib/python3.10/dist-packages (2.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQLB_Y-wSsfk"
      },
      "source": [
        "## Model Setup\n",
        "\n",
        "Next, we'll load up the transformer model, tokenizer, etc. ⏳"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoY37xIF-oP7"
      },
      "source": [
        "### Install HuggingFace transformers and other dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rp3vUVjT9I4",
        "outputId": "60c99655-88ce-4972-b8f7-3c7a8fbfe33a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip3 install torch torchvision torchaudio\n",
        "# !pip install deberta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4LFuLhzAa2j"
      },
      "source": [
        "### Get Model Components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZhhgV9c__TU"
      },
      "source": [
        "Specify which model parameters from transformers we want to use:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uA6XunCb_gd9"
      },
      "outputs": [],
      "source": [
        "if task_name in ['trip', 'ce']:\n",
        "  multiple_choice = False\n",
        "elif task_name == 'art':\n",
        "  multiple_choice = True\n",
        "else:\n",
        "  raise ValueError(\"Task name should be set to 'trip', 'ce', or 'art' in the first cell of the notebook!\")\n",
        "\n",
        "if mode == 'bert':\n",
        "  model_name = 'bert-large-uncased'\n",
        "elif mode == 'roberta':\n",
        "  model_name = 'roberta-large'\n",
        "elif mode == 'roberta_mnli':\n",
        "  model_name = 'roberta-large-mnli'\n",
        "elif mode == 'deberta':\n",
        "  model_name = 'microsoft/deberta-base'\n",
        "elif mode == 'deberta_large':\n",
        "  model_name = 'microsoft/deberta-large'\n",
        "elif mode == 'albert':\n",
        "  model_name = 'albert/albert-base-v1'\n",
        "elif mode == 'bart':\n",
        "  model_name = 'facebook/bart-large-cnn'\n",
        "elif mode == 'electra':\n",
        "  model_name = 'google/electra-base-discriminator'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgFIl1MJ-185"
      },
      "source": [
        "Load the tokenizer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etkxf75f-9Gj"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, RobertaTokenizer, DebertaTokenizer, AlbertTokenizer, T5Tokenizer, GPT2Tokenizer, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# from DeBERTa import deberta\n",
        "if mode in ['bert']:\n",
        "  tokenizer_class = BertTokenizer\n",
        "elif mode in ['roberta', 'roberta_mnli']:\n",
        "  tokenizer_class = RobertaTokenizer\n",
        "elif mode in ['deberta', 'deberta_large']:\n",
        "  tokenizer_class = DebertaTokenizer\n",
        "elif mode in ['albert']:\n",
        "  tokenizer_class = AlbertTokenizer\n",
        "elif mode in ['bart']:\n",
        "  tokenizer_class = AutoTokenizer\n",
        "elif mode in ['electra']:\n",
        "  tokenizer_class = AutoTokenizer\n",
        "\n",
        "tokenizer = tokenizer_class.from_pretrained(model_name,\n",
        "                                                do_lower_case = False,\n",
        "                                                cache_dir=os.path.join(DRIVE_PATH, 'cache'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0iYZG6bBGIf"
      },
      "source": [
        "Load the model and optimizer:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import www"
      ],
      "metadata": {
        "id": "jA_O_mE1g_Mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PxFghcDBPm_"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForSequenceClassification, RobertaForSequenceClassification, DebertaForSequenceClassification, AlbertForSequenceClassification, AdamW, BartForSequenceClassification, ElectraForSequenceClassification\n",
        "from transformers import BertForMultipleChoice, RobertaForMultipleChoice, AlbertForMultipleChoice, DebertaModel\n",
        "from transformers import BertModel, RobertaModel, AlbertModel, DebertaModel, T5Model, T5EncoderModel, GPT2Model, BartModel, ElectraModel\n",
        "from transformers import RobertaForMaskedLM\n",
        "from transformers import BertConfig, RobertaConfig, DebertaConfig, AlbertConfig, T5Config, GPT2Config, BartConfig, ElectraConfig\n",
        "from www.model.transformers_ext import DebertaForMultipleChoice\n",
        "from torch.optim import Adam\n",
        "if not multiple_choice:\n",
        "  if mode == 'bert':\n",
        "    model_class = BertForSequenceClassification\n",
        "    config_class = BertConfig\n",
        "    emb_class = BertModel\n",
        "  elif mode in ['roberta', 'roberta_mnli']:\n",
        "    model_class = RobertaForSequenceClassification\n",
        "    config_class = RobertaConfig\n",
        "    emb_class = RobertaModel\n",
        "    lm_class = RobertaForMaskedLM\n",
        "  elif mode in ['deberta', 'deberta_large']:\n",
        "    model_class = DebertaForSequenceClassification\n",
        "    config_class = DebertaConfig\n",
        "    emb_class = DebertaModel\n",
        "  elif mode in ['albert']:\n",
        "    model_class = AlbertForSequenceClassification\n",
        "    config_class = AlbertConfig\n",
        "    emb_class = AlbertModel\n",
        "  elif mode in ['bart']:\n",
        "    model_class = BartForSequenceClassification\n",
        "    config_class = BartConfig\n",
        "    emb_class = BartModel\n",
        "  elif mode in ['electra']:\n",
        "    mode_class = ElectraForSequenceClassification\n",
        "    config_class = ElectraConfig\n",
        "    emb_class = ElectraModel\n",
        "\n",
        "else:\n",
        "  if mode == 'bert':\n",
        "    model_class = BertForMultipleChoice\n",
        "    config_class = BertConfig\n",
        "    emb_class = BertModel\n",
        "  elif mode in ['roberta', 'roberta_mnli']:\n",
        "    model_class = RobertaForMultipleChoice\n",
        "    config_class = RobertaConfig\n",
        "    emb_class = RobertaModel\n",
        "    lm_class = RobertaForMaskedLM\n",
        "  elif mode in ['deberta', 'deberta_large']:\n",
        "    model_class = DebertaForMultipleChoice\n",
        "    config_class = DebertaConfig\n",
        "    emb_class = DebertaModel\n",
        "  elif mode in ['bart']:\n",
        "    model_class = BartForSequenceClassification\n",
        "    config_class = BartConfig\n",
        "    emb_class = BartModel\n",
        "  elif mode in ['electra']:\n",
        "    mode_class = ElectraForSequenceClassification\n",
        "    config_class = ElectraConfig\n",
        "    emb_class = ElectraModel\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzFnAVtuUmpQ"
      },
      "source": [
        "## Data Setup\n",
        "\n",
        "Preprocess the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKY0hTEgnQgB"
      },
      "source": [
        "### Preprocessing\n",
        "\n",
        "Construct the dataset from the .txt files collected from AMT. Save a backup copy in Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aE-LOkJ4nWuu",
        "outputId": "e13b678a-71bc-4eda-d027-0189b7ae474a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed examples:\n",
            "{\n",
            "  story_id: \n",
            "    13,\n",
            "  worker_id: \n",
            "    A32W24TWSWXW,\n",
            "  type: \n",
            "    None,\n",
            "  idx: \n",
            "    None,\n",
            "  aug: \n",
            "    False,\n",
            "  actor: \n",
            "    John,\n",
            "  location: \n",
            "    kitchen,\n",
            "  objects: \n",
            "    cabinet, counter, knife, pan, potato, pizza,\n",
            "  sentences: \n",
            "    [\n",
            "      John was getting the snacks ready for the party.\n",
            "      John opened the cabinet, took out a pan and put it on the counter.\n",
            "      John opened the fridge and got out the pizza.\n",
            "      John put the pizza on the pan and put them into the oven.\n",
            "      John took a knife and cut the hot pizza in eight slices.\n",
            "    ],\n",
            "  length: \n",
            "    5,\n",
            "  example_id: \n",
            "    13,\n",
            "  plausible: \n",
            "    True,\n",
            "  breakpoint: \n",
            "    -1,\n",
            "  confl_sents: \n",
            "    [],\n",
            "  confl_pairs: \n",
            "    [],\n",
            "  states: \n",
            "    [\n",
            "      {'h_location': [['John', 0]], 'conscious': [['John', 2]], 'wearing': [['John', 0]], 'h_wet': [['John', 0]], 'hygiene': [['John', 0]], 'location': [['snacks', 0], ['party', 0]], 'exist': [['snacks', 4], ['party', 2]], 'clean': [['snacks', 0], ['party', 0]], 'power': [['snacks', 0], ['party', 0]], 'functional': [['snacks', 2], ['party', 2]], 'pieces': [['snacks', 0], ['party', 0]], 'wet': [['snacks', 0], ['party', 0]], 'open': [['snacks', 0], ['party', 0]], 'temperature': [['snacks', 0], ['party', 0]], 'solid': [['snacks', 0], ['party', 0]], 'contain': [['snacks', 0], ['party', 0]], 'running': [['snacks', 0], ['party', 0]], 'moveable': [['snacks', 2], ['party', 2]], 'mixed': [['snacks', 0], ['party', 0]], 'edible': [['snacks', 0], ['party', 0]]}\n",
            "      {'h_location': [['John', 0]], 'conscious': [['John', 2]], 'wearing': [['John', 0]], 'h_wet': [['John', 0]], 'hygiene': [['John', 0]], 'location': [['counter', 0], ['pan', 7], ['cabinet', 0]], 'exist': [['counter', 2], ['pan', 2], ['cabinet', 2]], 'clean': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'power': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'functional': [['counter', 2], ['pan', 2], ['cabinet', 2]], 'pieces': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'wet': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'open': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'temperature': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'solid': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'contain': [['counter', 6], ['pan', 0], ['cabinet', 8]], 'running': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'moveable': [['counter', 0], ['pan', 2], ['cabinet', 0]], 'mixed': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'edible': [['counter', 0], ['pan', 0], ['cabinet', 0]]}\n",
            "      {'h_location': [['John', 0]], 'conscious': [['John', 2]], 'wearing': [['John', 0]], 'h_wet': [['John', 0]], 'hygiene': [['John', 0]], 'location': [['fridge', 0], ['pizza', 7]], 'exist': [['fridge', 2], ['pizza', 2]], 'clean': [['fridge', 0], ['pizza', 0]], 'power': [['fridge', 2], ['pizza', 0]], 'functional': [['fridge', 2], ['pizza', 2]], 'pieces': [['fridge', 0], ['pizza', 0]], 'wet': [['fridge', 0], ['pizza', 0]], 'open': [['fridge', 4], ['pizza', 0]], 'temperature': [['fridge', 0], ['pizza', 1]], 'solid': [['fridge', 0], ['pizza', 0]], 'contain': [['fridge', 8], ['pizza', 0]], 'running': [['fridge', 2], ['pizza', 0]], 'moveable': [['fridge', 2], ['pizza', 2]], 'mixed': [['fridge', 0], ['pizza', 0]], 'edible': [['fridge', 0], ['pizza', 0]]}\n",
            "      {'h_location': [['John', 0]], 'conscious': [['John', 2]], 'wearing': [['John', 0]], 'h_wet': [['John', 0]], 'hygiene': [['John', 0]], 'location': [['oven', 0], ['pizza', 3], ['pan', 6]], 'exist': [['oven', 2], ['pizza', 2], ['pan', 2]], 'clean': [['oven', 0], ['pizza', 0], ['pan', 0]], 'power': [['oven', 2], ['pizza', 0], ['pan', 0]], 'functional': [['oven', 2], ['pizza', 2], ['pan', 2]], 'pieces': [['oven', 0], ['pizza', 0], ['pan', 0]], 'wet': [['oven', 0], ['pizza', 0], ['pan', 0]], 'open': [['oven', 8], ['pizza', 0], ['pan', 0]], 'temperature': [['oven', 2], ['pizza', 0], ['pan', 0]], 'solid': [['oven', 0], ['pizza', 0], ['pan', 0]], 'contain': [['oven', 6], ['pizza', 0], ['pan', 4]], 'running': [['oven', 0], ['pizza', 0], ['pan', 0]], 'moveable': [['oven', 0], ['pizza', 2], ['pan', 2]], 'mixed': [['oven', 0], ['pizza', 0], ['pan', 0]], 'edible': [['oven', 0], ['pizza', 0], ['pan', 0]]}\n",
            "      {'h_location': [['John', 0]], 'conscious': [['John', 2]], 'wearing': [['John', 0]], 'h_wet': [['John', 0]], 'hygiene': [['John', 0]], 'location': [['knife', 2], ['slices', 2], ['hot pizza', 0]], 'exist': [['knife', 2], ['slices', 2], ['hot pizza', 2]], 'clean': [['knife', 0], ['slices', 0], ['hot pizza', 0]], 'power': [['knife', 0], ['slices', 0], ['hot pizza', 0]], 'functional': [['knife', 2], ['slices', 2], ['hot pizza', 2]], 'pieces': [['knife', 0], ['slices', 0], ['hot pizza', 4]], 'wet': [['knife', 0], ['slices', 0], ['hot pizza', 0]], 'open': [['knife', 0], ['slices', 0], ['hot pizza', 0]], 'temperature': [['knife', 0], ['slices', 0], ['hot pizza', 2]], 'solid': [['knife', 0], ['slices', 0], ['hot pizza', 0]], 'contain': [['knife', 0], ['slices', 0], ['hot pizza', 0]], 'running': [['knife', 0], ['slices', 0], ['hot pizza', 0]], 'moveable': [['knife', 2], ['slices', 2], ['hot pizza', 2]], 'mixed': [['knife', 0], ['slices', 0], ['hot pizza', 0]], 'edible': [['knife', 0], ['slices', 0], ['hot pizza', 0]]}\n",
            "    ],\n",
            "}\n",
            "\n",
            "\n",
            "{\n",
            "  story_id: \n",
            "    13,\n",
            "  worker_id: \n",
            "    A32W24TWSWXW,\n",
            "  type: \n",
            "    cloze,\n",
            "  idx: \n",
            "    0,\n",
            "  aug: \n",
            "    False,\n",
            "  actor: \n",
            "    John,\n",
            "  location: \n",
            "    kitchen,\n",
            "  objects: \n",
            "    cabinet, counter, knife, pan, potato, pizza,\n",
            "  sentences: \n",
            "    [\n",
            "      John was getting the snacks ready for the party.\n",
            "      John opened the cabinet, took out a pan and put it on the counter.\n",
            "      John opened the fridge and got out the pizza.\n",
            "      John put the pizza on the pan and put them into the oven.\n",
            "      John called the pizza joint to deliver a pizza.\n",
            "    ],\n",
            "  length: \n",
            "    5,\n",
            "  example_id: \n",
            "    13-C0,\n",
            "  plausible: \n",
            "    False,\n",
            "  breakpoint: \n",
            "    4,\n",
            "  confl_sents: \n",
            "    [\n",
            "      2\n",
            "      3\n",
            "    ],\n",
            "  confl_pairs: \n",
            "    [\n",
            "      [2, 4]\n",
            "      [3, 4]\n",
            "    ],\n",
            "  states: \n",
            "    [\n",
            "      {'h_location': [['John', 0]], 'conscious': [['John', 2]], 'wearing': [['John', 0]], 'h_wet': [['John', 0]], 'hygiene': [['John', 0]], 'location': [['snacks', 0], ['party', 0]], 'exist': [['snacks', 4], ['party', 2]], 'clean': [['snacks', 0], ['party', 0]], 'power': [['snacks', 0], ['party', 0]], 'functional': [['snacks', 2], ['party', 2]], 'pieces': [['snacks', 0], ['party', 0]], 'wet': [['snacks', 0], ['party', 0]], 'open': [['snacks', 0], ['party', 0]], 'temperature': [['snacks', 0], ['party', 0]], 'solid': [['snacks', 0], ['party', 0]], 'contain': [['snacks', 0], ['party', 0]], 'running': [['snacks', 0], ['party', 0]], 'moveable': [['snacks', 2], ['party', 2]], 'mixed': [['snacks', 0], ['party', 0]], 'edible': [['snacks', 0], ['party', 0]]}\n",
            "      {'h_location': [['John', 0]], 'conscious': [['John', 2]], 'wearing': [['John', 0]], 'h_wet': [['John', 0]], 'hygiene': [['John', 0]], 'location': [['counter', 0], ['pan', 7], ['cabinet', 0]], 'exist': [['counter', 2], ['pan', 2], ['cabinet', 2]], 'clean': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'power': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'functional': [['counter', 2], ['pan', 2], ['cabinet', 2]], 'pieces': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'wet': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'open': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'temperature': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'solid': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'contain': [['counter', 6], ['pan', 0], ['cabinet', 8]], 'running': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'moveable': [['counter', 0], ['pan', 2], ['cabinet', 0]], 'mixed': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'edible': [['counter', 0], ['pan', 0], ['cabinet', 0]]}\n",
            "      {'h_location': [['John', 0]], 'conscious': [['John', 2]], 'wearing': [['John', 0]], 'h_wet': [['John', 0]], 'hygiene': [['John', 0]], 'location': [['fridge', 0], ['pizza', 7]], 'exist': [['fridge', 2], ['pizza', 2]], 'clean': [['fridge', 0], ['pizza', 0]], 'power': [['fridge', 2], ['pizza', 0]], 'functional': [['fridge', 2], ['pizza', 2]], 'pieces': [['fridge', 0], ['pizza', 0]], 'wet': [['fridge', 0], ['pizza', 0]], 'open': [['fridge', 4], ['pizza', 0]], 'temperature': [['fridge', 0], ['pizza', 1]], 'solid': [['fridge', 0], ['pizza', 0]], 'contain': [['fridge', 8], ['pizza', 0]], 'running': [['fridge', 2], ['pizza', 0]], 'moveable': [['fridge', 2], ['pizza', 2]], 'mixed': [['fridge', 0], ['pizza', 0]], 'edible': [['fridge', 0], ['pizza', 0]]}\n",
            "      {'h_location': [['John', 0]], 'conscious': [['John', 2]], 'wearing': [['John', 0]], 'h_wet': [['John', 0]], 'hygiene': [['John', 0]], 'location': [['oven', 0], ['pizza', 3], ['pan', 6]], 'exist': [['oven', 2], ['pizza', 2], ['pan', 2]], 'clean': [['oven', 0], ['pizza', 0], ['pan', 0]], 'power': [['oven', 2], ['pizza', 0], ['pan', 0]], 'functional': [['oven', 2], ['pizza', 2], ['pan', 2]], 'pieces': [['oven', 0], ['pizza', 0], ['pan', 0]], 'wet': [['oven', 0], ['pizza', 0], ['pan', 0]], 'open': [['oven', 8], ['pizza', 0], ['pan', 0]], 'temperature': [['oven', 2], ['pizza', 0], ['pan', 0]], 'solid': [['oven', 0], ['pizza', 0], ['pan', 0]], 'contain': [['oven', 6], ['pizza', 0], ['pan', 4]], 'running': [['oven', 0], ['pizza', 0], ['pan', 0]], 'moveable': [['oven', 0], ['pizza', 2], ['pan', 2]], 'mixed': [['oven', 0], ['pizza', 0], ['pan', 0]], 'edible': [['oven', 0], ['pizza', 0], ['pan', 0]]}\n",
            "      {'h_location': [['John', 0]], 'conscious': [['John', 2]], 'wearing': [['John', 0]], 'h_wet': [['John', 0]], 'hygiene': [['John', 0]], 'location': [['pizza', 0]], 'exist': [['pizza', 4]], 'clean': [['pizza', 0]], 'power': [['pizza', 0]], 'functional': [['pizza', 2]], 'pieces': [['pizza', 0]], 'wet': [['pizza', 0]], 'open': [['pizza', 0]], 'temperature': [['pizza', 0]], 'solid': [['pizza', 0]], 'contain': [['pizza', 0]], 'running': [['pizza', 0]], 'moveable': [['pizza', 2]], 'mixed': [['pizza', 0]], 'edible': [['pizza', 0]]}\n",
            "    ],\n",
            "}\n",
            "\n",
            "\n",
            "{\n",
            "  story_id: \n",
            "    13,\n",
            "  worker_id: \n",
            "    A32W24TWSWXW,\n",
            "  type: \n",
            "    order,\n",
            "  idx: \n",
            "    2,\n",
            "  aug: \n",
            "    False,\n",
            "  actor: \n",
            "    John,\n",
            "  location: \n",
            "    kitchen,\n",
            "  objects: \n",
            "    cabinet, counter, knife, pan, potato, pizza,\n",
            "  sentences: \n",
            "    [\n",
            "      John was getting the snacks ready for the party.\n",
            "      John opened the cabinet, took out a pan and put it on the counter.\n",
            "      John put the pizza on the pan and put them into the oven.\n",
            "      John opened the fridge and got out the pizza.\n",
            "      John took a knife and cut the hot pizza in eight slices.\n",
            "    ],\n",
            "  length: \n",
            "    5,\n",
            "  example_id: \n",
            "    13-O2,\n",
            "  plausible: \n",
            "    False,\n",
            "  breakpoint: \n",
            "    3,\n",
            "  confl_sents: \n",
            "    [\n",
            "      2\n",
            "    ],\n",
            "  confl_pairs: \n",
            "    [],\n",
            "  states: \n",
            "    [\n",
            "      {'h_location': [['John', 0]], 'conscious': [['John', 2]], 'wearing': [['John', 0]], 'h_wet': [['John', 0]], 'hygiene': [['John', 0]], 'location': [['snacks', 0], ['party', 0]], 'exist': [['snacks', 4], ['party', 2]], 'clean': [['snacks', 0], ['party', 0]], 'power': [['snacks', 0], ['party', 0]], 'functional': [['snacks', 2], ['party', 2]], 'pieces': [['snacks', 0], ['party', 0]], 'wet': [['snacks', 0], ['party', 0]], 'open': [['snacks', 0], ['party', 0]], 'temperature': [['snacks', 0], ['party', 0]], 'solid': [['snacks', 0], ['party', 0]], 'contain': [['snacks', 0], ['party', 0]], 'running': [['snacks', 0], ['party', 0]], 'moveable': [['snacks', 2], ['party', 2]], 'mixed': [['snacks', 0], ['party', 0]], 'edible': [['snacks', 0], ['party', 0]]}\n",
            "      {'h_location': [['John', 0]], 'conscious': [['John', 2]], 'wearing': [['John', 0]], 'h_wet': [['John', 0]], 'hygiene': [['John', 0]], 'location': [['counter', 0], ['pan', 7], ['cabinet', 0]], 'exist': [['counter', 2], ['pan', 2], ['cabinet', 2]], 'clean': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'power': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'functional': [['counter', 2], ['pan', 2], ['cabinet', 2]], 'pieces': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'wet': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'open': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'temperature': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'solid': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'contain': [['counter', 6], ['pan', 0], ['cabinet', 8]], 'running': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'moveable': [['counter', 0], ['pan', 2], ['cabinet', 0]], 'mixed': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'edible': [['counter', 0], ['pan', 0], ['cabinet', 0]]}\n",
            "      {'h_location': [['John', 0]], 'conscious': [['John', 2]], 'wearing': [['John', 0]], 'h_wet': [['John', 0]], 'hygiene': [['John', 0]], 'location': [['oven', 0], ['pizza', 3], ['pan', 6]], 'exist': [['oven', 2], ['pizza', 2], ['pan', 2]], 'clean': [['oven', 0], ['pizza', 0], ['pan', 0]], 'power': [['oven', 2], ['pizza', 0], ['pan', 0]], 'functional': [['oven', 2], ['pizza', 2], ['pan', 2]], 'pieces': [['oven', 0], ['pizza', 0], ['pan', 0]], 'wet': [['oven', 0], ['pizza', 0], ['pan', 0]], 'open': [['oven', 8], ['pizza', 0], ['pan', 0]], 'temperature': [['oven', 2], ['pizza', 0], ['pan', 0]], 'solid': [['oven', 0], ['pizza', 0], ['pan', 0]], 'contain': [['oven', 6], ['pizza', 0], ['pan', 4]], 'running': [['oven', 0], ['pizza', 0], ['pan', 0]], 'moveable': [['oven', 0], ['pizza', 2], ['pan', 2]], 'mixed': [['oven', 0], ['pizza', 0], ['pan', 0]], 'edible': [['oven', 0], ['pizza', 0], ['pan', 0]]}\n",
            "      {'h_location': [['John', 0]], 'conscious': [['John', 2]], 'wearing': [['John', 0]], 'h_wet': [['John', 0]], 'hygiene': [['John', 0]], 'location': [['fridge', 0], ['pizza', 7]], 'exist': [['fridge', 2], ['pizza', 2]], 'clean': [['fridge', 0], ['pizza', 0]], 'power': [['fridge', 2], ['pizza', 0]], 'functional': [['fridge', 2], ['pizza', 2]], 'pieces': [['fridge', 0], ['pizza', 0]], 'wet': [['fridge', 0], ['pizza', 0]], 'open': [['fridge', 4], ['pizza', 0]], 'temperature': [['fridge', 0], ['pizza', 1]], 'solid': [['fridge', 0], ['pizza', 0]], 'contain': [['fridge', 8], ['pizza', 0]], 'running': [['fridge', 2], ['pizza', 0]], 'moveable': [['fridge', 2], ['pizza', 2]], 'mixed': [['fridge', 0], ['pizza', 0]], 'edible': [['fridge', 0], ['pizza', 0]]}\n",
            "      {'h_location': [['John', 0]], 'conscious': [['John', 2]], 'wearing': [['John', 0]], 'h_wet': [['John', 0]], 'hygiene': [['John', 0]], 'location': [['knife', 2], ['slices', 2], ['hot pizza', 0]], 'exist': [['knife', 2], ['slices', 2], ['hot pizza', 2]], 'clean': [['knife', 0], ['slices', 0], ['hot pizza', 0]], 'power': [['knife', 0], ['slices', 0], ['hot pizza', 0]], 'functional': [['knife', 2], ['slices', 2], ['hot pizza', 2]], 'pieces': [['knife', 0], ['slices', 0], ['hot pizza', 4]], 'wet': [['knife', 0], ['slices', 0], ['hot pizza', 0]], 'open': [['knife', 0], ['slices', 0], ['hot pizza', 0]], 'temperature': [['knife', 0], ['slices', 0], ['hot pizza', 2]], 'solid': [['knife', 0], ['slices', 0], ['hot pizza', 0]], 'contain': [['knife', 0], ['slices', 0], ['hot pizza', 0]], 'running': [['knife', 0], ['slices', 0], ['hot pizza', 0]], 'moveable': [['knife', 2], ['slices', 2], ['hot pizza', 2]], 'mixed': [['knife', 0], ['slices', 0], ['hot pizza', 0]], 'edible': [['knife', 0], ['slices', 0], ['hot pizza', 0]]}\n",
            "    ],\n",
            "}\n",
            "\n",
            "\n",
            "{\n",
            "  story_id: \n",
            "    33,\n",
            "  worker_id: \n",
            "    A1F01FVEPYCPHO,\n",
            "  type: \n",
            "    None,\n",
            "  idx: \n",
            "    None,\n",
            "  aug: \n",
            "    False,\n",
            "  actor: \n",
            "    Mary,\n",
            "  location: \n",
            "    bathroom,\n",
            "  objects: \n",
            "    washing machine, cabinet, toothpaste, bleach, socks, mirror,\n",
            "  sentences: \n",
            "    [\n",
            "      Mary took off her socks.\n",
            "      Mary put the socks in the washing machine.\n",
            "      Mary opened the cabinet.\n",
            "      Mary took out the toothbrush and toothpaste.\n",
            "      Mary brushed her teeth while looking in the mirror.\n",
            "    ],\n",
            "  length: \n",
            "    5,\n",
            "  example_id: \n",
            "    33,\n",
            "  plausible: \n",
            "    True,\n",
            "  breakpoint: \n",
            "    -1,\n",
            "  confl_sents: \n",
            "    [],\n",
            "  confl_pairs: \n",
            "    [],\n",
            "  states: \n",
            "    [\n",
            "      {'h_location': [['Mary', 0]], 'conscious': [['Mary', 2]], 'wearing': [['Mary', 8]], 'h_wet': [['Mary', 0]], 'hygiene': [['Mary', 0]], 'location': [['socks', 5]], 'exist': [['socks', 2]], 'clean': [['socks', 0]], 'power': [['socks', 0]], 'functional': [['socks', 2]], 'pieces': [['socks', 0]], 'wet': [['socks', 0]], 'open': [['socks', 0]], 'temperature': [['socks', 0]], 'solid': [['socks', 0]], 'contain': [['socks', 0]], 'running': [['socks', 0]], 'moveable': [['socks', 2]], 'mixed': [['socks', 0]], 'edible': [['socks', 0]]}\n",
            "      {'h_location': [['Mary', 0]], 'conscious': [['Mary', 2]], 'wearing': [['Mary', 0]], 'h_wet': [['Mary', 0]], 'hygiene': [['Mary', 0]], 'location': [['socks', 6], ['washing machine', 0]], 'exist': [['socks', 2], ['washing machine', 2]], 'clean': [['socks', 0], ['washing machine', 0]], 'power': [['socks', 0], ['washing machine', 0]], 'functional': [['socks', 2], ['washing machine', 2]], 'pieces': [['socks', 0], ['washing machine', 0]], 'wet': [['socks', 0], ['washing machine', 0]], 'open': [['socks', 0], ['washing machine', 8]], 'temperature': [['socks', 0], ['washing machine', 0]], 'solid': [['socks', 0], ['washing machine', 0]], 'contain': [['socks', 0], ['washing machine', 6]], 'running': [['socks', 0], ['washing machine', 0]], 'moveable': [['socks', 2], ['washing machine', 2]], 'mixed': [['socks', 0], ['washing machine', 0]], 'edible': [['socks', 0], ['washing machine', 0]]}\n",
            "      {'h_location': [['Mary', 0]], 'conscious': [['Mary', 2]], 'wearing': [['Mary', 0]], 'h_wet': [['Mary', 0]], 'hygiene': [['Mary', 0]], 'location': [['cabinet', 0]], 'exist': [['cabinet', 2]], 'clean': [['cabinet', 0]], 'power': [['cabinet', 0]], 'functional': [['cabinet', 2]], 'pieces': [['cabinet', 0]], 'wet': [['cabinet', 0]], 'open': [['cabinet', 4]], 'temperature': [['cabinet', 0]], 'solid': [['cabinet', 0]], 'contain': [['cabinet', 0]], 'running': [['cabinet', 0]], 'moveable': [['cabinet', 2]], 'mixed': [['cabinet', 0]], 'edible': [['cabinet', 0]]}\n",
            "      {'h_location': [['Mary', 0]], 'conscious': [['Mary', 2]], 'wearing': [['Mary', 0]], 'h_wet': [['Mary', 0]], 'hygiene': [['Mary', 0]], 'location': [['toothbrush', 7], ['toothpaste', 7]], 'exist': [['toothbrush', 2], ['toothpaste', 2]], 'clean': [['toothbrush', 0], ['toothpaste', 0]], 'power': [['toothbrush', 0], ['toothpaste', 0]], 'functional': [['toothbrush', 2], ['toothpaste', 2]], 'pieces': [['toothbrush', 0], ['toothpaste', 0]], 'wet': [['toothbrush', 0], ['toothpaste', 0]], 'open': [['toothbrush', 0], ['toothpaste', 0]], 'temperature': [['toothbrush', 0], ['toothpaste', 0]], 'solid': [['toothbrush', 0], ['toothpaste', 0]], 'contain': [['toothbrush', 0], ['toothpaste', 0]], 'running': [['toothbrush', 0], ['toothpaste', 0]], 'moveable': [['toothbrush', 2], ['toothpaste', 2]], 'mixed': [['toothbrush', 0], ['toothpaste', 0]], 'edible': [['toothbrush', 0], ['toothpaste', 0]]}\n",
            "      {'h_location': [['Mary', 0]], 'conscious': [['Mary', 2]], 'wearing': [['Mary', 0]], 'h_wet': [['Mary', 0]], 'hygiene': [['Mary', 6]], 'location': [['mirror', 0], ['teeth', 0]], 'exist': [['mirror', 2], ['teeth', 2]], 'clean': [['mirror', 0], ['teeth', 6]], 'power': [['mirror', 0], ['teeth', 0]], 'functional': [['mirror', 2], ['teeth', 2]], 'pieces': [['mirror', 0], ['teeth', 0]], 'wet': [['mirror', 0], ['teeth', 0]], 'open': [['mirror', 0], ['teeth', 0]], 'temperature': [['mirror', 0], ['teeth', 0]], 'solid': [['mirror', 0], ['teeth', 0]], 'contain': [['mirror', 0], ['teeth', 0]], 'running': [['mirror', 0], ['teeth', 0]], 'moveable': [['mirror', 2], ['teeth', 0]], 'mixed': [['mirror', 0], ['teeth', 0]], 'edible': [['mirror', 0], ['teeth', 0]]}\n",
            "    ],\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from www.utils import print_dict\n",
        "\n",
        "partitions = ['train', 'dev', 'test']\n",
        "subtasks = ['cloze', 'order']\n",
        "\n",
        "# We can split the data into multiple json files later\n",
        "data_file = os.path.join(DRIVE_PATH, 'all_data/www.json')\n",
        "with open(data_file, 'r') as f:\n",
        "  dataset = json.load(f)\n",
        "\n",
        "print('Preprocessed examples:')\n",
        "for ex_idx in [0,1,5,10]:\n",
        "  ex = dataset['dev'][list(dataset['dev'].keys())[ex_idx]]\n",
        "  print_dict(ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_0WsycpFMdb"
      },
      "source": [
        "### Data Filtering and Sampling\n",
        "Since there is a big imbalance between plausible/implausible class labels, we will upsample the plausible stories.\n",
        "\n",
        "For now, we will also break the dataset into two sub-datasets: cloze and ordering.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-twYzY5rF1Mi"
      },
      "outputs": [],
      "source": [
        "cloze_dataset = {p: [] for p in dataset}\n",
        "order_dataset = {p: [] for p in dataset}\n",
        "\n",
        "for p in dataset:\n",
        "  for exid in dataset[p]:\n",
        "    ex = dataset[p][exid]\n",
        "\n",
        "    if ex['type'] == None:\n",
        "      continue\n",
        "\n",
        "    ex_plaus = dataset[p][str(ex['story_id'])]\n",
        "\n",
        "    if ex['type'] == 'cloze':\n",
        "      cloze_dataset[p].append(ex)\n",
        "      cloze_dataset[p].append(ex_plaus) # For every implausible story, add a copy of its corresponding plausible story\n",
        "\n",
        "    # Exclude augmented ordering examples from dev and test, since the breakpoints aren't always accurate in those\n",
        "    elif ex['type'] == 'order' and not (p != 'train' and ex['aug']):\n",
        "      order_dataset[p].append(ex)\n",
        "      order_dataset[p].append(ex_plaus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cz5tcmScJrka"
      },
      "source": [
        "\n",
        "\n",
        "### Convert TRIP to Two-Story Classification Task\n",
        "\n",
        "Ready the TRIP dataset for two-story classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Af976ygKJv7W",
        "outputId": "214ace8e-2500-4087-9241-f514b06dd611"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloze label distribution (train):\n",
            "[(1, 400), (0, 399)]\n",
            "Cloze label distribution (dev):\n",
            "[(0, 161), (1, 161)]\n",
            "Cloze label distribution (test):\n",
            "[(1, 176), (0, 175)]\n",
            "{\n",
            "  example_id: \n",
            "    0-C0,\n",
            "  stories: \n",
            "    [\n",
            "      {'story_id': 0, 'worker_id': 'A1F01FVEPYCPHO', 'type': 'cloze', 'idx': 0, 'aug': False, 'actor': 'Tom', 'location': 'kitchen', 'objects': 'dustbin, microwave, pan, plate, cereal, soup', 'sentences': ['Tom bought a new dustbin for the kitchen.', 'Tom threw a broken plate in the dustbin.', 'Tom got some soup from the fridge.', 'Tom put the soup in the microwave.', 'Tom ate the cold soup.'], 'length': 5, 'example_id': '0-C0', 'plausible': False, 'breakpoint': 4, 'confl_sents': [3], 'confl_pairs': [[3, 4]], 'states': [{'h_location': [['Tom', 0]], 'conscious': [['Tom', 2]], 'wearing': [['Tom', 0]], 'h_wet': [['Tom', 0]], 'hygiene': [['Tom', 0]], 'location': [['dustbin', 6]], 'exist': [['dustbin', 4]], 'clean': [['dustbin', 0]], 'power': [['dustbin', 0]], 'functional': [['dustbin', 2]], 'pieces': [['dustbin', 0]], 'wet': [['dustbin', 0]], 'open': [['dustbin', 0]], 'temperature': [['dustbin', 0]], 'solid': [['dustbin', 0]], 'contain': [['dustbin', 0]], 'running': [['dustbin', 0]], 'moveable': [['dustbin', 2]], 'mixed': [['dustbin', 0]], 'edible': [['dustbin', 0]]}, {'h_location': [['Tom', 0]], 'conscious': [['Tom', 2]], 'wearing': [['Tom', 0]], 'h_wet': [['Tom', 0]], 'hygiene': [['Tom', 0]], 'location': [['dustbin', 0], ['plate', 6]], 'exist': [['dustbin', 2], ['plate', 2]], 'clean': [['dustbin', 0], ['plate', 5]], 'power': [['dustbin', 0], ['plate', 0]], 'functional': [['dustbin', 2], ['plate', 1]], 'pieces': [['dustbin', 0], ['plate', 0]], 'wet': [['dustbin', 0], ['plate', 0]], 'open': [['dustbin', 0], ['plate', 0]], 'temperature': [['dustbin', 0], ['plate', 0]], 'solid': [['dustbin', 0], ['plate', 0]], 'contain': [['dustbin', 6], ['plate', 0]], 'running': [['dustbin', 0], ['plate', 0]], 'moveable': [['dustbin', 0], ['plate', 2]], 'mixed': [['dustbin', 0], ['plate', 0]], 'edible': [['dustbin', 0], ['plate', 0]]}, {'h_location': [['Tom', 0]], 'conscious': [['Tom', 2]], 'wearing': [['Tom', 0]], 'h_wet': [['Tom', 0]], 'hygiene': [['Tom', 0]], 'location': [['fridge', 0], ['soup', 2]], 'exist': [['fridge', 2], ['soup', 2]], 'clean': [['fridge', 0], ['soup', 0]], 'power': [['fridge', 0], ['soup', 0]], 'functional': [['fridge', 2], ['soup', 2]], 'pieces': [['fridge', 0], ['soup', 0]], 'wet': [['fridge', 0], ['soup', 0]], 'open': [['fridge', 8], ['soup', 0]], 'temperature': [['fridge', 0], ['soup', 1]], 'solid': [['fridge', 0], ['soup', 0]], 'contain': [['fridge', 8], ['soup', 0]], 'running': [['fridge', 0], ['soup', 0]], 'moveable': [['fridge', 2], ['soup', 2]], 'mixed': [['fridge', 0], ['soup', 0]], 'edible': [['fridge', 0], ['soup', 0]]}, {'h_location': [['Tom', 0]], 'conscious': [['Tom', 2]], 'wearing': [['Tom', 0]], 'h_wet': [['Tom', 0]], 'hygiene': [['Tom', 0]], 'location': [['microwave', 0], ['soup', 3]], 'exist': [['microwave', 2], ['soup', 2]], 'clean': [['microwave', 0], ['soup', 0]], 'power': [['microwave', 2], ['soup', 0]], 'functional': [['microwave', 2], ['soup', 2]], 'pieces': [['microwave', 0], ['soup', 0]], 'wet': [['microwave', 0], ['soup', 0]], 'open': [['microwave', 8], ['soup', 0]], 'temperature': [['microwave', 0], ['soup', 0]], 'solid': [['microwave', 0], ['soup', 0]], 'contain': [['microwave', 6], ['soup', 0]], 'running': [['microwave', 0], ['soup', 0]], 'moveable': [['microwave', 2], ['soup', 2]], 'mixed': [['microwave', 0], ['soup', 0]], 'edible': [['microwave', 0], ['soup', 0]]}, {'h_location': [['Tom', 0]], 'conscious': [['Tom', 2]], 'wearing': [['Tom', 0]], 'h_wet': [['Tom', 0]], 'hygiene': [['Tom', 0]], 'location': [['soup', 1]], 'exist': [['soup', 3]], 'clean': [['soup', 0]], 'power': [['soup', 0]], 'functional': [['soup', 2]], 'pieces': [['soup', 0]], 'wet': [['soup', 0]], 'open': [['soup', 0]], 'temperature': [['soup', 7]], 'solid': [['soup', 0]], 'contain': [['soup', 0]], 'running': [['soup', 0]], 'moveable': [['soup', 2]], 'mixed': [['soup', 0]], 'edible': [['soup', 0]]}]}\n",
            "      {'story_id': 0, 'worker_id': 'A1F01FVEPYCPHO', 'type': None, 'idx': None, 'aug': False, 'actor': 'Tom', 'location': 'kitchen', 'objects': 'dustbin, microwave, pan, plate, cereal, soup', 'sentences': ['Tom bought a new dustbin for the kitchen.', 'Tom threw a broken plate in the dustbin.', 'Tom got some soup from the fridge.', 'Tom put the soup in the microwave.', 'Tom turned on the microwave.'], 'length': 5, 'example_id': '0', 'plausible': True, 'breakpoint': -1, 'confl_sents': [], 'confl_pairs': [], 'states': [{'h_location': [['Tom', 0]], 'conscious': [['Tom', 2]], 'wearing': [['Tom', 0]], 'h_wet': [['Tom', 0]], 'hygiene': [['Tom', 0]], 'location': [['dustbin', 6]], 'exist': [['dustbin', 4]], 'clean': [['dustbin', 0]], 'power': [['dustbin', 0]], 'functional': [['dustbin', 2]], 'pieces': [['dustbin', 0]], 'wet': [['dustbin', 0]], 'open': [['dustbin', 0]], 'temperature': [['dustbin', 0]], 'solid': [['dustbin', 0]], 'contain': [['dustbin', 0]], 'running': [['dustbin', 0]], 'moveable': [['dustbin', 2]], 'mixed': [['dustbin', 0]], 'edible': [['dustbin', 0]]}, {'h_location': [['Tom', 0]], 'conscious': [['Tom', 2]], 'wearing': [['Tom', 0]], 'h_wet': [['Tom', 0]], 'hygiene': [['Tom', 0]], 'location': [['dustbin', 0], ['plate', 6]], 'exist': [['dustbin', 2], ['plate', 2]], 'clean': [['dustbin', 0], ['plate', 5]], 'power': [['dustbin', 0], ['plate', 0]], 'functional': [['dustbin', 2], ['plate', 1]], 'pieces': [['dustbin', 0], ['plate', 0]], 'wet': [['dustbin', 0], ['plate', 0]], 'open': [['dustbin', 0], ['plate', 0]], 'temperature': [['dustbin', 0], ['plate', 0]], 'solid': [['dustbin', 0], ['plate', 0]], 'contain': [['dustbin', 6], ['plate', 0]], 'running': [['dustbin', 0], ['plate', 0]], 'moveable': [['dustbin', 0], ['plate', 2]], 'mixed': [['dustbin', 0], ['plate', 0]], 'edible': [['dustbin', 0], ['plate', 0]]}, {'h_location': [['Tom', 0]], 'conscious': [['Tom', 2]], 'wearing': [['Tom', 0]], 'h_wet': [['Tom', 0]], 'hygiene': [['Tom', 0]], 'location': [['fridge', 0], ['soup', 2]], 'exist': [['fridge', 2], ['soup', 2]], 'clean': [['fridge', 0], ['soup', 0]], 'power': [['fridge', 0], ['soup', 0]], 'functional': [['fridge', 2], ['soup', 2]], 'pieces': [['fridge', 0], ['soup', 0]], 'wet': [['fridge', 0], ['soup', 0]], 'open': [['fridge', 8], ['soup', 0]], 'temperature': [['fridge', 0], ['soup', 1]], 'solid': [['fridge', 0], ['soup', 0]], 'contain': [['fridge', 8], ['soup', 0]], 'running': [['fridge', 0], ['soup', 0]], 'moveable': [['fridge', 2], ['soup', 2]], 'mixed': [['fridge', 0], ['soup', 0]], 'edible': [['fridge', 0], ['soup', 0]]}, {'h_location': [['Tom', 0]], 'conscious': [['Tom', 2]], 'wearing': [['Tom', 0]], 'h_wet': [['Tom', 0]], 'hygiene': [['Tom', 0]], 'location': [['microwave', 0], ['soup', 3]], 'exist': [['microwave', 2], ['soup', 2]], 'clean': [['microwave', 0], ['soup', 0]], 'power': [['microwave', 2], ['soup', 0]], 'functional': [['microwave', 2], ['soup', 2]], 'pieces': [['microwave', 0], ['soup', 0]], 'wet': [['microwave', 0], ['soup', 0]], 'open': [['microwave', 8], ['soup', 0]], 'temperature': [['microwave', 0], ['soup', 0]], 'solid': [['microwave', 0], ['soup', 0]], 'contain': [['microwave', 6], ['soup', 0]], 'running': [['microwave', 0], ['soup', 0]], 'moveable': [['microwave', 2], ['soup', 2]], 'mixed': [['microwave', 0], ['soup', 0]], 'edible': [['microwave', 0], ['soup', 0]]}, {'h_location': [['Tom', 0]], 'conscious': [['Tom', 2]], 'wearing': [['Tom', 0]], 'h_wet': [['Tom', 0]], 'hygiene': [['Tom', 0]], 'location': [['microwave', 0]], 'exist': [['microwave', 2]], 'clean': [['microwave', 0]], 'power': [['microwave', 2]], 'functional': [['microwave', 2]], 'pieces': [['microwave', 0]], 'wet': [['microwave', 0]], 'open': [['microwave', 1]], 'temperature': [['microwave', 0]], 'solid': [['microwave', 0]], 'contain': [['microwave', 2]], 'running': [['microwave', 4]], 'moveable': [['microwave', 2]], 'mixed': [['microwave', 0]], 'edible': [['microwave', 0]]}]}\n",
            "    ],\n",
            "  length: \n",
            "    5,\n",
            "  label: \n",
            "    1,\n",
            "  breakpoint: \n",
            "    4,\n",
            "  confl_sents: \n",
            "    [\n",
            "      3\n",
            "    ],\n",
            "  confl_pairs: \n",
            "    [\n",
            "      [3, 4]\n",
            "    ],\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from www.utils import print_dict\n",
        "import json\n",
        "from collections import Counter\n",
        "\n",
        "data_file = os.path.join(DRIVE_PATH, 'all_data/www_2s_new.json')\n",
        "with open(data_file, 'r') as f:\n",
        "  cloze_dataset_2s, order_dataset_2s = json.load(f)\n",
        "\n",
        "for p in cloze_dataset_2s:\n",
        "  label_dist = Counter([ex['label'] for ex in cloze_dataset_2s[p]])\n",
        "  print('Cloze label distribution (%s):' % p)\n",
        "  print(label_dist.most_common())\n",
        "print_dict(cloze_dataset_2s['train'][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxIYaEobhR7J"
      },
      "source": [
        "---\n",
        "\n",
        "# TRIP Results\n",
        "\n",
        "Contains code for the tiered and random TRIP baselines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbUgyE0bbJqn"
      },
      "outputs": [],
      "source": [
        "if task_name != 'trip':\n",
        "  raise ValueError('Please configure task_name in first cell to \"trip\" to run TRIP results!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7VlN2jUwvcC"
      },
      "source": [
        "## Random Tiered Classifier for TRIP\n",
        "\n",
        "For the random baseline, we average the results of 10 runs. Running the below will report (mean, variance) for each evaluation partition."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pPF-GPz6dNu",
        "outputId": "843836eb-f7d1-40af-8043-373c6b3ff1ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "absl-py==1.4.0\n",
            "accelerate==1.1.1\n",
            "aiohappyeyeballs==2.4.4\n",
            "aiohttp==3.11.10\n",
            "aiosignal==1.3.1\n",
            "alabaster==1.0.0\n",
            "albucore==0.0.19\n",
            "albumentations==1.4.20\n",
            "altair==5.5.0\n",
            "annotated-types==0.7.0\n",
            "anyio==3.7.1\n",
            "argon2-cffi==23.1.0\n",
            "argon2-cffi-bindings==21.2.0\n",
            "array_record==0.5.1\n",
            "arviz==0.20.0\n",
            "astropy==6.1.7\n",
            "astropy-iers-data==0.2024.12.9.0.36.21\n",
            "astunparse==1.6.3\n",
            "async-timeout==4.0.3\n",
            "atpublic==4.1.0\n",
            "attrs==24.2.0\n",
            "audioread==3.0.1\n",
            "autograd==1.7.0\n",
            "babel==2.16.0\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.12.3\n",
            "bigframes==1.27.0\n",
            "bigquery-magics==0.4.0\n",
            "bleach==6.2.0\n",
            "blinker==1.9.0\n",
            "blis==0.7.11\n",
            "blosc2==2.7.1\n",
            "bokeh==3.6.2\n",
            "Bottleneck==1.4.2\n",
            "bqplot==0.12.43\n",
            "branca==0.8.0\n",
            "CacheControl==0.14.1\n",
            "cachetools==5.5.0\n",
            "catalogue==2.0.10\n",
            "certifi==2024.8.30\n",
            "cffi==1.17.1\n",
            "chardet==5.2.0\n",
            "charset-normalizer==3.4.0\n",
            "chex==0.1.87\n",
            "clarabel==0.9.0\n",
            "click==8.1.7\n",
            "cloudpathlib==0.20.0\n",
            "cloudpickle==3.1.0\n",
            "cmake==3.30.5\n",
            "cmdstanpy==1.2.4\n",
            "colorcet==3.1.0\n",
            "colorlover==0.3.0\n",
            "colour==0.1.5\n",
            "community==1.0.0b1\n",
            "confection==0.1.5\n",
            "cons==0.4.6\n",
            "contourpy==1.3.1\n",
            "cryptography==43.0.3\n",
            "cuda-python==12.2.1\n",
            "cudf-cu12 @ https://pypi.nvidia.com/cudf-cu12/cudf_cu12-24.10.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\n",
            "cufflinks==0.17.3\n",
            "cupy-cuda12x==12.2.0\n",
            "cvxopt==1.3.2\n",
            "cvxpy==1.5.4\n",
            "cycler==0.12.1\n",
            "cymem==2.0.10\n",
            "Cython==3.0.11\n",
            "dask==2024.10.0\n",
            "datascience==0.17.6\n",
            "db-dtypes==1.3.1\n",
            "dbus-python==1.2.18\n",
            "debugpy==1.8.0\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "Deprecated==1.2.15\n",
            "diffusers==0.31.0\n",
            "distro==1.9.0\n",
            "dlib==19.24.2\n",
            "dm-tree==0.1.8\n",
            "docker-pycreds==0.4.0\n",
            "docstring_parser==0.16\n",
            "docutils==0.21.2\n",
            "dopamine_rl==4.0.9\n",
            "duckdb==1.1.3\n",
            "earthengine-api==1.2.0\n",
            "easydict==1.13\n",
            "ecos==2.0.14\n",
            "editdistance==0.8.1\n",
            "eerepr==0.0.4\n",
            "einops==0.8.0\n",
            "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl#sha256=86cc141f63942d4b2c5fcee06630fd6f904788d2f0ab005cce45aadb8fb73889\n",
            "entrypoints==0.4\n",
            "et_xmlfile==2.0.0\n",
            "etils==1.11.0\n",
            "etuples==0.3.9\n",
            "eval_type_backport==0.2.0\n",
            "exceptiongroup==1.2.2\n",
            "fastai==2.7.18\n",
            "fastcore==1.7.25\n",
            "fastdownload==0.0.7\n",
            "fastjsonschema==2.21.1\n",
            "fastprogress==1.0.3\n",
            "fastrlock==0.8.2\n",
            "filelock==3.16.1\n",
            "firebase-admin==6.5.0\n",
            "Flask==3.0.3\n",
            "flatbuffers==24.3.25\n",
            "flax==0.8.5\n",
            "folium==0.18.0\n",
            "fonttools==4.55.2\n",
            "frozendict==2.4.6\n",
            "frozenlist==1.5.0\n",
            "fsspec==2024.10.0\n",
            "future==1.0.0\n",
            "gast==0.6.0\n",
            "gcsfs==2024.10.0\n",
            "GDAL==3.6.4\n",
            "gdown==5.2.0\n",
            "geemap==0.35.1\n",
            "gensim==4.3.3\n",
            "geocoder==1.38.1\n",
            "geographiclib==2.0\n",
            "geopandas==1.0.1\n",
            "geopy==2.4.1\n",
            "gin-config==0.5.0\n",
            "gitdb==4.0.11\n",
            "GitPython==3.1.43\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-ai-generativelanguage==0.6.10\n",
            "google-api-core==2.19.2\n",
            "google-api-python-client==2.151.0\n",
            "google-auth==2.27.0\n",
            "google-auth-httplib2==0.2.0\n",
            "google-auth-oauthlib==1.2.1\n",
            "google-cloud-aiplatform==1.73.0\n",
            "google-cloud-bigquery==3.25.0\n",
            "google-cloud-bigquery-connection==1.16.1\n",
            "google-cloud-bigquery-storage==2.27.0\n",
            "google-cloud-bigtable==2.27.0\n",
            "google-cloud-core==2.4.1\n",
            "google-cloud-datastore==2.20.1\n",
            "google-cloud-firestore==2.19.0\n",
            "google-cloud-functions==1.18.1\n",
            "google-cloud-iam==2.16.1\n",
            "google-cloud-language==2.15.1\n",
            "google-cloud-pubsub==2.27.1\n",
            "google-cloud-resource-manager==1.13.1\n",
            "google-cloud-storage==2.8.0\n",
            "google-cloud-translate==3.17.0\n",
            "google-colab @ file:///colabtools/dist/google_colab-1.0.0.tar.gz\n",
            "google-crc32c==1.6.0\n",
            "google-generativeai==0.8.3\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==2.7.2\n",
            "googleapis-common-protos==1.66.0\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.20.3\n",
            "greenlet==3.1.1\n",
            "grpc-google-iam-v1==0.13.1\n",
            "grpcio==1.68.1\n",
            "grpcio-status==1.62.3\n",
            "gspread==6.0.2\n",
            "gspread-dataframe==3.3.1\n",
            "gym==0.25.2\n",
            "gym-notices==0.0.8\n",
            "h11==0.14.0\n",
            "h5netcdf==1.4.1\n",
            "h5py==3.12.1\n",
            "holidays==0.62\n",
            "holoviews==1.20.0\n",
            "html5lib==1.1\n",
            "httpcore==1.0.7\n",
            "httpimport==1.4.0\n",
            "httplib2==0.22.0\n",
            "httpx==0.28.1\n",
            "huggingface-hub==0.26.5\n",
            "humanize==4.11.0\n",
            "hyperopt==0.2.7\n",
            "ibis-framework==9.2.0\n",
            "idna==3.10\n",
            "imageio==2.36.1\n",
            "imageio-ffmpeg==0.5.1\n",
            "imagesize==1.4.1\n",
            "imbalanced-learn==0.12.4\n",
            "imgaug==0.4.0\n",
            "immutabledict==4.2.1\n",
            "importlib_metadata==8.5.0\n",
            "importlib_resources==6.4.5\n",
            "imutils==0.5.4\n",
            "inflect==7.4.0\n",
            "iniconfig==2.0.0\n",
            "intel-cmplr-lib-ur==2025.0.3\n",
            "intel-openmp==2025.0.3\n",
            "ipyevents==2.0.2\n",
            "ipyfilechooser==0.6.0\n",
            "ipykernel==5.5.6\n",
            "ipyleaflet==0.19.2\n",
            "ipyparallel==8.8.0\n",
            "ipython==7.34.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.5.0\n",
            "ipytree==0.2.2\n",
            "ipywidgets==7.7.1\n",
            "itsdangerous==2.2.0\n",
            "jax==0.4.33\n",
            "jax-cuda12-pjrt==0.4.33\n",
            "jax-cuda12-plugin==0.4.33\n",
            "jaxlib==0.4.33\n",
            "jeepney==0.7.1\n",
            "jellyfish==1.1.2\n",
            "jieba==0.42.1\n",
            "Jinja2==3.1.4\n",
            "jiter==0.8.2\n",
            "joblib==1.4.2\n",
            "jsonlines==2.0.0\n",
            "jsonpatch==1.33\n",
            "jsonpickle==4.0.0\n",
            "jsonpointer==3.0.0\n",
            "jsonschema==4.23.0\n",
            "jsonschema-specifications==2024.10.1\n",
            "jupyter-client==6.1.12\n",
            "jupyter-console==6.1.0\n",
            "jupyter-leaflet==0.19.2\n",
            "jupyter-server==1.24.0\n",
            "jupyter_core==5.7.2\n",
            "jupyterlab_pygments==0.3.0\n",
            "jupyterlab_widgets==3.0.13\n",
            "kaggle==1.6.17\n",
            "kagglehub==0.3.4\n",
            "keras==3.5.0\n",
            "keyring==23.5.0\n",
            "kiwisolver==1.4.7\n",
            "langchain==0.3.10\n",
            "langchain-core==0.3.22\n",
            "langchain-text-splitters==0.3.2\n",
            "langcodes==3.5.0\n",
            "langsmith==0.1.147\n",
            "language_data==1.3.0\n",
            "launchpadlib==1.10.16\n",
            "lazr.restfulclient==0.14.4\n",
            "lazr.uri==1.0.6\n",
            "lazy_loader==0.4\n",
            "libclang==18.1.1\n",
            "libcudf-cu12 @ https://pypi.nvidia.com/libcudf-cu12/libcudf_cu12-24.10.1-py3-none-manylinux_2_28_x86_64.whl\n",
            "librosa==0.10.2.post1\n",
            "lightgbm==4.5.0\n",
            "linkify-it-py==2.0.3\n",
            "llvmlite==0.43.0\n",
            "locket==1.0.0\n",
            "logical-unification==0.4.6\n",
            "lxml==5.3.0\n",
            "marisa-trie==1.2.1\n",
            "Markdown==3.7\n",
            "markdown-it-py==3.0.0\n",
            "MarkupSafe==3.0.2\n",
            "matplotlib==3.8.0\n",
            "matplotlib-inline==0.1.7\n",
            "matplotlib-venn==1.1.1\n",
            "mdit-py-plugins==0.4.2\n",
            "mdurl==0.1.2\n",
            "miniKanren==1.0.3\n",
            "missingno==0.5.2\n",
            "mistune==3.0.2\n",
            "mizani==0.13.0\n",
            "mkl==2025.0.1\n",
            "ml-dtypes==0.4.1\n",
            "mlxtend==0.23.3\n",
            "more-itertools==10.5.0\n",
            "moviepy==1.0.3\n",
            "mpmath==1.3.0\n",
            "msgpack==1.1.0\n",
            "multidict==6.1.0\n",
            "multipledispatch==1.0.0\n",
            "multitasking==0.0.11\n",
            "murmurhash==1.0.11\n",
            "music21==9.3.0\n",
            "namex==0.0.8\n",
            "narwhals==1.16.0\n",
            "natsort==8.4.0\n",
            "nbclassic==1.1.0\n",
            "nbclient==0.10.1\n",
            "nbconvert==7.16.4\n",
            "nbformat==5.10.4\n",
            "ndindex==1.9.2\n",
            "nest-asyncio==1.6.0\n",
            "networkx==3.4.2\n",
            "nibabel==5.3.2\n",
            "nltk==3.9.1\n",
            "notebook==6.5.5\n",
            "notebook_shim==0.2.4\n",
            "numba==0.60.0\n",
            "numexpr==2.10.2\n",
            "numpy==1.26.4\n",
            "nvidia-cublas-cu12==12.6.4.1\n",
            "nvidia-cuda-cupti-cu12==12.6.80\n",
            "nvidia-cuda-nvcc-cu12==12.6.85\n",
            "nvidia-cuda-runtime-cu12==12.6.77\n",
            "nvidia-cudnn-cu12==9.6.0.74\n",
            "nvidia-cufft-cu12==11.3.0.4\n",
            "nvidia-curand-cu12==10.3.7.77\n",
            "nvidia-cusolver-cu12==11.7.1.2\n",
            "nvidia-cusparse-cu12==12.5.4.2\n",
            "nvidia-nccl-cu12==2.23.4\n",
            "nvidia-nvjitlink-cu12==12.6.85\n",
            "nvtx==0.2.10\n",
            "nx-cugraph-cu12 @ https://pypi.nvidia.com/nx-cugraph-cu12/nx_cugraph_cu12-24.10.0-py3-none-any.whl\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.2.2\n",
            "openai==1.54.5\n",
            "opencv-contrib-python==4.10.0.84\n",
            "opencv-python==4.10.0.84\n",
            "opencv-python-headless==4.10.0.84\n",
            "openpyxl==3.1.5\n",
            "opentelemetry-api==1.28.2\n",
            "opentelemetry-sdk==1.28.2\n",
            "opentelemetry-semantic-conventions==0.49b2\n",
            "opt_einsum==3.4.0\n",
            "optax==0.2.4\n",
            "optree==0.13.1\n",
            "orbax-checkpoint==0.6.4\n",
            "orjson==3.10.12\n",
            "osqp==0.6.7.post3\n",
            "packaging==24.2\n",
            "pandas==2.2.2\n",
            "pandas-datareader==0.10.0\n",
            "pandas-gbq==0.24.0\n",
            "pandas-stubs==2.2.2.240909\n",
            "pandocfilters==1.5.1\n",
            "panel==1.5.4\n",
            "param==2.1.1\n",
            "parso==0.8.4\n",
            "parsy==2.1\n",
            "partd==1.4.2\n",
            "pathlib==1.0.1\n",
            "patsy==1.0.1\n",
            "peewee==3.17.8\n",
            "peft==0.13.2\n",
            "pexpect==4.9.0\n",
            "pickleshare==0.7.5\n",
            "pillow==11.0.0\n",
            "platformdirs==4.3.6\n",
            "plotly==5.24.1\n",
            "plotnine==0.14.3\n",
            "pluggy==1.5.0\n",
            "ply==3.11\n",
            "polars==1.9.0\n",
            "pooch==1.8.2\n",
            "portpicker==1.5.2\n",
            "preshed==3.0.9\n",
            "prettytable==3.12.0\n",
            "proglog==0.1.10\n",
            "progressbar2==4.5.0\n",
            "prometheus_client==0.21.1\n",
            "promise==2.3\n",
            "prompt_toolkit==3.0.48\n",
            "propcache==0.2.1\n",
            "prophet==1.1.6\n",
            "proto-plus==1.25.0\n",
            "protobuf==4.25.5\n",
            "psutil==5.9.5\n",
            "psycopg2==2.9.10\n",
            "ptyprocess==0.7.0\n",
            "py-cpuinfo==9.0.0\n",
            "py4j==0.10.9.7\n",
            "pyarrow==17.0.0\n",
            "pyarrow-hotfix==0.6\n",
            "pyasn1==0.6.1\n",
            "pyasn1_modules==0.4.1\n",
            "pycocotools==2.0.8\n",
            "pycparser==2.22\n",
            "pydantic==2.10.3\n",
            "pydantic_core==2.27.1\n",
            "pydata-google-auth==1.9.0\n",
            "pydot==3.0.3\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "PyDrive2==1.21.3\n",
            "pyerfa==2.0.1.5\n",
            "pygame==2.6.1\n",
            "pygit2==1.16.0\n",
            "Pygments==2.18.0\n",
            "PyGObject==3.42.1\n",
            "PyJWT==2.10.1\n",
            "pylibcudf-cu12 @ https://pypi.nvidia.com/pylibcudf-cu12/pylibcudf_cu12-24.10.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\n",
            "pylibcugraph-cu12==24.10.0\n",
            "pylibraft-cu12==24.10.0\n",
            "pymc==5.18.2\n",
            "pymystem3==0.2.0\n",
            "pynvjitlink-cu12==0.4.0\n",
            "pyogrio==0.10.0\n",
            "Pyomo==6.8.2\n",
            "PyOpenGL==3.1.7\n",
            "pyOpenSSL==24.2.1\n",
            "pyparsing==3.2.0\n",
            "pyperclip==1.9.0\n",
            "pyproj==3.7.0\n",
            "pyshp==2.3.1\n",
            "PySocks==1.7.1\n",
            "pyspark==3.5.3\n",
            "pytensor==2.26.4\n",
            "pytest==8.3.4\n",
            "python-apt==0.0.0\n",
            "python-box==7.2.0\n",
            "python-dateutil==2.8.2\n",
            "python-louvain==0.16\n",
            "python-slugify==8.0.4\n",
            "python-utils==3.9.1\n",
            "pytz==2024.2\n",
            "pyviz_comms==3.0.3\n",
            "PyYAML==6.0.2\n",
            "pyzmq==24.0.1\n",
            "qdldl==0.1.7.post4\n",
            "ratelim==0.1.6\n",
            "referencing==0.35.1\n",
            "regex==2024.9.11\n",
            "requests==2.32.3\n",
            "requests-oauthlib==1.3.1\n",
            "requests-toolbelt==1.0.0\n",
            "requirements-parser==0.9.0\n",
            "rich==13.9.4\n",
            "rmm-cu12==24.10.0\n",
            "rpds-py==0.22.3\n",
            "rpy2==3.4.2\n",
            "rsa==4.9\n",
            "safetensors==0.4.5\n",
            "scikit-image==0.24.0\n",
            "scikit-learn==1.5.2\n",
            "scipy==1.13.1\n",
            "scooby==0.10.0\n",
            "scs==3.2.7\n",
            "seaborn==0.13.2\n",
            "SecretStorage==3.3.1\n",
            "Send2Trash==1.8.3\n",
            "sentence-transformers==3.2.1\n",
            "sentencepiece==0.2.0\n",
            "sentry-sdk==2.19.2\n",
            "setproctitle==1.3.4\n",
            "shap==0.46.0\n",
            "shapely==2.0.6\n",
            "shellingham==1.5.4\n",
            "simple-parsing==0.1.6\n",
            "six==1.17.0\n",
            "sklearn-pandas==2.2.0\n",
            "slicer==0.0.8\n",
            "smart-open==7.0.5\n",
            "smmap==5.0.1\n",
            "sniffio==1.3.1\n",
            "snowballstemmer==2.2.0\n",
            "soundfile==0.12.1\n",
            "soupsieve==2.6\n",
            "soxr==0.5.0.post1\n",
            "spacy==3.7.5\n",
            "spacy-legacy==3.0.12\n",
            "spacy-loggers==1.0.5\n",
            "Sphinx==8.1.3\n",
            "sphinxcontrib-applehelp==2.0.0\n",
            "sphinxcontrib-devhelp==2.0.0\n",
            "sphinxcontrib-htmlhelp==2.1.0\n",
            "sphinxcontrib-jsmath==1.0.1\n",
            "sphinxcontrib-qthelp==2.0.0\n",
            "sphinxcontrib-serializinghtml==2.0.0\n",
            "SQLAlchemy==2.0.36\n",
            "sqlglot==25.1.0\n",
            "sqlparse==0.5.2\n",
            "srsly==2.4.8\n",
            "stanio==0.5.1\n",
            "statsmodels==0.14.4\n",
            "StrEnum==0.4.15\n",
            "stringzilla==3.11.0\n",
            "sympy==1.13.1\n",
            "tables==3.10.1\n",
            "tabulate==0.9.0\n",
            "tbb==2022.0.0\n",
            "tcmlib==1.2.0\n",
            "tenacity==9.0.0\n",
            "tensorboard==2.17.1\n",
            "tensorboard-data-server==0.7.2\n",
            "tensorflow==2.17.1\n",
            "tensorflow-datasets==4.9.7\n",
            "tensorflow-hub==0.16.1\n",
            "tensorflow-io-gcs-filesystem==0.37.1\n",
            "tensorflow-metadata==1.13.1\n",
            "tensorflow-probability==0.24.0\n",
            "tensorstore==0.1.69\n",
            "termcolor==2.5.0\n",
            "terminado==0.18.1\n",
            "text-unidecode==1.3\n",
            "textblob==0.17.1\n",
            "tf-slim==1.1.0\n",
            "tf_keras==2.17.0\n",
            "thinc==8.2.5\n",
            "threadpoolctl==3.5.0\n",
            "tifffile==2024.9.20\n",
            "timm==1.0.12\n",
            "tinycss2==1.4.0\n",
            "tokenizers==0.20.3\n",
            "toml==0.10.2\n",
            "tomli==2.2.1\n",
            "toolz==0.12.1\n",
            "torch @ https://download.pytorch.org/whl/cu121_full/torch-2.5.1%2Bcu121-cp310-cp310-linux_x86_64.whl\n",
            "torchaudio @ https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp310-cp310-linux_x86_64.whl\n",
            "torchsummary==1.5.1\n",
            "torchvision @ https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp310-cp310-linux_x86_64.whl\n",
            "tornado==6.3.3\n",
            "tqdm==4.66.6\n",
            "traitlets==5.7.1\n",
            "traittypes==0.2.1\n",
            "transformers==4.46.3\n",
            "tweepy==4.14.0\n",
            "typeguard==4.4.1\n",
            "typer==0.15.1\n",
            "types-pytz==2024.2.0.20241003\n",
            "types-setuptools==75.6.0.20241126\n",
            "typing_extensions==4.12.2\n",
            "tzdata==2024.2\n",
            "tzlocal==5.2\n",
            "uc-micro-py==1.0.3\n",
            "umf==0.9.1\n",
            "uritemplate==4.1.1\n",
            "urllib3==2.2.3\n",
            "vega-datasets==0.9.0\n",
            "wadllib==1.3.6\n",
            "wandb==0.18.7\n",
            "wasabi==1.1.3\n",
            "wcwidth==0.2.13\n",
            "weasel==0.4.1\n",
            "webcolors==24.11.1\n",
            "webencodings==0.5.1\n",
            "websocket-client==1.8.0\n",
            "Werkzeug==3.1.3\n",
            "widgetsnbextension==3.6.10\n",
            "wordcloud==1.9.4\n",
            "wrapt==1.17.0\n",
            "xarray==2024.10.0\n",
            "xarray-einstats==0.8.0\n",
            "xgboost==2.1.3\n",
            "xlrd==2.0.1\n",
            "xyzservices==2024.9.0\n",
            "yarl==1.18.3\n",
            "yellowbrick==1.5\n",
            "yfinance==0.2.50\n",
            "zipp==3.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGYE2UIiASDv",
        "outputId": "7beaa379-0c22-438c-faf3-8d32d8c78bc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n",
            "[========================================================================] \u001b[38;2;0;255;0m100%\u001b[39m\n",
            "[========================================================================] \u001b[38;2;0;255;0m100%\u001b[39m\n",
            "[========================================================================] \u001b[38;2;0;255;0m100%\u001b[39m\n"
          ]
        }
      ],
      "source": [
        "from www.dataset.prepro import get_tiered_data\n",
        "from www.dataset.featurize import add_bert_features_tiered, get_tensor_dataset_tiered\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "from www.dataset.ann import att_to_num_classes, idx_to_att\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from www.utils import print_dict\n",
        "import transformers\n",
        "\n",
        "transformers.logging.set_verbosity_error()\n",
        "\n",
        "tiered_dataset = cloze_dataset_2s\n",
        "\n",
        "seq_length = 16 # Max sequence length to pad to\n",
        "\n",
        "tiered_dataset = get_tiered_data(tiered_dataset)\n",
        "tiered_dataset = add_bert_features_tiered(tiered_dataset, tokenizer, seq_length, add_segment_ids=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wL20bloxwxci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "971adb23-389c-4f54-91cc-c1705b1cef2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting dev...\n",
            "starting run 0...\n",
            "starting run 1...\n",
            "starting run 2...\n",
            "starting run 3...\n",
            "starting run 4...\n",
            "starting run 5...\n",
            "starting run 6...\n",
            "starting run 7...\n",
            "starting run 8...\n",
            "starting run 9...\n",
            "RANDOM BASELINE (dev, 10 runs)\n",
            "{\n",
            "  story_accuracy: \n",
            "    (0.4768119639160012, 0.013949527138295129),\n",
            "  confl_f1: \n",
            "    (0.4855347248422836, 0.0008174248775743625),\n",
            "  precondition_f1: \n",
            "    (0.040135527004918986, 0.00010658768238311807),\n",
            "  effect_f1: \n",
            "    (0.040177613152679, 0.0001515907774214225),\n",
            "  verifiability: \n",
            "    (0.0, 0.0),\n",
            "  consistency: \n",
            "    (0.12340481119984226, 0.001886887218373742),\n",
            "}\n",
            "\n",
            "\n",
            "starting test...\n",
            "starting run 0...\n",
            "starting run 1...\n",
            "starting run 2...\n",
            "starting run 3...\n",
            "starting run 4...\n",
            "starting run 5...\n",
            "starting run 6...\n",
            "starting run 7...\n",
            "starting run 8...\n",
            "starting run 9...\n",
            "RANDOM BASELINE (test, 10 runs)\n",
            "{\n",
            "  story_accuracy: \n",
            "    (0.4887003876015702, 0.002554084109254179),\n",
            "  confl_f1: \n",
            "    (0.4838064784519188, 0.0006696668011244163),\n",
            "  precondition_f1: \n",
            "    (0.04008409126649581, 0.00010034371145872117),\n",
            "  effect_f1: \n",
            "    (0.04024398279727084, 3.998112312749474e-05),\n",
            "  verifiability: \n",
            "    (0.0, 0.0),\n",
            "  consistency: \n",
            "    (0.1080558226597387, 0.0044741117552505125),\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from www.dataset.prepro import get_tiered_data, balance_labels\n",
        "from www.dataset.featurize import add_bert_features_tiered, get_tensor_dataset_tiered\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "from www.dataset.ann import att_to_num_classes, idx_to_att, att_default_values\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from www.utils import print_dict\n",
        "import numpy as np\n",
        "\n",
        "# Have to add BERT input IDs and tensorize again\n",
        "num_runs = 10\n",
        "stories = []\n",
        "pred_stories = []\n",
        "conflicts = []\n",
        "pred_conflicts = []\n",
        "preconditions = []\n",
        "pred_preconditions = []\n",
        "effects = []\n",
        "pred_effects = []\n",
        "verifiability = []\n",
        "consistency = []\n",
        "for p in tiered_dataset:\n",
        "  if p == 'train':\n",
        "    continue\n",
        "  metr_avg = {}\n",
        "  print('starting %s...' % p)\n",
        "  for r in range(num_runs):\n",
        "    print('starting run %s...' % str(r))\n",
        "    for ex in tiered_dataset[p]:\n",
        "      verifiable = True\n",
        "      consistent = True\n",
        "\n",
        "      stories.append(ex['label'])\n",
        "      pred_stories.append(np.random.randint(2))\n",
        "\n",
        "      if stories[-1] != pred_stories[-1]:\n",
        "        verifiable = False\n",
        "\n",
        "      labels_ex_p = []\n",
        "      preds_ex_p = []\n",
        "\n",
        "      labels_ex_e = []\n",
        "      preds_ex_e = []\n",
        "\n",
        "      labels_ex_c = []\n",
        "      preds_ex_c = []\n",
        "\n",
        "      for si, story in enumerate(ex['stories']):\n",
        "        labels_story_p = []\n",
        "        preds_story_p = []\n",
        "\n",
        "        labels_story_e = []\n",
        "        preds_story_e = []\n",
        "\n",
        "        for ent_ann in story['entities']:\n",
        "          entity = ent_ann['entity']\n",
        "\n",
        "          if si == 1 - ex['label']:\n",
        "            labels_ex_c.append(ent_ann['conflict_span_onehot'])\n",
        "            pred = np.zeros(ent_ann['conflict_span_onehot'].shape)\n",
        "            for cs in np.random.choice(len(pred), size=2, replace=False):\n",
        "              pred[cs] = 1\n",
        "            preds_ex_c.append(pred)\n",
        "\n",
        "          labels_ent = []\n",
        "          preds_ent = []\n",
        "          for s, sent_ann in enumerate(ent_ann['preconditions']):\n",
        "            if s < len(story['sentences']):\n",
        "              if entity in story['sentences'][s]:\n",
        "\n",
        "                labels_ent.append(sent_ann)\n",
        "                sent_ann_pred = []\n",
        "                for i, l in enumerate(sent_ann):\n",
        "                  pl = np.random.randint(att_to_num_classes[idx_to_att[i]])\n",
        "                  if pl > 0 and pl != att_default_values[idx_to_att[i]]:\n",
        "                    if pl != l:\n",
        "                      verifiable = False\n",
        "                  sent_ann_pred.append(pl)\n",
        "                preds_ent.append(sent_ann_pred)\n",
        "\n",
        "          labels_story_p.append(labels_ent)\n",
        "          preds_story_p.append(preds_ent)\n",
        "\n",
        "          labels_ent = []\n",
        "          preds_ent = []\n",
        "          for s, sent_ann in enumerate(ent_ann['effects']):\n",
        "            if s < len(story['sentences']):\n",
        "              if entity in story['sentences'][s]:\n",
        "\n",
        "                labels_ent.append(sent_ann)\n",
        "                sent_ann_pred = []\n",
        "                for i, l in enumerate(sent_ann):\n",
        "                  pl = np.random.randint(att_to_num_classes[idx_to_att[i]])\n",
        "                  if pl > 0 and pl != att_default_values[idx_to_att[i]]:\n",
        "                    if pl != l:\n",
        "                      verifiable = False\n",
        "                  sent_ann_pred.append(pl)\n",
        "                preds_ent.append(sent_ann_pred)\n",
        "\n",
        "          labels_story_e.append(labels_ent)\n",
        "          preds_story_e.append(preds_ent)\n",
        "\n",
        "        labels_ex_p.append(labels_story_p)\n",
        "        preds_ex_p.append(preds_story_p)\n",
        "\n",
        "        labels_ex_e.append(labels_story_e)\n",
        "        preds_ex_e.append(preds_story_e)\n",
        "\n",
        "      conflicts.append(labels_ex_c)\n",
        "      pred_conflicts.append(preds_ex_c)\n",
        "\n",
        "      preconditions.append(labels_ex_p)\n",
        "      pred_preconditions.append(preds_ex_p)\n",
        "\n",
        "      effects.append(labels_ex_e)\n",
        "      pred_effects.append(preds_ex_e)\n",
        "\n",
        "      p_confl = np.nonzero(np.sum(np.array(preds_ex_c), axis=0))[0]\n",
        "      l_confl = np.nonzero(np.sum(np.array(labels_ex_c), axis=0))[0]\n",
        "      assert len(l_confl) == 2, str(labels_ex_c)\n",
        "      if not (p_confl[0] == l_confl[0] and p_confl[1] == l_confl[1]):\n",
        "        verifiable = False\n",
        "        consistent = False\n",
        "\n",
        "      verifiability.append(1 if verifiable else 0)\n",
        "      consistency.append(1 if consistent else 0)\n",
        "\n",
        "    # Compute metrics\n",
        "    metr = {}\n",
        "    metr['story_accuracy'] = accuracy_score(stories, pred_stories)\n",
        "\n",
        "    conflicts_flat = [c for c_ex in conflicts for c_ent in c_ex for c in c_ent]\n",
        "    pred_conflicts_flat = [c for c_ex in pred_conflicts for c_ent in c_ex for c in c_ent]\n",
        "    metr['confl_f1'] = f1_score(conflicts_flat, pred_conflicts_flat, average='macro')\n",
        "\n",
        "    preconditions_flat = [p for p_ex in preconditions for p_story in p_ex for p_sent in p_story for p_ent in p_sent for p in p_ent]\n",
        "    pred_preconditions_flat = [p for p_ex in pred_preconditions for p_story in p_ex for p_sent in p_story for p_ent in p_sent for p in p_ent]\n",
        "    metr['precondition_f1'] = f1_score(preconditions_flat, pred_preconditions_flat, average='macro')\n",
        "\n",
        "    effects_flat = [p for p_ex in effects for p_story in p_ex for p_sent in p_story for p_ent in p_sent for p in p_ent]\n",
        "    pred_effects_flat = [p for p_ex in pred_effects for p_story in p_ex for p_sent in p_story for p_ent in p_sent for p in p_ent]\n",
        "    metr['effect_f1'] = f1_score(effects_flat, pred_effects_flat, average='macro')\n",
        "\n",
        "    metr['verifiability'] = np.mean(verifiability)\n",
        "    metr['consistency'] = np.mean(consistency)\n",
        "\n",
        "    for k in metr:\n",
        "      if k not in metr_avg:\n",
        "        metr_avg[k] = []\n",
        "      metr_avg[k].append(metr[k])\n",
        "\n",
        "  for k in metr_avg:\n",
        "    metr_avg[k] = (np.mean(metr_avg[k]), np.var(metr_avg[k]) ** 0.5)\n",
        "  print('RANDOM BASELINE (%s, %s runs)' % (str(p), str(num_runs)))\n",
        "  print_dict(metr_avg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ctQweSlAceo"
      },
      "source": [
        "## Transformer-Based Tiered Classifier for TRIP\n",
        "\n",
        "This is the baseline model presented in the paper. Based on the settings above, the below cells can be used for training and evaluating models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q-xjfYU_cV8"
      },
      "source": [
        "### Featurization for Tiered Classification\n",
        "\n",
        "Get the data ready for input to the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLCJXeMb_cV9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "901e7756-488d-451a-a2d1-b7e62e371b09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n",
            "[========================================================================] \u001b[38;2;0;255;0m100%\u001b[39m\n",
            "[========================================================================] \u001b[38;2;0;255;0m100%\u001b[39m\n",
            "[========================================================================] \u001b[38;2;0;255;0m100%\u001b[39m\n"
          ]
        }
      ],
      "source": [
        "from www.dataset.prepro import get_tiered_data, balance_labels\n",
        "from www.dataset.featurize import add_bert_features_tiered, get_tensor_dataset_tiered\n",
        "from collections import Counter\n",
        "\n",
        "tiered_dataset = cloze_dataset_2s\n",
        "\n",
        "# Debug the code on a small amount of data\n",
        "if debug:\n",
        "  for k in tiered_dataset:\n",
        "    tiered_dataset[k] = tiered_dataset[k][:20]\n",
        "\n",
        "# train_spans = True\n",
        "train_spans = False\n",
        "if train_spans:\n",
        "  tiered_dataset = get_story_spans_2s(tiered_dataset, train_only=True)\n",
        "  tiered_dataset['train'] = [ex for ex in tiered_dataset['train'] if ex['label'] != -1] # For now, ignore examples where both stories are plausible :(\n",
        "\n",
        "seq_length = 16 # Max sequence length to pad to\n",
        "\n",
        "tiered_dataset = get_tiered_data(tiered_dataset)\n",
        "tiered_dataset = add_bert_features_tiered(tiered_dataset, tokenizer, seq_length, add_segment_ids=True)\n",
        "\n",
        "tiered_tensor_dataset = {}\n",
        "max_story_length = max([len(ex['stories'][0]['sentences']) for p in tiered_dataset for ex in tiered_dataset[p]])\n",
        "for p in tiered_dataset:\n",
        "  tiered_tensor_dataset[p] = get_tensor_dataset_tiered(tiered_dataset[p], max_story_length, add_segment_ids=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fQ6wXQIBdq1"
      },
      "source": [
        "### Train Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-BMInyrBdq2"
      },
      "source": [
        "#### Configure Hyperparameters\n",
        "We will perform grid search over (batch size, learning rate). Configure the training sub-task, search space and set the maximum number of training epochs here. Currently configured for re-training the best RoBERTa-based model instance. Read code comments for more information.\n",
        "\n",
        "**Additional configuration options:**\n",
        "* Change the `generate_learning_curve` variable to `True` to generate data for training curves in the style presented in the paper.\n",
        "* You may ablate the input to the Conflict Detector based on a few pre-defined ablation modes. To do so, change the `ablation` variable based on the comments in the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvfTuEYRBdq3"
      },
      "outputs": [],
      "source": [
        "from www.dataset.ann import att_to_idx, att_to_num_classes, att_types\n",
        "\n",
        "subtask = 'cloze'\n",
        "batch_sizes = [config_batch_size]\n",
        "learning_rates = [config_lr]\n",
        "epochs = config_epochs\n",
        "eval_batch_size = 16\n",
        "generate_learning_curve = False # Generate data for training curve figure in TRIP paper\n",
        "\n",
        "num_state_labels = {}\n",
        "for att in att_to_idx:\n",
        "  if att_types[att] == 'default':\n",
        "    num_state_labels[att_to_idx[att]] = 3\n",
        "  else:\n",
        "    num_state_labels[att_to_idx[att]] = att_to_num_classes[att] # Location attributes fall into this since they don't have well-define pre- and post-condition yet\n",
        "\n",
        "# Ablation options:\n",
        "# - attributes: skip attribute prediction phase\n",
        "# - embeddings: DON'T input contextual embeddings to conflict detector\n",
        "# - states: DON'T input states to conflict detector\n",
        "# - states-labels: in states input to conflict detector, include predicted labels\n",
        "# - states-logits: in states input to conflict detector, include state logits (preferred)\n",
        "# - states-teacher-forcing: train conflict detector on ground truth state labels (not predictions)\n",
        "# - states-attention: re-weight input to conflict detector with weights conditioned on states representation\n",
        "ablation = ['attributes', 'states-logits'] # This is the default mode presented in the paper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fRC3cnLBdq3"
      },
      "source": [
        "#### Perform Grid Search\n",
        "\n",
        "Perform hyperparameter tuning to find the best story classification model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWnCen7NBdq3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a49de701-6b0d-460f-bf20-0615eec13092"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beginning grid search for the cloze sub-task over 1 parameter combination(s)!\n",
            "\n",
            "TRAINING MODEL: bs=1, lr=1e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "\r[                                                                        ] \u001b[38;2;255;0;0m  0%\u001b[39m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0] Beginning epoch...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] \u001b[38;2;0;255;0m100%\u001b[39m\n",
            "[                                                                        ] \u001b[38;2;255;0;0m  0%\u001b[39m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] \u001b[38;2;0;255;0m100%\u001b[39m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:19s.\n",
            "[0] Validation results:\n",
            "[0] Preconditions:\n",
            "{\n",
            "  accuracy: \n",
            "    0.8232755802549853,\n",
            "  f1: \n",
            "    0.1128466488542583,\n",
            "  accuracy_0: \n",
            "    0.9829542801102135,\n",
            "  f1_0: \n",
            "    0.33146514889048057,\n",
            "  accuracy_1: \n",
            "    0.8079087470228365,\n",
            "  f1_1: \n",
            "    0.37758815636317083,\n",
            "  accuracy_2: \n",
            "    0.7506538084341288,\n",
            "  f1_2: \n",
            "    0.28702255793398224,\n",
            "  accuracy_3: \n",
            "    0.7399009947228319,\n",
            "  f1_3: \n",
            "    0.284868232888907,\n",
            "  accuracy_4: \n",
            "    0.9519100546397049,\n",
            "  f1_4: \n",
            "    0.32544580154246777,\n",
            "  accuracy_5: \n",
            "    0.7107364685004437,\n",
            "  f1_5: \n",
            "    0.09939173096007103,\n",
            "  accuracy_6: \n",
            "    0.9036099565684398,\n",
            "  f1_6: \n",
            "    0.3205410191891603,\n",
            "  accuracy_7: \n",
            "    0.7347289030028488,\n",
            "  f1_7: \n",
            "    0.28461943149039093,\n",
            "  accuracy_8: \n",
            "    0.9847289030028488,\n",
            "  f1_8: \n",
            "    0.3446153975098211,\n",
            "  accuracy_9: \n",
            "    0.700859291084855,\n",
            "  f1_9: \n",
            "    0.30542070620995915,\n",
            "  accuracy_10: \n",
            "    0.9950147106897679,\n",
            "  f1_10: \n",
            "    0.3325003755137711,\n",
            "  accuracy_11: \n",
            "    0.7010344183439966,\n",
            "  f1_11: \n",
            "    0.2796313109828401,\n",
            "  accuracy_12: \n",
            "    0.7028090412366319,\n",
            "  f1_12: \n",
            "    0.29140618579330835,\n",
            "  accuracy_13: \n",
            "    0.9940806986410125,\n",
            "  f1_13: \n",
            "    0.3323438545954164,\n",
            "  accuracy_14: \n",
            "    0.6966095362630178,\n",
            "  f1_14: \n",
            "    0.28175411563495184,\n",
            "  accuracy_15: \n",
            "    0.8380072852939803,\n",
            "  f1_15: \n",
            "    0.3154369185331886,\n",
            "  accuracy_16: \n",
            "    0.6985592864147947,\n",
            "  f1_16: \n",
            "    0.2860884242081591,\n",
            "  accuracy_17: \n",
            "    0.9284546770653341,\n",
            "  f1_17: \n",
            "    0.3623523705231894,\n",
            "  accuracy_18: \n",
            "    0.9472166440947088,\n",
            "  f1_18: \n",
            "    0.32429764024710755,\n",
            "  accuracy_19: \n",
            "    0.6957338999673096,\n",
            "  f1_19: \n",
            "    0.27826159318979066,\n",
            "}\n",
            "\n",
            "\n",
            "[0] Effects:\n",
            "{\n",
            "  accuracy: \n",
            "    0.7694829075795078,\n",
            "  f1: \n",
            "    0.11395715720861031,\n",
            "  accuracy_0: \n",
            "    0.9802222948676038,\n",
            "  f1_0: \n",
            "    0.39077668893928313,\n",
            "  accuracy_1: \n",
            "    0.6991430439452669,\n",
            "  f1_1: \n",
            "    0.32730886108023716,\n",
            "  accuracy_2: \n",
            "    0.9875075888478961,\n",
            "  f1_2: \n",
            "    0.3312537450213246,\n",
            "  accuracy_3: \n",
            "    0.7670106944379582,\n",
            "  f1_3: \n",
            "    0.2925227942081536,\n",
            "  accuracy_4: \n",
            "    0.701968430392752,\n",
            "  f1_4: \n",
            "    0.2751030063439554,\n",
            "  accuracy_5: \n",
            "    0.694402932797833,\n",
            "  f1_5: \n",
            "    0.09972892175463323,\n",
            "  accuracy_6: \n",
            "    0.7642086582916919,\n",
            "  f1_6: \n",
            "    0.4152825643062444,\n",
            "  accuracy_7: \n",
            "    0.801172185121188,\n",
            "  f1_7: \n",
            "    0.2976151855737214,\n",
            "  accuracy_8: \n",
            "    0.7521599028627469,\n",
            "  f1_8: \n",
            "    0.30444754556105263,\n",
            "  accuracy_9: \n",
            "    0.7804137673375987,\n",
            "  f1_9: \n",
            "    0.4059066635660395,\n",
            "  accuracy_10: \n",
            "    0.6962125811422968,\n",
            "  f1_10: \n",
            "    0.2924523035601551,\n",
            "  accuracy_11: \n",
            "    0.7401461728856302,\n",
            "  f1_11: \n",
            "    0.28729507601103066,\n",
            "  accuracy_12: \n",
            "    0.6962943071965628,\n",
            "  f1_12: \n",
            "    0.28229197516950394,\n",
            "  accuracy_13: \n",
            "    0.8099869238313174,\n",
            "  f1_13: \n",
            "    0.30774408459406655,\n",
            "  accuracy_14: \n",
            "    0.6993648718068463,\n",
            "  f1_14: \n",
            "    0.2796011230306713,\n",
            "  accuracy_15: \n",
            "    0.9313150889646477,\n",
            "  f1_15: \n",
            "    0.342021809111416,\n",
            "  accuracy_16: \n",
            "    0.7182085648904871,\n",
            "  f1_16: \n",
            "    0.29405806112312116,\n",
            "  accuracy_17: \n",
            "    0.7828188483631439,\n",
            "  f1_17: \n",
            "    0.29839121550617376,\n",
            "  accuracy_18: \n",
            "    0.6930019147247,\n",
            "  f1_18: \n",
            "    0.27302060407021805,\n",
            "  accuracy_19: \n",
            "    0.6940993788819876,\n",
            "  f1_19: \n",
            "    0.27627158071606417,\n",
            "}\n",
            "\n",
            "\n",
            "[0] Conflicts:\n",
            "{\n",
            "  accuracy: \n",
            "    0.9428151123149489,\n",
            "  f1: \n",
            "    0.5558635265700483,\n",
            "}\n",
            "\n",
            "\n",
            "[0] Stories:\n",
            "{\n",
            "  accuracy: \n",
            "    0.6428571428571429,\n",
            "  f1: \n",
            "    0.6428261393778636,\n",
            "  verifiability: \n",
            "    0.0,\n",
            "}\n",
            "\n",
            "\n",
            "[0] Saving model checkpoint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[                                                                        ] \u001b[38;2;255;0;0m  0%\u001b[39m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0] Finished epoch.\n",
            "[1] Beginning epoch...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] \u001b[38;2;0;255;0m100%\u001b[39m\n",
            "[                                                                        ] \u001b[38;2;255;0;0m  0%\u001b[39m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] \u001b[38;2;0;255;0m100%\u001b[39m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:19s.\n",
            "[1] Validation results:\n",
            "[1] Preconditions:\n",
            "{\n",
            "  accuracy: \n",
            "    0.7982930929808995,\n",
            "  f1: \n",
            "    0.11385266543491707,\n",
            "  accuracy_0: \n",
            "    0.900714519217298,\n",
            "  f1_0: \n",
            "    0.3163799919880985,\n",
            "  accuracy_1: \n",
            "    0.7468010087330127,\n",
            "  f1_1: \n",
            "    0.3282644485658342,\n",
            "  accuracy_2: \n",
            "    0.767267547751366,\n",
            "  f1_2: \n",
            "    0.28962642310748493,\n",
            "  accuracy_3: \n",
            "    0.7073039742212675,\n",
            "  f1_3: \n",
            "    0.27696512162239656,\n",
            "  accuracy_4: \n",
            "    0.9647643954607015,\n",
            "  f1_4: \n",
            "    0.3277997171414649,\n",
            "  accuracy_5: \n",
            "    0.7172278522392939,\n",
            "  f1_5: \n",
            "    0.10037549128655852,\n",
            "  accuracy_6: \n",
            "    0.8037290431046561,\n",
            "  f1_6: \n",
            "    0.4055222383797635,\n",
            "  accuracy_7: \n",
            "    0.7080862093121001,\n",
            "  f1_7: \n",
            "    0.2791877313628394,\n",
            "  accuracy_8: \n",
            "    0.9886400784570121,\n",
            "  f1_8: \n",
            "    0.3385092273218902,\n",
            "  accuracy_9: \n",
            "    0.7707467426329799,\n",
            "  f1_9: \n",
            "    0.37001819328975644,\n",
            "  accuracy_10: \n",
            "    0.9714425816093027,\n",
            "  f1_10: \n",
            "    0.3337315250873763,\n",
            "  accuracy_11: \n",
            "    0.7173212534441694,\n",
            "  f1_11: \n",
            "    0.2838115468969001,\n",
            "  accuracy_12: \n",
            "    0.7146826694064353,\n",
            "  f1_12: \n",
            "    0.29243773192251976,\n",
            "  accuracy_13: \n",
            "    0.7777518329986457,\n",
            "  f1_13: \n",
            "    0.29446362841635865,\n",
            "  accuracy_14: \n",
            "    0.7228903002848737,\n",
            "  f1_14: \n",
            "    0.28711333620915636,\n",
            "  accuracy_15: \n",
            "    0.7162121141362724,\n",
            "  f1_15: \n",
            "    0.29358602637315645,\n",
            "  accuracy_16: \n",
            "    0.7138887591649933,\n",
            "  f1_16: \n",
            "    0.2905140345480332,\n",
            "  accuracy_17: \n",
            "    0.9376430205949656,\n",
            "  f1_17: \n",
            "    0.35775982544708246,\n",
            "  accuracy_18: \n",
            "    0.89417643487601,\n",
            "  f1_18: \n",
            "    0.3147145962515974,\n",
            "  accuracy_19: \n",
            "    0.7245715219726334,\n",
            "  f1_19: \n",
            "    0.28390164509045884,\n",
            "}\n",
            "\n",
            "\n",
            "[1] Effects:\n",
            "{\n",
            "  accuracy: \n",
            "    0.7658239153785084,\n",
            "  f1: \n",
            "    0.11041436512889687,\n",
            "  accuracy_0: \n",
            "    0.7927310512305609,\n",
            "  f1_0: \n",
            "    0.31377824689848316,\n",
            "  accuracy_1: \n",
            "    0.7025288376220054,\n",
            "  f1_1: \n",
            "    0.3542854974770935,\n",
            "  accuracy_2: \n",
            "    0.8253747723345631,\n",
            "  f1_2: \n",
            "    0.30363036091140533,\n",
            "  accuracy_3: \n",
            "    0.744384252556858,\n",
            "  f1_3: \n",
            "    0.2874455173593953,\n",
            "  accuracy_4: \n",
            "    0.7310045299584365,\n",
            "  f1_4: \n",
            "    0.2819317807413518,\n",
            "  accuracy_5: \n",
            "    0.694741512165507,\n",
            "  f1_5: \n",
            "    0.09876405432124019,\n",
            "  accuracy_6: \n",
            "    0.7601807313314342,\n",
            "  f1_6: \n",
            "    0.42491336257849843,\n",
            "  accuracy_7: \n",
            "    0.7992341101200205,\n",
            "  f1_7: \n",
            "    0.2996657130564316,\n",
            "  accuracy_8: \n",
            "    0.7525685331340775,\n",
            "  f1_8: \n",
            "    0.3026867808923128,\n",
            "  accuracy_9: \n",
            "    0.7395157147527203,\n",
            "  f1_9: \n",
            "    0.38124519547179214,\n",
            "  accuracy_10: \n",
            "    0.7311212814645309,\n",
            "  f1_10: \n",
            "    0.30855237929024265,\n",
            "  accuracy_11: \n",
            "    0.8147620604305795,\n",
            "  f1_11: \n",
            "    0.3027538079236812,\n",
            "  accuracy_12: \n",
            "    0.7122308877784523,\n",
            "  f1_12: \n",
            "    0.2846697101050371,\n",
            "  accuracy_13: \n",
            "    0.9123779946761313,\n",
            "  f1_13: \n",
            "    0.3200631841631863,\n",
            "  accuracy_14: \n",
            "    0.7282958950170457,\n",
            "  f1_14: \n",
            "    0.28998080733968756,\n",
            "  accuracy_15: \n",
            "    0.9289333582403213,\n",
            "  f1_15: \n",
            "    0.33922151179388077,\n",
            "  accuracy_16: \n",
            "    0.766847242329426,\n",
            "  f1_16: \n",
            "    0.2970863629386624,\n",
            "  accuracy_17: \n",
            "    0.7567248867510391,\n",
            "  f1_17: \n",
            "    0.2950950950607257,\n",
            "  accuracy_18: \n",
            "    0.7265679727268481,\n",
            "  f1_18: \n",
            "    0.28287747843721717,\n",
            "  accuracy_19: \n",
            "    0.6963526829496101,\n",
            "  f1_19: \n",
            "    0.27671327882503066,\n",
            "}\n",
            "\n",
            "\n",
            "[1] Conflicts:\n",
            "{\n",
            "  accuracy: \n",
            "    0.9365572315882875,\n",
            "  f1: \n",
            "    0.6113432904638438,\n",
            "}\n",
            "\n",
            "\n",
            "[1] Stories:\n",
            "{\n",
            "  accuracy: \n",
            "    0.7267080745341615,\n",
            "  f1: \n",
            "    0.7266975308641975,\n",
            "  verifiability: \n",
            "    0.0,\n",
            "}\n",
            "\n",
            "\n",
            "[1] Saving model checkpoint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[                                                                        ] \u001b[38;2;255;0;0m  0%\u001b[39m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] Finished epoch.\n",
            "[2] Beginning epoch...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] \u001b[38;2;0;255;0m100%\u001b[39m\n",
            "[                                                                        ] \u001b[38;2;255;0;0m  0%\u001b[39m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] \u001b[38;2;0;255;0m100%\u001b[39m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:19s.\n",
            "[2] Validation results:\n",
            "[2] Preconditions:\n",
            "{\n",
            "  accuracy: \n",
            "    0.8007372857609864,\n",
            "  f1: \n",
            "    0.11482257604747763,\n",
            "  accuracy_0: \n",
            "    0.8988348199691776,\n",
            "  f1_0: \n",
            "    0.3156168584260358,\n",
            "  accuracy_1: \n",
            "    0.7746579180871433,\n",
            "  f1_1: \n",
            "    0.3340779042681061,\n",
            "  accuracy_2: \n",
            "    0.7515994956334937,\n",
            "  f1_2: \n",
            "    0.28637372115591436,\n",
            "  accuracy_3: \n",
            "    0.707187222715173,\n",
            "  f1_3: \n",
            "    0.2868415063242818,\n",
            "  accuracy_4: \n",
            "    0.9684303927520665,\n",
            "  f1_4: \n",
            "    0.32798734677738234,\n",
            "  accuracy_5: \n",
            "    0.6970998925886144,\n",
            "  f1_5: \n",
            "    0.10249207123767155,\n",
            "  accuracy_6: \n",
            "    0.8065777798533601,\n",
            "  f1_6: \n",
            "    0.40543511077801025,\n",
            "  accuracy_7: \n",
            "    0.7397608929155186,\n",
            "  f1_7: \n",
            "    0.28746247466913083,\n",
            "  accuracy_8: \n",
            "    0.9569303694017652,\n",
            "  f1_8: \n",
            "    0.375009503927924,\n",
            "  accuracy_9: \n",
            "    0.7731634988091346,\n",
            "  f1_9: \n",
            "    0.3898785636287528,\n",
            "  accuracy_10: \n",
            "    0.9809344790547798,\n",
            "  f1_10: \n",
            "    0.3317445701456812,\n",
            "  accuracy_11: \n",
            "    0.7539111754541633,\n",
            "  f1_11: \n",
            "    0.2918978672630976,\n",
            "  accuracy_12: \n",
            "    0.7066384906365292,\n",
            "  f1_12: \n",
            "    0.2914242303762509,\n",
            "  accuracy_13: \n",
            "    0.8242539578760566,\n",
            "  f1_13: \n",
            "    0.3016241636629806,\n",
            "  accuracy_14: \n",
            "    0.7155933311539718,\n",
            "  f1_14: \n",
            "    0.2841515995400226,\n",
            "  accuracy_15: \n",
            "    0.7035095502731985,\n",
            "  f1_15: \n",
            "    0.2912550867159722,\n",
            "  accuracy_16: \n",
            "    0.7288679773969085,\n",
            "  f1_16: \n",
            "    0.2962195028754954,\n",
            "  accuracy_17: \n",
            "    0.9226404520618317,\n",
            "  f1_17: \n",
            "    0.3632148350259259,\n",
            "  accuracy_18: \n",
            "    0.8945266893942931,\n",
            "  f1_18: \n",
            "    0.31477966491647563,\n",
            "  accuracy_19: \n",
            "    0.7096273291925466,\n",
            "  f1_19: \n",
            "    0.28123718394395697,\n",
            "}\n",
            "\n",
            "\n",
            "[2] Effects:\n",
            "{\n",
            "  accuracy: \n",
            "    0.7711693830850418,\n",
            "  f1: \n",
            "    0.11289808971521562,\n",
            "  accuracy_0: \n",
            "    0.9601176855181431,\n",
            "  f1_0: \n",
            "    0.38295303867140973,\n",
            "  accuracy_1: \n",
            "    0.7028323915378508,\n",
            "  f1_1: \n",
            "    0.3529149673087006,\n",
            "  accuracy_2: \n",
            "    0.8794890954093307,\n",
            "  f1_2: \n",
            "    0.31527370456757137,\n",
            "  accuracy_3: \n",
            "    0.7456334936720683,\n",
            "  f1_3: \n",
            "    0.29014021279581026,\n",
            "  accuracy_4: \n",
            "    0.716387241395414,\n",
            "  f1_4: \n",
            "    0.27840353539822005,\n",
            "  accuracy_5: \n",
            "    0.6961775556904684,\n",
            "  f1_5: \n",
            "    0.09931587936671077,\n",
            "  accuracy_6: \n",
            "    0.7645589128099752,\n",
            "  f1_6: \n",
            "    0.4146414946810031,\n",
            "  accuracy_7: \n",
            "    0.7656330266660439,\n",
            "  f1_7: \n",
            "    0.2911270036414372,\n",
            "  accuracy_8: \n",
            "    0.7450263858403774,\n",
            "  f1_8: \n",
            "    0.30161410995927646,\n",
            "  accuracy_9: \n",
            "    0.7577523000046701,\n",
            "  f1_9: \n",
            "    0.4078336187673317,\n",
            "  accuracy_10: \n",
            "    0.7118923084107786,\n",
            "  f1_10: \n",
            "    0.3057957976964269,\n",
            "  accuracy_11: \n",
            "    0.728354270770093,\n",
            "  f1_11: \n",
            "    0.2848212399204933,\n",
            "  accuracy_12: \n",
            "    0.7014196983141082,\n",
            "  f1_12: \n",
            "    0.28335170536910775,\n",
            "  accuracy_13: \n",
            "    0.8277798533601084,\n",
            "  f1_13: \n",
            "    0.3068329474955712,\n",
            "  accuracy_14: \n",
            "    0.7472913650586093,\n",
            "  f1_14: \n",
            "    0.29193708813691127,\n",
            "  accuracy_15: \n",
            "    0.9367323588474291,\n",
            "  f1_15: \n",
            "    0.3382342420747421,\n",
            "  accuracy_16: \n",
            "    0.7408583570728062,\n",
            "  f1_16: \n",
            "    0.2924332262556548,\n",
            "  accuracy_17: \n",
            "    0.8930205949656751,\n",
            "  f1_17: \n",
            "    0.31757288308709525,\n",
            "  accuracy_18: \n",
            "    0.7044669126231728,\n",
            "  f1_18: \n",
            "    0.2758533426489388,\n",
            "  accuracy_19: \n",
            "    0.6979638537337132,\n",
            "  f1_19: \n",
            "    0.2772276758463876,\n",
            "}\n",
            "\n",
            "\n",
            "[2] Conflicts:\n",
            "{\n",
            "  accuracy: \n",
            "    0.9545019380750012,\n",
            "  f1: \n",
            "    0.6339110912089809,\n",
            "}\n",
            "\n",
            "\n",
            "[2] Stories:\n",
            "{\n",
            "  accuracy: \n",
            "    0.7298136645962733,\n",
            "  f1: \n",
            "    0.7297485023008132,\n",
            "  verifiability: \n",
            "    0.0,\n",
            "}\n",
            "\n",
            "\n",
            "[2] Saving model checkpoint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[                                                                        ] \u001b[38;2;255;0;0m  0%\u001b[39m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2] Finished epoch.\n",
            "[3] Beginning epoch...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] \u001b[38;2;0;255;0m100%\u001b[39m\n",
            "[                                                                        ] \u001b[38;2;255;0;0m  0%\u001b[39m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] \u001b[38;2;0;255;0m100%\u001b[39m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:19s.\n",
            "[3] Validation results:\n",
            "[3] Preconditions:\n",
            "{\n",
            "  accuracy: \n",
            "    0.8006999252790361,\n",
            "  f1: \n",
            "    0.11687476662953161,\n",
            "  accuracy_0: \n",
            "    0.877492644655116,\n",
            "  f1_0: \n",
            "    0.3129499885121592,\n",
            "  accuracy_1: \n",
            "    0.7922290197543548,\n",
            "  f1_1: \n",
            "    0.3094922986294301,\n",
            "  accuracy_2: \n",
            "    0.7326624013449774,\n",
            "  f1_2: \n",
            "    0.28241716567126224,\n",
            "  accuracy_3: \n",
            "    0.6999019287348807,\n",
            "  f1_3: \n",
            "    0.27632590407944196,\n",
            "  accuracy_4: \n",
            "    0.9643907906411993,\n",
            "  f1_4: \n",
            "    0.3272908816432299,\n",
            "  accuracy_5: \n",
            "    0.6955470975575585,\n",
            "  f1_5: \n",
            "    0.10503287023948106,\n",
            "  accuracy_6: \n",
            "    0.8132326157007426,\n",
            "  f1_6: \n",
            "    0.3951049890238143,\n",
            "  accuracy_7: \n",
            "    0.7296268621865222,\n",
            "  f1_7: \n",
            "    0.2847281212485327,\n",
            "  accuracy_8: \n",
            "    0.9705319198617662,\n",
            "  f1_8: \n",
            "    0.4106194678573733,\n",
            "  accuracy_9: \n",
            "    0.7385350021015271,\n",
            "  f1_9: \n",
            "    0.358882988380638,\n",
            "  accuracy_10: \n",
            "    0.9819969177602391,\n",
            "  f1_10: \n",
            "    0.33128625966024067,\n",
            "  accuracy_11: \n",
            "    0.7605309858497175,\n",
            "  f1_11: \n",
            "    0.29229311846891887,\n",
            "  accuracy_12: \n",
            "    0.7034978751225891,\n",
            "  f1_12: \n",
            "    0.28973746197668404,\n",
            "  accuracy_13: \n",
            "    0.8570261056367627,\n",
            "  f1_13: \n",
            "    0.3077335848661112,\n",
            "  accuracy_14: \n",
            "    0.7180801382337832,\n",
            "  f1_14: \n",
            "    0.2866661780377288,\n",
            "  accuracy_15: \n",
            "    0.7068486433474992,\n",
            "  f1_15: \n",
            "    0.29370647271751166,\n",
            "  accuracy_16: \n",
            "    0.7055060010274132,\n",
            "  f1_16: \n",
            "    0.2907351107422013,\n",
            "  accuracy_17: \n",
            "    0.9259445196843039,\n",
            "  f1_17: \n",
            "    0.3774488454215921,\n",
            "  accuracy_18: \n",
            "    0.9031312753934526,\n",
            "  f1_18: \n",
            "    0.31700484228555004,\n",
            "  accuracy_19: \n",
            "    0.7372857609863167,\n",
            "  f1_19: \n",
            "    0.2871881246320229,\n",
            "}\n",
            "\n",
            "\n",
            "[3] Effects:\n",
            "{\n",
            "  accuracy: \n",
            "    0.7691215616681455,\n",
            "  f1: \n",
            "    0.1125820229144164,\n",
            "  accuracy_0: \n",
            "    0.9545136132256106,\n",
            "  f1_0: \n",
            "    0.38833209889777837,\n",
            "  accuracy_1: \n",
            "    0.6984425349087003,\n",
            "  f1_1: \n",
            "    0.326131164983711,\n",
            "  accuracy_2: \n",
            "    0.8420001868024097,\n",
            "  f1_2: \n",
            "    0.3072235671782058,\n",
            "  accuracy_3: \n",
            "    0.740297949843553,\n",
            "  f1_3: \n",
            "    0.28646132583852396,\n",
            "  accuracy_4: \n",
            "    0.7109349460608042,\n",
            "  f1_4: \n",
            "    0.2773668297570417,\n",
            "  accuracy_5: \n",
            "    0.6951968430392752,\n",
            "  f1_5: \n",
            "    0.09927724491095664,\n",
            "  accuracy_6: \n",
            "    0.7513309671694764,\n",
            "  f1_6: \n",
            "    0.3972713911398888,\n",
            "  accuracy_7: \n",
            "    0.7561177789193481,\n",
            "  f1_7: \n",
            "    0.28879011764330764,\n",
            "  accuracy_8: \n",
            "    0.7386867790594499,\n",
            "  f1_8: \n",
            "    0.30531791295107774,\n",
            "  accuracy_9: \n",
            "    0.7688203427824218,\n",
            "  f1_9: \n",
            "    0.4308984197922467,\n",
            "  accuracy_10: \n",
            "    0.7316116377901275,\n",
            "  f1_10: \n",
            "    0.30694559890623496,\n",
            "  accuracy_11: \n",
            "    0.7199248120300752,\n",
            "  f1_11: \n",
            "    0.2830859350276031,\n",
            "  accuracy_12: \n",
            "    0.6968080138233783,\n",
            "  f1_12: \n",
            "    0.28255898345935104,\n",
            "  accuracy_13: \n",
            "    0.8351351982440574,\n",
            "  f1_13: \n",
            "    0.316236292810612,\n",
            "  accuracy_14: \n",
            "    0.8386143931256713,\n",
            "  f1_14: \n",
            "    0.30991303998575326,\n",
            "  accuracy_15: \n",
            "    0.9392775416802877,\n",
            "  f1_15: \n",
            "    0.34183874220624993,\n",
            "  accuracy_16: \n",
            "    0.7353476859851492,\n",
            "  f1_16: \n",
            "    0.2954323105682451,\n",
            "  accuracy_17: \n",
            "    0.8368864708354737,\n",
            "  f1_17: \n",
            "    0.3063555922448971,\n",
            "  accuracy_18: \n",
            "    0.6972866949983655,\n",
            "  f1_18: \n",
            "    0.2740148376529531,\n",
            "  accuracy_19: \n",
            "    0.6951968430392752,\n",
            "  f1_19: \n",
            "    0.2765437598133972,\n",
            "}\n",
            "\n",
            "\n",
            "[3] Conflicts:\n",
            "{\n",
            "  accuracy: \n",
            "    0.9463293326483911,\n",
            "  f1: \n",
            "    0.6500353216197372,\n",
            "}\n",
            "\n",
            "\n",
            "[3] Stories:\n",
            "{\n",
            "  accuracy: \n",
            "    0.7298136645962733,\n",
            "  f1: \n",
            "    0.7296859169199594,\n",
            "  verifiability: \n",
            "    0.0,\n",
            "}\n",
            "\n",
            "\n",
            "[3] Saving model checkpoint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[                                                                        ] \u001b[38;2;255;0;0m  0%\u001b[39m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3] Finished epoch.\n",
            "[4] Beginning epoch...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] \u001b[38;2;0;255;0m100%\u001b[39m\n",
            "[                                                                        ] \u001b[38;2;255;0;0m  0%\u001b[39m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] \u001b[38;2;0;255;0m100%\u001b[39m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:19s.\n",
            "[4] Validation results:\n",
            "[4] Preconditions:\n",
            "{\n",
            "  accuracy: \n",
            "    0.8005843412880026,\n",
            "  f1: \n",
            "    0.11800927455575468,\n",
            "  accuracy_0: \n",
            "    0.8544575725026853,\n",
            "  f1_0: \n",
            "    0.3125520541061099,\n",
            "  accuracy_1: \n",
            "    0.8071498622332228,\n",
            "  f1_1: \n",
            "    0.37850531872714904,\n",
            "  accuracy_2: \n",
            "    0.7281441180591229,\n",
            "  f1_2: \n",
            "    0.2823669292036914,\n",
            "  accuracy_3: \n",
            "    0.6997384766263485,\n",
            "  f1_3: \n",
            "    0.28299393244408894,\n",
            "  accuracy_4: \n",
            "    0.9579577826553962,\n",
            "  f1_4: \n",
            "    0.3261758386353653,\n",
            "  accuracy_5: \n",
            "    0.6972750198477561,\n",
            "  f1_5: \n",
            "    0.10302596620788798,\n",
            "  accuracy_6: \n",
            "    0.8165483584738243,\n",
            "  f1_6: \n",
            "    0.39417087106402643,\n",
            "  accuracy_7: \n",
            "    0.7199248120300752,\n",
            "  f1_7: \n",
            "    0.2824000295225562,\n",
            "  accuracy_8: \n",
            "    0.9474501471068977,\n",
            "  f1_8: \n",
            "    0.39581376679238084,\n",
            "  accuracy_9: \n",
            "    0.7496614206323261,\n",
            "  f1_9: \n",
            "    0.36252656316707266,\n",
            "  accuracy_10: \n",
            "    0.9746182225750712,\n",
            "  f1_10: \n",
            "    0.3307217896937025,\n",
            "  accuracy_11: \n",
            "    0.7632629710923271,\n",
            "  f1_11: \n",
            "    0.29198215134230837,\n",
            "  accuracy_12: \n",
            "    0.7219446130855088,\n",
            "  f1_12: \n",
            "    0.2945131975463379,\n",
            "  accuracy_13: \n",
            "    0.8319128566758511,\n",
            "  f1_13: \n",
            "    0.30451018221424164,\n",
            "  accuracy_14: \n",
            "    0.7213842058562555,\n",
            "  f1_14: \n",
            "    0.2867831721300642,\n",
            "  accuracy_15: \n",
            "    0.703626301779293,\n",
            "  f1_15: \n",
            "    0.2917448492805404,\n",
            "  accuracy_16: \n",
            "    0.7190141502825387,\n",
            "  f1_16: \n",
            "    0.2979376094187623,\n",
            "  accuracy_17: \n",
            "    0.9185774996497454,\n",
            "  f1_17: \n",
            "    0.37256069023186655,\n",
            "  accuracy_18: \n",
            "    0.9181104936253678,\n",
            "  f1_18: \n",
            "    0.319970388395903,\n",
            "  accuracy_19: \n",
            "    0.7609279409704385,\n",
            "  f1_19: \n",
            "    0.2928581117592442,\n",
            "}\n",
            "\n",
            "\n",
            "[4] Effects:\n",
            "{\n",
            "  accuracy: \n",
            "    0.7678367113435763,\n",
            "  f1: \n",
            "    0.1100945323322779,\n",
            "  accuracy_0: \n",
            "    0.8864941857749965,\n",
            "  f1_0: \n",
            "    0.3364972808382378,\n",
            "  accuracy_1: \n",
            "    0.7051207210573016,\n",
            "  f1_1: \n",
            "    0.35861450229002473,\n",
            "  accuracy_2: \n",
            "    0.8182412553121935,\n",
            "  f1_2: \n",
            "    0.3022082637235413,\n",
            "  accuracy_3: \n",
            "    0.7534441694297856,\n",
            "  f1_3: \n",
            "    0.2920414750138745,\n",
            "  accuracy_4: \n",
            "    0.7204501938075001,\n",
            "  f1_4: \n",
            "    0.2799152814367773,\n",
            "  accuracy_5: \n",
            "    0.6972049689440993,\n",
            "  f1_5: \n",
            "    0.09801827528465913,\n",
            "  accuracy_6: \n",
            "    0.759515247746696,\n",
            "  f1_6: \n",
            "    0.37826357083588685,\n",
            "  accuracy_7: \n",
            "    0.7428197823751926,\n",
            "  f1_7: \n",
            "    0.28576541877307804,\n",
            "  accuracy_8: \n",
            "    0.7577990006071078,\n",
            "  f1_8: \n",
            "    0.30836062532069536,\n",
            "  accuracy_9: \n",
            "    0.7611614439826274,\n",
            "  f1_9: \n",
            "    0.45173200635698324,\n",
            "  accuracy_10: \n",
            "    0.7661000326904217,\n",
            "  f1_10: \n",
            "    0.31609225675342006,\n",
            "  accuracy_11: \n",
            "    0.7458553215336478,\n",
            "  f1_11: \n",
            "    0.2886146956059969,\n",
            "  accuracy_12: \n",
            "    0.7014897492177649,\n",
            "  f1_12: \n",
            "    0.2862946144855933,\n",
            "  accuracy_13: \n",
            "    0.8190234904030262,\n",
            "  f1_13: \n",
            "    0.31684786487631955,\n",
            "  accuracy_14: \n",
            "    0.7871269789380283,\n",
            "  f1_14: \n",
            "    0.3001884786854233,\n",
            "  accuracy_15: \n",
            "    0.9276490916732826,\n",
            "  f1_15: \n",
            "    0.3395857891508503,\n",
            "  accuracy_16: \n",
            "    0.7228669499836547,\n",
            "  f1_16: \n",
            "    0.2855216033055094,\n",
            "  accuracy_17: \n",
            "    0.8719702984168496,\n",
            "  f1_17: \n",
            "    0.31304035590726303,\n",
            "  accuracy_18: \n",
            "    0.7146943445570448,\n",
            "  f1_18: \n",
            "    0.2779953815028508,\n",
            "  accuracy_19: \n",
            "    0.6977070004203054,\n",
            "  f1_19: \n",
            "    0.2770747298191866,\n",
            "}\n",
            "\n",
            "\n",
            "[4] Conflicts:\n",
            "{\n",
            "  accuracy: \n",
            "    0.9474151216550694,\n",
            "  f1: \n",
            "    0.6584072065014367,\n",
            "}\n",
            "\n",
            "\n",
            "[4] Stories:\n",
            "{\n",
            "  accuracy: \n",
            "    0.7732919254658385,\n",
            "  f1: \n",
            "    0.7732897389157336,\n",
            "  verifiability: \n",
            "    0.0,\n",
            "}\n",
            "\n",
            "\n",
            "[4] Saving model checkpoint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[                                                                        ] \u001b[38;2;255;0;0m  0%\u001b[39m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4] Finished epoch.\n",
            "[5] Beginning epoch...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] \u001b[38;2;0;255;0m100%\u001b[39m\n",
            "[                                                                        ] \u001b[38;2;255;0;0m  0%\u001b[39m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] \u001b[38;2;0;255;0m100%\u001b[39m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:19s.\n",
            "[5] Validation results:\n",
            "[5] Preconditions:\n",
            "{\n",
            "  accuracy: \n",
            "    0.7991050997057862,\n",
            "  f1: \n",
            "    0.1235768362404573,\n",
            "  accuracy_0: \n",
            "    0.8104072292532574,\n",
            "  f1_0: \n",
            "    0.31142443221187016,\n",
            "  accuracy_1: \n",
            "    0.8560687432867884,\n",
            "  f1_1: \n",
            "    0.390966860633393,\n",
            "  accuracy_2: \n",
            "    0.7407532807173213,\n",
            "  f1_2: \n",
            "    0.28507306875272137,\n",
            "  accuracy_3: \n",
            "    0.7135268294961005,\n",
            "  f1_3: \n",
            "    0.2781491306524625,\n",
            "  accuracy_4: \n",
            "    0.9438892261710176,\n",
            "  f1_4: \n",
            "    0.32371159613528894,\n",
            "  accuracy_5: \n",
            "    0.6963643581002195,\n",
            "  f1_5: \n",
            "    0.10973409096161903,\n",
            "  accuracy_6: \n",
            "    0.8276047261009667,\n",
            "  f1_6: \n",
            "    0.4094086944114341,\n",
            "  accuracy_7: \n",
            "    0.723952738990333,\n",
            "  f1_7: \n",
            "    0.28296713722709826,\n",
            "  accuracy_8: \n",
            "    0.9265166020641666,\n",
            "  f1_8: \n",
            "    0.3852804361355022,\n",
            "  accuracy_9: \n",
            "    0.7601573810302152,\n",
            "  f1_9: \n",
            "    0.3400948815795693,\n",
            "  accuracy_10: \n",
            "    0.9729837014897492,\n",
            "  f1_10: \n",
            "    0.3340764540003967,\n",
            "  accuracy_11: \n",
            "    0.74580862093121,\n",
            "  f1_11: \n",
            "    0.2879627546634526,\n",
            "  accuracy_12: \n",
            "    0.7396441414094241,\n",
            "  f1_12: \n",
            "    0.2975139660255565,\n",
            "  accuracy_13: \n",
            "    0.811107738289824,\n",
            "  f1_13: \n",
            "    0.30079286120912363,\n",
            "  accuracy_14: \n",
            "    0.7367837295101107,\n",
            "  f1_14: \n",
            "    0.28946042425120766,\n",
            "  accuracy_15: \n",
            "    0.7011511698500911,\n",
            "  f1_15: \n",
            "    0.2903950667854443,\n",
            "  accuracy_16: \n",
            "    0.7401461728856302,\n",
            "  f1_16: \n",
            "    0.3046390183252467,\n",
            "  accuracy_17: \n",
            "    0.8965231401485079,\n",
            "  f1_17: \n",
            "    0.34968319692016614,\n",
            "  accuracy_18: \n",
            "    0.8503946200905992,\n",
            "  f1_18: \n",
            "    0.30683378676167994,\n",
            "  accuracy_19: \n",
            "    0.7883178443001915,\n",
            "  f1_19: \n",
            "    0.2995903173193947,\n",
            "}\n",
            "\n",
            "\n",
            "[5] Effects:\n",
            "{\n",
            "  accuracy: \n",
            "    0.7834930883108392,\n",
            "  f1: \n",
            "    0.11176671097130411,\n",
            "  accuracy_0: \n",
            "    0.9164409470882174,\n",
            "  f1_0: \n",
            "    0.3421974694534881,\n",
            "  accuracy_1: \n",
            "    0.7093004249754822,\n",
            "  f1_1: \n",
            "    0.3668625032042798,\n",
            "  accuracy_2: \n",
            "    0.8489002008125904,\n",
            "  f1_2: \n",
            "    0.30879182921489345,\n",
            "  accuracy_3: \n",
            "    0.7704665390183534,\n",
            "  f1_3: \n",
            "    0.2930860343717942,\n",
            "  accuracy_4: \n",
            "    0.742119273338626,\n",
            "  f1_4: \n",
            "    0.28587543149381084,\n",
            "  accuracy_5: \n",
            "    0.6963526829496101,\n",
            "  f1_5: \n",
            "    0.09632090350184187,\n",
            "  accuracy_6: \n",
            "    0.8076635688600383,\n",
            "  f1_6: \n",
            "    0.3704193023006213,\n",
            "  accuracy_7: \n",
            "    0.7450730864428151,\n",
            "  f1_7: \n",
            "    0.28706229632888375,\n",
            "  accuracy_8: \n",
            "    0.7996777658431794,\n",
            "  f1_8: \n",
            "    0.3245659682426326,\n",
            "  accuracy_9: \n",
            "    0.7700812590482418,\n",
            "  f1_9: \n",
            "    0.491186544295416,\n",
            "  accuracy_10: \n",
            "    0.8059006211180124,\n",
            "  f1_10: \n",
            "    0.3200224608413846,\n",
            "  accuracy_11: \n",
            "    0.7574370709382151,\n",
            "  f1_11: \n",
            "    0.29316899391544843,\n",
            "  accuracy_12: \n",
            "    0.7029024424415075,\n",
            "  f1_12: \n",
            "    0.2911134331788077,\n",
            "  accuracy_13: \n",
            "    0.8399803857469761,\n",
            "  f1_13: \n",
            "    0.3250822136556189,\n",
            "  accuracy_14: \n",
            "    0.8406225190304955,\n",
            "  f1_14: \n",
            "    0.3096469234999177,\n",
            "  accuracy_15: \n",
            "    0.9006444683136412,\n",
            "  f1_15: \n",
            "    0.34238946755471694,\n",
            "  accuracy_16: \n",
            "    0.7477700462335964,\n",
            "  f1_16: \n",
            "    0.29271620442583207,\n",
            "  accuracy_17: \n",
            "    0.8322397608929155,\n",
            "  f1_17: \n",
            "    0.3069480163366937,\n",
            "  accuracy_18: \n",
            "    0.7358146920095269,\n",
            "  f1_18: \n",
            "    0.28273420992422915,\n",
            "  accuracy_19: \n",
            "    0.7004740111147434,\n",
            "  f1_19: \n",
            "    0.2777474791823563,\n",
            "}\n",
            "\n",
            "\n",
            "[5] Conflicts:\n",
            "{\n",
            "  accuracy: \n",
            "    0.9530892448512586,\n",
            "  f1: \n",
            "    0.6716417666650161,\n",
            "}\n",
            "\n",
            "\n",
            "[5] Stories:\n",
            "{\n",
            "  accuracy: \n",
            "    0.7795031055900621,\n",
            "  f1: \n",
            "    0.7795009789454395,\n",
            "  verifiability: \n",
            "    0.0,\n",
            "}\n",
            "\n",
            "\n",
            "[5] Saving model checkpoint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[                                                                        ] \u001b[38;2;255;0;0m  0%\u001b[39m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5] Finished epoch.\n",
            "[6] Beginning epoch...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] \u001b[38;2;0;255;0m100%\u001b[39m\n",
            "[                                                                        ] \u001b[38;2;255;0;0m  0%\u001b[39m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] \u001b[38;2;0;255;0m100%\u001b[39m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:19s.\n",
            "[6] Validation results:\n",
            "[6] Preconditions:\n",
            "{\n",
            "  accuracy: \n",
            "    0.803342011861953,\n",
            "  f1: \n",
            "    0.11916385302808637,\n",
            "  accuracy_0: \n",
            "    0.8084341288002616,\n",
            "  f1_0: \n",
            "    0.3043514564848375,\n",
            "  accuracy_1: \n",
            "    0.8304184373978424,\n",
            "  f1_1: \n",
            "    0.3877216984167026,\n",
            "  accuracy_2: \n",
            "    0.7445243543641713,\n",
            "  f1_2: \n",
            "    0.28638677851107186,\n",
            "  accuracy_3: \n",
            "    0.7116004296455424,\n",
            "  f1_3: \n",
            "    0.28190724834396413,\n",
            "  accuracy_4: \n",
            "    0.9418227245131462,\n",
            "  f1_4: \n",
            "    0.32365198082896274,\n",
            "  accuracy_5: \n",
            "    0.6966212114136272,\n",
            "  f1_5: \n",
            "    0.10883503542949437,\n",
            "  accuracy_6: \n",
            "    0.819385420071919,\n",
            "  f1_6: \n",
            "    0.37720279742343327,\n",
            "  accuracy_7: \n",
            "    0.7405548031569608,\n",
            "  f1_7: \n",
            "    0.28721304845607437,\n",
            "  accuracy_8: \n",
            "    0.9300658478494372,\n",
            "  f1_8: \n",
            "    0.38823609941879217,\n",
            "  accuracy_9: \n",
            "    0.7697310045299585,\n",
            "  f1_9: \n",
            "    0.3075899794750209,\n",
            "  accuracy_10: \n",
            "    0.9749684770933545,\n",
            "  f1_10: \n",
            "    0.3363950661555968,\n",
            "  accuracy_11: \n",
            "    0.7695792275720357,\n",
            "  f1_11: \n",
            "    0.29122359928837244,\n",
            "  accuracy_12: \n",
            "    0.7285644234810629,\n",
            "  f1_12: \n",
            "    0.2943075846562146,\n",
            "  accuracy_13: \n",
            "    0.8520758417783589,\n",
            "  f1_13: \n",
            "    0.3070244503506094,\n",
            "  accuracy_14: \n",
            "    0.7495213188250128,\n",
            "  f1_14: \n",
            "    0.29192204619670054,\n",
            "  accuracy_15: \n",
            "    0.7025872133750526,\n",
            "  f1_15: \n",
            "    0.2897181199538988,\n",
            "  accuracy_16: \n",
            "    0.722528370615981,\n",
            "  f1_16: \n",
            "    0.3018222219154498,\n",
            "  accuracy_17: \n",
            "    0.9013099518983795,\n",
            "  f1_17: \n",
            "    0.3837511805265779,\n",
            "  accuracy_18: \n",
            "    0.9150866296175221,\n",
            "  f1_18: \n",
            "    0.3185710859925294,\n",
            "  accuracy_19: \n",
            "    0.757460421239434,\n",
            "  f1_19: \n",
            "    0.29300009344786443,\n",
            "}\n",
            "\n",
            "\n",
            "[6] Effects:\n",
            "{\n",
            "  accuracy: \n",
            "    0.7646990146172885,\n",
            "  f1: \n",
            "    0.11045159795203455,\n",
            "  accuracy_0: \n",
            "    0.8720286741698968,\n",
            "  f1_0: \n",
            "    0.3348213758792073,\n",
            "  accuracy_1: \n",
            "    0.7017699528323915,\n",
            "  f1_1: \n",
            "    0.3374725502144355,\n",
            "  accuracy_2: \n",
            "    0.7913884089104749,\n",
            "  f1_2: \n",
            "    0.2960544268181521,\n",
            "  accuracy_3: \n",
            "    0.7590132162704899,\n",
            "  f1_3: \n",
            "    0.2899819962112285,\n",
            "  accuracy_4: \n",
            "    0.7132116004296455,\n",
            "  f1_4: \n",
            "    0.27992218776912164,\n",
            "  accuracy_5: \n",
            "    0.6952902442441508,\n",
            "  f1_5: \n",
            "    0.09491448453919184,\n",
            "  accuracy_6: \n",
            "    0.7614649978984729,\n",
            "  f1_6: \n",
            "    0.35963372884618733,\n",
            "  accuracy_7: \n",
            "    0.7467426329799655,\n",
            "  f1_7: \n",
            "    0.28727482757079414,\n",
            "  accuracy_8: \n",
            "    0.7634380983514687,\n",
            "  f1_8: \n",
            "    0.316517964918093,\n",
            "  accuracy_9: \n",
            "    0.7810792509223369,\n",
            "  f1_9: \n",
            "    0.48497681986513425,\n",
            "  accuracy_10: \n",
            "    0.7536659972913651,\n",
            "  f1_10: \n",
            "    0.30982491722196137,\n",
            "  accuracy_11: \n",
            "    0.7581842805772194,\n",
            "  f1_11: \n",
            "    0.2990543672940222,\n",
            "  accuracy_12: \n",
            "    0.7006141129220567,\n",
            "  f1_12: \n",
            "    0.29051644627296863,\n",
            "  accuracy_13: \n",
            "    0.8018610190071452,\n",
            "  f1_13: \n",
            "    0.3117176956499641,\n",
            "  accuracy_14: \n",
            "    0.8039625461168449,\n",
            "  f1_14: \n",
            "    0.3045494337084777,\n",
            "  accuracy_15: \n",
            "    0.9185774996497454,\n",
            "  f1_15: \n",
            "    0.33588708565947495,\n",
            "  accuracy_16: \n",
            "    0.7277004623359641,\n",
            "  f1_16: \n",
            "    0.2925047415980249,\n",
            "  accuracy_17: \n",
            "    0.8329869705319198,\n",
            "  f1_17: \n",
            "    0.30619454265701634,\n",
            "  accuracy_18: \n",
            "    0.7122542380796713,\n",
            "  f1_18: \n",
            "    0.27744881345448924,\n",
            "  accuracy_19: \n",
            "    0.6987460888245458,\n",
            "  f1_19: \n",
            "    0.27740921722451783,\n",
            "}\n",
            "\n",
            "\n",
            "[6] Conflicts:\n",
            "{\n",
            "  accuracy: \n",
            "    0.9420095269228973,\n",
            "  f1: \n",
            "    0.6662911042770074,\n",
            "}\n",
            "\n",
            "\n",
            "[6] Stories:\n",
            "{\n",
            "  accuracy: \n",
            "    0.7763975155279503,\n",
            "  f1: \n",
            "    0.7763888888888889,\n",
            "  verifiability: \n",
            "    0.0,\n",
            "}\n",
            "\n",
            "\n",
            "[6] Saving model checkpoint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[                                                                        ] \u001b[38;2;255;0;0m  0%\u001b[39m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6] Finished epoch.\n",
            "[7] Beginning epoch...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] \u001b[38;2;0;255;0m100%\u001b[39m\n",
            "[                                                                        ] \u001b[38;2;255;0;0m  0%\u001b[39m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] \u001b[38;2;0;255;0m100%\u001b[39m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:19s.\n",
            "[7] Validation results:\n",
            "[7] Preconditions:\n",
            "{\n",
            "  accuracy: \n",
            "    0.8027273151823658,\n",
            "  f1: \n",
            "    0.1169160324352112,\n",
            "  accuracy_0: \n",
            "    0.7719142576939243,\n",
            "  f1_0: \n",
            "    0.3006379427606094,\n",
            "  accuracy_1: \n",
            "    0.8219189277541681,\n",
            "  f1_1: \n",
            "    0.38293890105498013,\n",
            "  accuracy_2: \n",
            "    0.7364918507448746,\n",
            "  f1_2: \n",
            "    0.283899135283968,\n",
            "  accuracy_3: \n",
            "    0.724664923177509,\n",
            "  f1_3: \n",
            "    0.2902983589907975,\n",
            "  accuracy_4: \n",
            "    0.9505557371690094,\n",
            "  f1_4: \n",
            "    0.32488761993691156,\n",
            "  accuracy_5: \n",
            "    0.6980105543361509,\n",
            "  f1_5: \n",
            "    0.10354500002034091,\n",
            "  accuracy_6: \n",
            "    0.8064026525942185,\n",
            "  f1_6: \n",
            "    0.40916882474269173,\n",
            "  accuracy_7: \n",
            "    0.7425979545136132,\n",
            "  f1_7: \n",
            "    0.2881455767165368,\n",
            "  accuracy_8: \n",
            "    0.9298089945360295,\n",
            "  f1_8: \n",
            "    0.3879154824879934,\n",
            "  accuracy_9: \n",
            "    0.7885396721617709,\n",
            "  f1_9: \n",
            "    0.3135845391098299,\n",
            "  accuracy_10: \n",
            "    0.960141035819362,\n",
            "  f1_10: \n",
            "    0.3425455821170107,\n",
            "  accuracy_11: \n",
            "    0.7734787278755896,\n",
            "  f1_11: \n",
            "    0.2940742208943522,\n",
            "  accuracy_12: \n",
            "    0.735896418063793,\n",
            "  f1_12: \n",
            "    0.29799317495268446,\n",
            "  accuracy_13: \n",
            "    0.8270910194741512,\n",
            "  f1_13: \n",
            "    0.30557976410064486,\n",
            "  accuracy_14: \n",
            "    0.7631228692850138,\n",
            "  f1_14: \n",
            "    0.29509160836802883,\n",
            "  accuracy_15: \n",
            "    0.6987927894269836,\n",
            "  f1_15: \n",
            "    0.2911064777858049,\n",
            "  accuracy_16: \n",
            "    0.7293233082706767,\n",
            "  f1_16: \n",
            "    0.3047706813632575,\n",
            "  accuracy_17: \n",
            "    0.9190211553729043,\n",
            "  f1_17: \n",
            "    0.3525737280090678,\n",
            "  accuracy_18: \n",
            "    0.8930439452668939,\n",
            "  f1_18: \n",
            "    0.3145350809560524,\n",
            "  accuracy_19: \n",
            "    0.7837295101106805,\n",
            "  f1_19: \n",
            "    0.3003868243224129,\n",
            "}\n",
            "\n",
            "\n",
            "[7] Effects:\n",
            "{\n",
            "  accuracy: \n",
            "    0.780113715966936,\n",
            "  f1: \n",
            "    0.11431376208969384,\n",
            "  accuracy_0: \n",
            "    0.9021505627422594,\n",
            "  f1_0: \n",
            "    0.33794772956399727,\n",
            "  accuracy_1: \n",
            "    0.7005440620184,\n",
            "  f1_1: \n",
            "    0.33293879221355466,\n",
            "  accuracy_2: \n",
            "    0.8517022369588567,\n",
            "  f1_2: \n",
            "    0.3085002757186063,\n",
            "  accuracy_3: \n",
            "    0.7491126885536823,\n",
            "  f1_3: \n",
            "    0.28835405461275065,\n",
            "  accuracy_4: \n",
            "    0.738745154812497,\n",
            "  f1_4: \n",
            "    0.28730072245611205,\n",
            "  accuracy_5: \n",
            "    0.7010110680427778,\n",
            "  f1_5: \n",
            "    0.09710379886091919,\n",
            "  accuracy_6: \n",
            "    0.8041960491290338,\n",
            "  f1_6: \n",
            "    0.3646342338891449,\n",
            "  accuracy_7: \n",
            "    0.736608602250969,\n",
            "  f1_7: \n",
            "    0.28484346109104397,\n",
            "  accuracy_8: \n",
            "    0.7835777331527577,\n",
            "  f1_8: \n",
            "    0.3224894627094325,\n",
            "  accuracy_9: \n",
            "    0.7693690748610658,\n",
            "  f1_9: \n",
            "    0.47820238062299847,\n",
            "  accuracy_10: \n",
            "    0.8474174566851912,\n",
            "  f1_10: \n",
            "    0.3320306414817471,\n",
            "  accuracy_11: \n",
            "    0.7351258581235698,\n",
            "  f1_11: \n",
            "    0.29600386039704185,\n",
            "  accuracy_12: \n",
            "    0.7016532013262972,\n",
            "  f1_12: \n",
            "    0.2919785597644951,\n",
            "  accuracy_13: \n",
            "    0.8374118526128987,\n",
            "  f1_13: \n",
            "    0.324047905142774,\n",
            "  accuracy_14: \n",
            "    0.8153574931116612,\n",
            "  f1_14: \n",
            "    0.3077814335867706,\n",
            "  accuracy_15: \n",
            "    0.8968850698174007,\n",
            "  f1_15: \n",
            "    0.3375472613988732,\n",
            "  accuracy_16: \n",
            "    0.7540162518096484,\n",
            "  f1_16: \n",
            "    0.2910643861949986,\n",
            "  accuracy_17: \n",
            "    0.7982767477700462,\n",
            "  f1_17: \n",
            "    0.30257497816911244,\n",
            "  accuracy_18: \n",
            "    0.7779152851071779,\n",
            "  f1_18: \n",
            "    0.2918298163088324,\n",
            "  accuracy_19: \n",
            "    0.7011978704525288,\n",
            "  f1_19: \n",
            "    0.2779035382844991,\n",
            "}\n",
            "\n",
            "\n",
            "[7] Conflicts:\n",
            "{\n",
            "  accuracy: \n",
            "    0.9537197029841685,\n",
            "  f1: \n",
            "    0.668729399676989,\n",
            "}\n",
            "\n",
            "\n",
            "[7] Stories:\n",
            "{\n",
            "  accuracy: \n",
            "    0.7391304347826086,\n",
            "  f1: \n",
            "    0.7388785912882299,\n",
            "  verifiability: \n",
            "    0.0,\n",
            "}\n",
            "\n",
            "\n",
            "[7] Saving model checkpoint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[                                                                        ] \u001b[38;2;255;0;0m  0%\u001b[39m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7] Finished epoch.\n",
            "[8] Beginning epoch...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] \u001b[38;2;0;255;0m100%\u001b[39m\n",
            "[                                                                        ] \u001b[38;2;255;0;0m  0%\u001b[39m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] \u001b[38;2;0;255;0m100%\u001b[39m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:19s.\n",
            "[8] Validation results:\n",
            "[8] Preconditions:\n",
            "{\n",
            "  accuracy: \n",
            "    0.802839980385747,\n",
            "  f1: \n",
            "    0.11682915424146387,\n",
            "  accuracy_0: \n",
            "    0.7605893616027647,\n",
            "  f1_0: \n",
            "    0.29599521444019433,\n",
            "  accuracy_1: \n",
            "    0.8061457992808108,\n",
            "  f1_1: \n",
            "    0.3799669913544219,\n",
            "  accuracy_2: \n",
            "    0.7463456778592444,\n",
            "  f1_2: \n",
            "    0.2854865199092129,\n",
            "  accuracy_3: \n",
            "    0.7216410591696633,\n",
            "  f1_3: \n",
            "    0.2802657661925707,\n",
            "  accuracy_4: \n",
            "    0.9392775416802877,\n",
            "  f1_4: \n",
            "    0.3228960343883012,\n",
            "  accuracy_5: \n",
            "    0.7025054873207864,\n",
            "  f1_5: \n",
            "    0.10167461920845605,\n",
            "  accuracy_6: \n",
            "    0.8012655863260636,\n",
            "  f1_6: \n",
            "    0.39556943924543403,\n",
            "  accuracy_7: \n",
            "    0.7413136879465745,\n",
            "  f1_7: \n",
            "    0.2918001992269265,\n",
            "  accuracy_8: \n",
            "    0.9301709242049222,\n",
            "  f1_8: \n",
            "    0.3882330667307929,\n",
            "  accuracy_9: \n",
            "    0.7714355765189371,\n",
            "  f1_9: \n",
            "    0.312393924403985,\n",
            "  accuracy_10: \n",
            "    0.960479615187036,\n",
            "  f1_10: \n",
            "    0.3421505369797834,\n",
            "  accuracy_11: \n",
            "    0.7887147994209125,\n",
            "  f1_11: \n",
            "    0.295271749239562,\n",
            "  accuracy_12: \n",
            "    0.7398192686685658,\n",
            "  f1_12: \n",
            "    0.29832214271966256,\n",
            "  accuracy_13: \n",
            "    0.8446854714425817,\n",
            "  f1_13: \n",
            "    0.3098574250052241,\n",
            "  accuracy_14: \n",
            "    0.7590599168729276,\n",
            "  f1_14: \n",
            "    0.29517443910858504,\n",
            "  accuracy_15: \n",
            "    0.6994232475598935,\n",
            "  f1_15: \n",
            "    0.29009446583992526,\n",
            "  accuracy_16: \n",
            "    0.7407532807173213,\n",
            "  f1_16: \n",
            "    0.30702656314845816,\n",
            "  accuracy_17: \n",
            "    0.9150983047681315,\n",
            "  f1_17: \n",
            "    0.34324555522736233,\n",
            "  accuracy_18: \n",
            "    0.8930322701162845,\n",
            "  f1_18: \n",
            "    0.31454454985463265,\n",
            "  accuracy_19: \n",
            "    0.7950427310512306,\n",
            "  f1_19: \n",
            "    0.30301341785702746,\n",
            "}\n",
            "\n",
            "\n",
            "[8] Effects:\n",
            "{\n",
            "  accuracy: \n",
            "    0.7792287395507402,\n",
            "  f1: \n",
            "    0.11464212762036882,\n",
            "  accuracy_0: \n",
            "    0.8867160136365759,\n",
            "  f1_0: \n",
            "    0.32967524634773376,\n",
            "  accuracy_1: \n",
            "    0.7004273105123056,\n",
            "  f1_1: \n",
            "    0.33232434250410964,\n",
            "  accuracy_2: \n",
            "    0.831118946434409,\n",
            "  f1_2: \n",
            "    0.3044092806567195,\n",
            "  accuracy_3: \n",
            "    0.7415238406575445,\n",
            "  f1_3: \n",
            "    0.28617930551021525,\n",
            "  accuracy_4: \n",
            "    0.7508756362957082,\n",
            "  f1_4: \n",
            "    0.2892286857314585,\n",
            "  accuracy_5: \n",
            "    0.6991897445477047,\n",
            "  f1_5: \n",
            "    0.09844010824340982,\n",
            "  accuracy_6: \n",
            "    0.7989305562041751,\n",
            "  f1_6: \n",
            "    0.35149098668159273,\n",
            "  accuracy_7: \n",
            "    0.7435202914117592,\n",
            "  f1_7: \n",
            "    0.2875699798597611,\n",
            "  accuracy_8: \n",
            "    0.7768528464017186,\n",
            "  f1_8: \n",
            "    0.3196837510942158,\n",
            "  accuracy_9: \n",
            "    0.7697660299817868,\n",
            "  f1_9: \n",
            "    0.48013460168587724,\n",
            "  accuracy_10: \n",
            "    0.851865689067389,\n",
            "  f1_10: \n",
            "    0.33104125387613587,\n",
            "  accuracy_11: \n",
            "    0.7725680661280531,\n",
            "  f1_11: \n",
            "    0.3080177190733729,\n",
            "  accuracy_12: \n",
            "    0.7019100546397049,\n",
            "  f1_12: \n",
            "    0.2931781344335223,\n",
            "  accuracy_13: \n",
            "    0.8214752720310092,\n",
            "  f1_13: \n",
            "    0.3164817098277091,\n",
            "  accuracy_14: \n",
            "    0.8101153504880213,\n",
            "  f1_14: \n",
            "    0.30973976833402783,\n",
            "  accuracy_15: \n",
            "    0.8883038341194601,\n",
            "  f1_15: \n",
            "    0.3384819018107923,\n",
            "  accuracy_16: \n",
            "    0.7560360528650819,\n",
            "  f1_16: \n",
            "    0.29979555722538115,\n",
            "  accuracy_17: \n",
            "    0.8138747489842619,\n",
            "  f1_17: \n",
            "    0.3032206037545177,\n",
            "  accuracy_18: \n",
            "    0.7686101900714519,\n",
            "  f1_18: \n",
            "    0.2898567953417209,\n",
            "  accuracy_19: \n",
            "    0.7008943165366833,\n",
            "  f1_19: \n",
            "    0.2793620871800258,\n",
            "}\n",
            "\n",
            "\n",
            "[8] Conflicts:\n",
            "{\n",
            "  accuracy: \n",
            "    0.9540582823518423,\n",
            "  f1: \n",
            "    0.6803108363965895,\n",
            "}\n",
            "\n",
            "\n",
            "[8] Stories:\n",
            "{\n",
            "  accuracy: \n",
            "    0.7267080745341615,\n",
            "  f1: \n",
            "    0.7263279891829245,\n",
            "  verifiability: \n",
            "    0.0,\n",
            "}\n",
            "\n",
            "\n",
            "[8] Saving model checkpoint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[                                                                        ] \u001b[38;2;255;0;0m  0%\u001b[39m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8] Finished epoch.\n",
            "[9] Beginning epoch...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] \u001b[38;2;0;255;0m100%\u001b[39m\n",
            "[                                                                        ] \u001b[38;2;255;0;0m  0%\u001b[39m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] \u001b[38;2;0;255;0m100%\u001b[39m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:19s.\n",
            "[9] Validation results:\n",
            "[9] Preconditions:\n",
            "{\n",
            "  accuracy: \n",
            "    0.803351935739971,\n",
            "  f1: \n",
            "    0.11548227467254321,\n",
            "  accuracy_0: \n",
            "    0.7752883762200532,\n",
            "  f1_0: \n",
            "    0.3012040811995493,\n",
            "  accuracy_1: \n",
            "    0.818252930462803,\n",
            "  f1_1: \n",
            "    0.38258214506588245,\n",
            "  accuracy_2: \n",
            "    0.7532223415682062,\n",
            "  f1_2: \n",
            "    0.28741954041762946,\n",
            "  accuracy_3: \n",
            "    0.7701046093494606,\n",
            "  f1_3: \n",
            "    0.29223581940766763,\n",
            "  accuracy_4: \n",
            "    0.9300775230000466,\n",
            "  f1_4: \n",
            "    0.3215326443176793,\n",
            "  accuracy_5: \n",
            "    0.7016882267781255,\n",
            "  f1_5: \n",
            "    0.10175325575986885,\n",
            "  accuracy_6: \n",
            "    0.8020711717181152,\n",
            "  f1_6: \n",
            "    0.41806780597596527,\n",
            "  accuracy_7: \n",
            "    0.7649091673282585,\n",
            "  f1_7: \n",
            "    0.29325037575414176,\n",
            "  accuracy_8: \n",
            "    0.9257110166721151,\n",
            "  f1_8: \n",
            "    0.382139879145194,\n",
            "  accuracy_9: \n",
            "    0.7556507728949703,\n",
            "  f1_9: \n",
            "    0.306343588387882,\n",
            "  accuracy_10: \n",
            "    0.9488978657824686,\n",
            "  f1_10: \n",
            "    0.331278721309111,\n",
            "  accuracy_11: \n",
            "    0.7869401765282772,\n",
            "  f1_11: \n",
            "    0.29569964932557363,\n",
            "  accuracy_12: \n",
            "    0.7240227898939896,\n",
            "  f1_12: \n",
            "    0.2920852605394381,\n",
            "  accuracy_13: \n",
            "    0.864941857749965,\n",
            "  f1_13: \n",
            "    0.31370367940693394,\n",
            "  accuracy_14: \n",
            "    0.7582309811796573,\n",
            "  f1_14: \n",
            "    0.29581804463186884,\n",
            "  accuracy_15: \n",
            "    0.7000537056928035,\n",
            "  f1_15: \n",
            "    0.29008358872687484,\n",
            "  accuracy_16: \n",
            "    0.7539812263578201,\n",
            "  f1_16: \n",
            "    0.3079519467198877,\n",
            "  accuracy_17: \n",
            "    0.9064820436183627,\n",
            "  f1_17: \n",
            "    0.35094516765230055,\n",
            "  accuracy_18: \n",
            "    0.8355555036659973,\n",
            "  f1_18: \n",
            "    0.3035265178022351,\n",
            "  accuracy_19: \n",
            "    0.7909564283379256,\n",
            "  f1_19: \n",
            "    0.3016386906394238,\n",
            "}\n",
            "\n",
            "\n",
            "[9] Effects:\n",
            "{\n",
            "  accuracy: \n",
            "    0.7771143697753701,\n",
            "  f1: \n",
            "    0.11016333633368275,\n",
            "  accuracy_0: \n",
            "    0.8748657357679914,\n",
            "  f1_0: \n",
            "    0.33339815072867324,\n",
            "  accuracy_1: \n",
            "    0.7040349320506235,\n",
            "  f1_1: \n",
            "    0.33961183550001484,\n",
            "  accuracy_2: \n",
            "    0.8102204268435063,\n",
            "  f1_2: \n",
            "    0.30010184887217656,\n",
            "  accuracy_3: \n",
            "    0.7600523046747303,\n",
            "  f1_3: \n",
            "    0.2923777627106467,\n",
            "  accuracy_4: \n",
            "    0.7481786765049269,\n",
            "  f1_4: \n",
            "    0.28804544303325696,\n",
            "  accuracy_5: \n",
            "    0.7034278242189325,\n",
            "  f1_5: \n",
            "    0.09563241974252272,\n",
            "  accuracy_6: \n",
            "    0.8112828655489656,\n",
            "  f1_6: \n",
            "    0.3519257380489442,\n",
            "  accuracy_7: \n",
            "    0.7489025358427124,\n",
            "  f1_7: \n",
            "    0.2901837123693906,\n",
            "  accuracy_8: \n",
            "    0.7978097417456685,\n",
            "  f1_8: \n",
            "    0.33097951309561696,\n",
            "  accuracy_9: \n",
            "    0.7738289823938729,\n",
            "  f1_9: \n",
            "    0.4895414083472427,\n",
            "  accuracy_10: \n",
            "    0.835415401858684,\n",
            "  f1_10: \n",
            "    0.3212757706725015,\n",
            "  accuracy_11: \n",
            "    0.7772731518236585,\n",
            "  f1_11: \n",
            "    0.30357000135520423,\n",
            "  accuracy_12: \n",
            "    0.7028790921402887,\n",
            "  f1_12: \n",
            "    0.2920148128734564,\n",
            "  accuracy_13: \n",
            "    0.7945640498762434,\n",
            "  f1_13: \n",
            "    0.30750631401230927,\n",
            "  accuracy_14: \n",
            "    0.8278966048662028,\n",
            "  f1_14: \n",
            "    0.31175771118779183,\n",
            "  accuracy_15: \n",
            "    0.865654041937141,\n",
            "  f1_15: \n",
            "    0.33778418410792477,\n",
            "  accuracy_16: \n",
            "    0.75377107364685,\n",
            "  f1_16: \n",
            "    0.3054532954115049,\n",
            "  accuracy_17: \n",
            "    0.8101737262410685,\n",
            "  f1_17: \n",
            "    0.30306252098096537,\n",
            "  accuracy_18: \n",
            "    0.7354761126418531,\n",
            "  f1_18: \n",
            "    0.28265927207216907,\n",
            "  accuracy_19: \n",
            "    0.706580114883482,\n",
            "  f1_19: \n",
            "    0.2792866003077603,\n",
            "}\n",
            "\n",
            "\n",
            "[9] Conflicts:\n",
            "{\n",
            "  accuracy: \n",
            "    0.94740344650446,\n",
            "  f1: \n",
            "    0.6819063520786893,\n",
            "}\n",
            "\n",
            "\n",
            "[9] Stories:\n",
            "{\n",
            "  accuracy: \n",
            "    0.7515527950310559,\n",
            "  f1: \n",
            "    0.7515144499749199,\n",
            "  verifiability: \n",
            "    0.0,\n",
            "}\n",
            "\n",
            "\n",
            "[9] Saving model checkpoint...\n",
            "[9] Finished epoch.\n",
            "Finished grid search! :)\n",
            "Best validation *verifiability* 0.0 from model <none>.\n",
            "Best validation *accuracy* 0.7795031055900621 from model google-electra-base-discriminator_cloze_1_1e-05_5_0.0-0.0-0.0-0.5-0.5_tiered_pipeline_lc_ablate_attributes_states-logits.\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from www.model.train import train_epoch_tiered\n",
        "from www.model.eval import evaluate_tiered, save_results, save_preds, add_entity_attribute_labels\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from www.utils import print_dict, get_model_dir\n",
        "from www.model.transformers_ext import TieredModelPipeline\n",
        "from www.dataset.ann import att_to_num_classes\n",
        "import shutil\n",
        "import pandas as pd\n",
        "\n",
        "seed_val = 22 # Save random seed for reproducibility\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll keep the validation data here with a constant eval batch size\n",
        "dev_sampler = SequentialSampler(tiered_tensor_dataset['dev'])\n",
        "dev_dataloader = DataLoader(tiered_tensor_dataset['dev'], sampler=dev_sampler, batch_size=eval_batch_size)\n",
        "dev_dataset_name = subtask + '_%s_dev'\n",
        "dev_ids = [ex['example_id'] for ex in tiered_dataset['dev']]\n",
        "\n",
        "all_losses = []\n",
        "param_combos = []\n",
        "combo_names = []\n",
        "all_val_objs = []\n",
        "output_dirs = []\n",
        "best_obj = 0.0\n",
        "best_model = '<none>'\n",
        "best_dir = ''\n",
        "best_obj2 = 0.0\n",
        "best_model2 = '<none>'\n",
        "best_dir2 = ''\n",
        "\n",
        "print('Beginning grid search for the %s sub-task over %s parameter combination(s)!' % (subtask, str(len(batch_sizes) * len(learning_rates))))\n",
        "for bs in batch_sizes:\n",
        "  for lr in learning_rates:\n",
        "    print('\\nTRAINING MODEL: bs=%s, lr=%s' % (str(bs), str(lr)))\n",
        "\n",
        "    loss_values = []\n",
        "    obj_values = []\n",
        "\n",
        "    # Set up training dataset with new batch size\n",
        "    train_sampler = RandomSampler(tiered_tensor_dataset['train'])\n",
        "    train_dataloader = DataLoader(tiered_tensor_dataset['train'], sampler=train_sampler, batch_size=bs)\n",
        "\n",
        "    # Set up model\n",
        "    config = config_class.from_pretrained(model_name,\n",
        "                                          cache_dir=os.path.join(DRIVE_PATH, 'cache'))\n",
        "    emb = emb_class.from_pretrained(model_name,\n",
        "                                          config=config,\n",
        "                                          cache_dir=os.path.join(DRIVE_PATH, 'cache'))\n",
        "    if torch.cuda.is_available():\n",
        "      emb.cuda()\n",
        "    device = emb.device\n",
        "    max_story_length = max([len(ex['stories'][0]['sentences']) for p in tiered_dataset for ex in tiered_dataset[p]])\n",
        "    model = TieredModelPipeline(emb, max_story_length, len(att_to_num_classes), num_state_labels,\n",
        "                                config_class, model_name, device,\n",
        "                                ablation=ablation, loss_weights=loss_weights).to(device)\n",
        "\n",
        "    # Set up optimizer\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps = total_steps)\n",
        "\n",
        "    train_lc_data = []\n",
        "    val_lc_data = []\n",
        "    for epoch in range(epochs):\n",
        "      # Train the model for one epoch\n",
        "      print('[%s] Beginning epoch...' % str(epoch))\n",
        "\n",
        "      epoch_loss, _ = train_epoch_tiered(model, optimizer, train_dataloader, device, seg_mode=False,\n",
        "                                         build_learning_curves=generate_learning_curve, val_dataloader=dev_dataloader,\n",
        "                                         train_lc_data=train_lc_data, val_lc_data=val_lc_data)\n",
        "\n",
        "      # Save loss\n",
        "      loss_values.append(epoch_loss)\n",
        "\n",
        "      # Validate on dev set\n",
        "      validation_results = evaluate_tiered(model, dev_dataloader, device, [(accuracy_score, 'accuracy'), (f1_score, 'f1')], seg_mode=False, return_explanations=True)\n",
        "      metr_attr, all_pred_atts, all_atts, \\\n",
        "      metr_prec, all_pred_prec, all_prec, \\\n",
        "      metr_eff, all_pred_eff, all_eff, \\\n",
        "      metr_conflicts, all_pred_conflicts, all_conflicts, \\\n",
        "      metr_stories, all_pred_stories, all_stories, explanations = validation_results[:16]\n",
        "      explanations = add_entity_attribute_labels(explanations, tiered_dataset['dev'], list(att_to_num_classes.keys()))\n",
        "\n",
        "      print('[%s] Validation results:' % str(epoch))\n",
        "      print('[%s] Preconditions:' % str(epoch))\n",
        "      print_dict(metr_prec)\n",
        "      print('[%s] Effects:' % str(epoch))\n",
        "      print_dict(metr_eff)\n",
        "      print('[%s] Conflicts:' % str(epoch))\n",
        "      print_dict(metr_conflicts)\n",
        "      print('[%s] Stories:' % str(epoch))\n",
        "      print_dict(metr_stories)\n",
        "\n",
        "      # Save accuracy - want to maximize verifiability of tiered predictions\n",
        "      ver = metr_stories['verifiability']\n",
        "      acc = metr_stories['accuracy']\n",
        "      obj_values.append(ver)\n",
        "\n",
        "      # Save model checkpoint\n",
        "      print('[%s] Saving model checkpoint...' % str(epoch))\n",
        "      model_param_str = get_model_dir(model_name.replace('/', '-'), subtask, bs, lr, epoch) + '_' +  '-'.join([str(lw) for lw in loss_weights]) +  '_tiered_pipeline_lc'\n",
        "      if train_spans:\n",
        "        model_param_str += 'spans'\n",
        "      if len(model.ablation) > 0:\n",
        "        model_param_str += '_ablate_'\n",
        "        model_param_str += '_'.join(model.ablation)\n",
        "      output_dir = os.path.join(DRIVE_PATH, 'saved_models', model_param_str)\n",
        "      output_dirs.append(output_dir)\n",
        "      if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "      save_results(metr_attr, output_dir, dev_dataset_name % 'attributes')\n",
        "      save_results(metr_prec, output_dir, dev_dataset_name % 'preconditions')\n",
        "      save_results(metr_eff, output_dir, dev_dataset_name % 'effects')\n",
        "      save_results(metr_conflicts, output_dir, dev_dataset_name % 'conflicts')\n",
        "      save_results(metr_stories, output_dir, dev_dataset_name % 'stories')\n",
        "      save_results(explanations, output_dir, dev_dataset_name % 'explanations')\n",
        "\n",
        "      # Just save story preds\n",
        "      save_preds(dev_ids, all_stories, all_pred_stories, output_dir, dev_dataset_name % 'stories')\n",
        "\n",
        "      emb = emb.module if hasattr(emb, 'module') else emb\n",
        "      emb.save_pretrained(output_dir)\n",
        "      torch.save(model, os.path.join(output_dir, 'classifiers.pth'))\n",
        "      tokenizer.save_vocabulary(output_dir)\n",
        "\n",
        "      if ver > best_obj:\n",
        "        best_obj = ver\n",
        "        best_model = model_param_str\n",
        "        best_dir = output_dir\n",
        "      if acc > best_obj2:\n",
        "        best_obj2 = acc\n",
        "        best_model2 = model_param_str\n",
        "        best_dir2 = output_dir\n",
        "\n",
        "      for od in output_dirs:\n",
        "        if od != best_dir and od != best_dir2 and os.path.exists(od):\n",
        "          shutil.rmtree(od)\n",
        "\n",
        "      print('[%s] Finished epoch.' % str(epoch))\n",
        "\n",
        "    all_losses.append(loss_values)\n",
        "    all_val_objs.append(obj_values)\n",
        "    param_combos.append((bs, lr))\n",
        "    combo_names.append('bs=%s, lr=%s' % (str(bs), str(lr)))\n",
        "\n",
        "print('Finished grid search! :)')\n",
        "print('Best validation *verifiability* %s from model %s.' % (str(best_obj), best_model))\n",
        "print('Best validation *accuracy* %s from model %s.' % (str(best_obj2), best_model2))\n",
        "\n",
        "if generate_learning_curve:\n",
        "  print('Saving learning curve data...')\n",
        "  train_lc_data = [subrecord for record in train_lc_data for subrecord in record] # flatten\n",
        "  val_lc_data = [subrecord for record in val_lc_data for subrecord in record] # flatten\n",
        "\n",
        "  train_lc_data = pd.DataFrame(train_lc_data)\n",
        "  print(os.path.join(best_dir if best_dir != '<none>' else best_dir2, 'learning_curve_data_train.csv'))\n",
        "  train_lc_data.to_csv(os.path.join(best_dir if best_dir != '' else best_dir2, 'learning_curve_data_train.csv'), index=False)\n",
        "  val_lc_data = pd.DataFrame(val_lc_data)\n",
        "  val_lc_data.to_csv(os.path.join(best_dir if best_dir != '' else best_dir2, 'learning_curve_data_val.csv'), index=False)\n",
        "  print('Learning curve data saved. %s rows saved for training, %s rows saved for validation.' % (str(len(train_lc_data.index)), str(len(val_lc_data.index))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_jhT4gSBdq5"
      },
      "source": [
        "Delete all non-best model checkpoints:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7iILulEBdq6"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "# Delete non-best model checkpoints\n",
        "for od in output_dirs:\n",
        "  if od != best_dir and od != best_dir2 and os.path.exists(od):\n",
        "    shutil.rmtree(od)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWFmGRhznl2T"
      },
      "source": [
        "### Test Models\n",
        "\n",
        "Evaluate accuracy, consistency, and verifiability on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbvpm9irn3qL"
      },
      "source": [
        "#### Load the Trained Model\n",
        "\n",
        "Load the trained model we want to probe and select the appropriate dataset. Paths to the pre-trained models presented in the paper are already provided (download links are found in GitHub repo)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fM_lYqw9n3qM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a28c802-5369-40d0-9bb9-3328ca97be1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-104-03e6ec9d53d0>:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model = torch.load(os.path.join(probe_model, 'classifiers.pth'))\n"
          ]
        }
      ],
      "source": [
        "from www.model.transformers_ext import TieredModelPipeline\n",
        "from www.dataset.ann import att_to_num_classes, att_to_idx, att_types\n",
        "#'bert-large-uncased_cloze_1_5e-05_8_0.0-0.4-0.4-0.2-0.0_tiered_pipeline_ablate_attributes_states-logits'\n",
        "#probe_model = eval_model_dir\n",
        "#probe_model = os.path.join(DRIVE_PATH, 'saved_models', probe_model)\n",
        "probe_model = 'google-electra-base-discriminator_cloze_1_1e-05_5_0.0-0.0-0.0-0.5-0.5_tiered_pipeline_lc_ablate_attributes_states-logits'\n",
        "probe_model = os.path.join(DRIVE_PATH, 'saved_models', probe_model)\n",
        "\n",
        "ablation = ['attributes', 'states-logits']\n",
        "\n",
        "if 'cloze' in probe_model:\n",
        "  subtask = 'cloze'\n",
        "elif 'order' in probe_model:\n",
        "  subtask = 'order'\n",
        "\n",
        "if subtask == 'cloze':\n",
        "  subtask_dataset = cloze_dataset_2s\n",
        "elif subtask == 'order':\n",
        "  subtask_dataset = order_dataset_2s\n",
        "\n",
        "# Load the model\n",
        "model = None\n",
        "# model = torch.load(os.path.join(probe_model, 'classifiers.pth'), map_location=torch.device('cpu'))\n",
        "model = torch.load(os.path.join(probe_model, 'classifiers.pth'))\n",
        "if torch.cuda.is_available():\n",
        "  model.cuda()\n",
        "device = model.embedding.device\n",
        "\n",
        "for layer in model.precondition_classifiers:\n",
        "  layer.eval()\n",
        "for layer in model.effect_classifiers:\n",
        "  layer.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfXiCTA9KPjG"
      },
      "source": [
        "#### Test the Model\n",
        "\n",
        "Run inference on the testing set of TRIP. Can simply edit the top-level `for` loop if you want to run inference on other partitions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQX4bIxcKWlf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bb44eae-08df-4adc-fde0-21ea4abe8930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[                                                                        ] \u001b[38;2;255;0;0m  0%\u001b[39m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing model: drive/My Drive/TRIP/saved_models/google-electra-base-discriminator_cloze_1_1e-05_5_0.0-0.0-0.0-0.5-0.5_tiered_pipeline_lc_ablate_attributes_states-logits.\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] \u001b[38;2;0;255;0m100%\u001b[39m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:29s.\n",
            "\n",
            "PARTITION: test\n",
            "Stories:\n",
            "{\n",
            "  accuracy: \n",
            "    0.7464387464387464,\n",
            "  f1: \n",
            "    0.7464058123959898,\n",
            "  verifiability: \n",
            "    0.0,\n",
            "}\n",
            "\n",
            "\n",
            "Conflicts:\n",
            "{\n",
            "  accuracy: \n",
            "    0.9630684815870001,\n",
            "  f1: \n",
            "    0.6663366045504188,\n",
            "}\n",
            "\n",
            "\n",
            "Preconditions:\n",
            "{\n",
            "  accuracy: \n",
            "    0.8519769667917816,\n",
            "  f1: \n",
            "    0.12411638232303598,\n",
            "  accuracy_0: \n",
            "    0.8602481195073788,\n",
            "  f1_0: \n",
            "    0.3189528914152549,\n",
            "  accuracy_1: \n",
            "    0.892597114819337,\n",
            "  f1_1: \n",
            "    0.39660444917316723,\n",
            "  accuracy_2: \n",
            "    0.8069687514131959,\n",
            "  f1_2: \n",
            "    0.30024776619447097,\n",
            "  accuracy_3: \n",
            "    0.7862192677007492,\n",
            "  f1_3: \n",
            "    0.2939008909999747,\n",
            "  accuracy_4: \n",
            "    0.9597446449298301,\n",
            "  f1_4: \n",
            "    0.32662472476495485,\n",
            "  accuracy_5: \n",
            "    0.7770768326323881,\n",
            "  f1_5: \n",
            "    0.11086106181455696,\n",
            "  accuracy_6: \n",
            "    0.8728425209906692,\n",
            "  f1_6: \n",
            "    0.42443110052853145,\n",
            "  accuracy_7: \n",
            "    0.7995598365968737,\n",
            "  f1_7: \n",
            "    0.3012241011861772,\n",
            "  accuracy_8: \n",
            "    0.9442937035529628,\n",
            "  f1_8: \n",
            "    0.369495140180891,\n",
            "  accuracy_9: \n",
            "    0.8250425843018435,\n",
            "  f1_9: \n",
            "    0.3582939666069857,\n",
            "  accuracy_10: \n",
            "    0.9805770361325917,\n",
            "  f1_10: \n",
            "    0.338355081420874,\n",
            "  accuracy_11: \n",
            "    0.8133450911228689,\n",
            "  f1_11: \n",
            "    0.30134742226114086,\n",
            "  accuracy_12: \n",
            "    0.8051447866262681,\n",
            "  f1_12: \n",
            "    0.31245298565663776,\n",
            "  accuracy_13: \n",
            "    0.8616876950210284,\n",
            "  f1_13: \n",
            "    0.311874654668334,\n",
            "  accuracy_14: \n",
            "    0.8026500248722471,\n",
            "  f1_14: \n",
            "    0.3099709824764743,\n",
            "  accuracy_15: \n",
            "    0.7796695759658723,\n",
            "  f1_15: \n",
            "    0.30577286822953953,\n",
            "  accuracy_16: \n",
            "    0.8084309380605676,\n",
            "  f1_16: \n",
            "    0.3192145774023732,\n",
            "  accuracy_17: \n",
            "    0.9259259259259259,\n",
            "  f1_17: \n",
            "    0.348166748041558,\n",
            "  accuracy_18: \n",
            "    0.8914137988212062,\n",
            "  f1_18: \n",
            "    0.31424297496067677,\n",
            "  accuracy_19: \n",
            "    0.8461010868418276,\n",
            "  f1_19: \n",
            "    0.313098899059002,\n",
            "}\n",
            "\n",
            "\n",
            "Effects:\n",
            "{\n",
            "  accuracy: \n",
            "    0.8407671203967501,\n",
            "  f1: \n",
            "    0.11451365594383568,\n",
            "  accuracy_0: \n",
            "    0.9414673118376822,\n",
            "  f1_0: \n",
            "    0.34374485176352315,\n",
            "  accuracy_1: \n",
            "    0.7854128039313224,\n",
            "  f1_1: \n",
            "    0.37608850872763183,\n",
            "  accuracy_2: \n",
            "    0.8919564660305401,\n",
            "  f1_2: \n",
            "    0.3168569104190205,\n",
            "  accuracy_3: \n",
            "    0.8308008863564419,\n",
            "  f1_3: \n",
            "    0.304008647852441,\n",
            "  accuracy_4: \n",
            "    0.8073380665973259,\n",
            "  f1_4: \n",
            "    0.29895539068280785,\n",
            "  accuracy_5: \n",
            "    0.7773557032816292,\n",
            "  f1_5: \n",
            "    0.10006728748914658,\n",
            "  accuracy_6: \n",
            "    0.859712989342619,\n",
            "  f1_6: \n",
            "    0.38405427776465806,\n",
            "  accuracy_7: \n",
            "    0.8132847947662762,\n",
            "  f1_7: \n",
            "    0.30208188010313936,\n",
            "  accuracy_8: \n",
            "    0.8507288322103137,\n",
            "  f1_8: \n",
            "    0.32672161761676694,\n",
            "  accuracy_9: \n",
            "    0.8293989960656627,\n",
            "  f1_9: \n",
            "    0.49559041218113403,\n",
            "  accuracy_10: \n",
            "    0.8553113553113553,\n",
            "  f1_10: \n",
            "    0.32000425793935805,\n",
            "  accuracy_11: \n",
            "    0.8215453956194697,\n",
            "  f1_11: \n",
            "    0.30803367692240874,\n",
            "  accuracy_12: \n",
            "    0.7817045780008743,\n",
            "  f1_12: \n",
            "    0.3087900178212453,\n",
            "  accuracy_13: \n",
            "    0.876987895506414,\n",
            "  f1_13: \n",
            "    0.32983215272006466,\n",
            "  accuracy_14: \n",
            "    0.8872759613500354,\n",
            "  f1_14: \n",
            "    0.3213008527368781,\n",
            "  accuracy_15: \n",
            "    0.9281041318078355,\n",
            "  f1_15: \n",
            "    0.34839878524546847,\n",
            "  accuracy_16: \n",
            "    0.8104131807835512,\n",
            "  f1_16: \n",
            "    0.30323557704503745,\n",
            "  accuracy_17: \n",
            "    0.8813970665822518,\n",
            "  f1_17: \n",
            "    0.3164277189684758,\n",
            "  accuracy_18: \n",
            "    0.8051146384479718,\n",
            "  f1_18: \n",
            "    0.2982844140227345,\n",
            "  accuracy_19: \n",
            "    0.7800313541054282,\n",
            "  f1_19: \n",
            "    0.29556041455165066,\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from www.model.eval import evaluate_tiered, save_results, save_preds, list_comparison, add_entity_attribute_labels\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "metrics = [(accuracy_score, 'accuracy'), (precision_score, 'precision'), (recall_score, 'recall'), (f1_score, 'f1')]\n",
        "import numpy as np\n",
        "from www.utils import print_dict\n",
        "\n",
        "print('Testing model: %s.' % probe_model)\n",
        "\n",
        "# May alter this depending on which partition(s) you want to run inference on\n",
        "for p in tiered_dataset:\n",
        "  if p != 'test':\n",
        "    continue\n",
        "\n",
        "  p_dataset = tiered_dataset[p]\n",
        "  p_tensor_dataset = tiered_tensor_dataset[p]\n",
        "  p_sampler = SequentialSampler(p_tensor_dataset)\n",
        "  p_dataloader = DataLoader(p_tensor_dataset, sampler=p_sampler, batch_size=16)\n",
        "  dev_dataset_name = subtask + '_%s_' + p\n",
        "  p_ids = [ex['example_id'] for ex in tiered_dataset[p]]\n",
        "\n",
        "  # Get preds and metrics on this partition\n",
        "  metr_attr, all_pred_atts, all_atts, \\\n",
        "  metr_prec, all_pred_prec, all_prec, \\\n",
        "  metr_eff, all_pred_eff, all_eff, \\\n",
        "  metr_conflicts, all_pred_conflicts, all_conflicts, \\\n",
        "  metr_stories, all_pred_stories, all_stories, explanations = evaluate_tiered(model, p_dataloader, device, [(accuracy_score, 'accuracy'), (f1_score, 'f1')], seg_mode=False, return_explanations=True)\n",
        "  explanations = add_entity_attribute_labels(explanations, tiered_dataset[p], list(att_to_num_classes.keys()))\n",
        "\n",
        "  save_results(metr_attr, probe_model, dev_dataset_name % 'attributes')\n",
        "  save_results(metr_prec, probe_model, dev_dataset_name % 'preconditions')\n",
        "  save_results(metr_eff, probe_model, dev_dataset_name % 'effects')\n",
        "  save_results(metr_conflicts, probe_model, dev_dataset_name % 'conflicts')\n",
        "  save_results(metr_stories, probe_model, dev_dataset_name % 'stories')\n",
        "  save_results(explanations, probe_model, dev_dataset_name % 'explanations')\n",
        "\n",
        "  print('\\nPARTITION: %s' % p)\n",
        "  print('Stories:')\n",
        "  print_dict(metr_stories)\n",
        "  print('Conflicts:')\n",
        "  print_dict(metr_conflicts)\n",
        "  print('Preconditions:')\n",
        "  print_dict(metr_prec)\n",
        "  print('Effects:')\n",
        "  print_dict(metr_eff)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ON1UAnbc8OOE"
      },
      "source": [
        "#### Add Consistency Metric to Model Results\n",
        "The intermediate conistency metric isn't included in the originally calculated metrics. This block adds the consistency metric to pre-existing model directory based on the tiered predictions. Generates a new `results_cloze_stories_final_[partition].json` file that includes the consistency metric.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1obFel58pd-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfc6cc8d-6349-457f-b4e8-3448b189018f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 51 consistent preds in dev (versus 0 verifiable)\n",
            "Found 37 consistent preds in test (versus 0 verifiable)\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "model_directories = ['google-electra-base-discriminator_cloze_1_1e-05_5_0.0-0.0-0.0-0.5-0.5_tiered_pipeline_lc_ablate_attributes_states-logits']\n",
        "\n",
        "partitions = ['dev', 'test']\n",
        "expl_fname = 'results_cloze_explanations_%s.json'\n",
        "endtask_fname = 'results_cloze_stories_%s.json'\n",
        "endtask_fname_new = 'results_cloze_stories_final_%s.json'\n",
        "for md in model_directories:\n",
        "  for p in partitions:\n",
        "    # print(md, expl_fname % p)\n",
        "    explanations = json.load(open(os.path.join(DRIVE_PATH, 'saved_models', md, expl_fname % p), 'r'))\n",
        "    endtask_results = json.load(open(os.path.join(DRIVE_PATH, 'saved_models', md, endtask_fname % p), 'r'))\n",
        "\n",
        "    consistent_preds = 0\n",
        "    verifiable_preds = 0\n",
        "    total = 0\n",
        "    for expl in explanations:\n",
        "      if expl['valid_explanation']:\n",
        "        verifiable_preds += 1\n",
        "      if expl['story_pred'] == expl['story_label']:\n",
        "        if len(expl['conflict_pred']) == len(expl['conflict_label']) and expl['conflict_pred'][0] == expl['conflict_label'][0] and expl['conflict_pred'][1] == expl['conflict_label'][1]:\n",
        "          expl['consistent'] = True\n",
        "          consistent_preds += 1\n",
        "        else:\n",
        "          expl['consistent'] = False\n",
        "      total += 1\n",
        "\n",
        "    endtask_results['consistency'] = float(consistent_preds) / total\n",
        "    print('Found %s consistent preds in %s (versus %s verifiable)' % (str(consistent_preds), p, str(verifiable_preds)))\n",
        "    json.dump(explanations, open(os.path.join(DRIVE_PATH, 'saved_models', md, (expl_fname % p).replace('explanations', 'explanations_consistency')), 'w'))\n",
        "    json.dump(endtask_results, open(os.path.join(DRIVE_PATH, 'saved_models', md, endtask_fname_new % p), 'w'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 --version\n",
        "!pip freeze"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoYOxL_QhMhw",
        "outputId": "009de483-9275-4f7c-941c-5fa2a2edf0d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n",
            "absl-py==1.4.0\n",
            "accelerate==1.1.1\n",
            "aiohappyeyeballs==2.4.4\n",
            "aiohttp==3.11.10\n",
            "aiosignal==1.3.1\n",
            "alabaster==1.0.0\n",
            "albucore==0.0.19\n",
            "albumentations==1.4.20\n",
            "altair==5.5.0\n",
            "annotated-types==0.7.0\n",
            "anyio==3.7.1\n",
            "argon2-cffi==23.1.0\n",
            "argon2-cffi-bindings==21.2.0\n",
            "array_record==0.5.1\n",
            "arviz==0.20.0\n",
            "astropy==6.1.7\n",
            "astropy-iers-data==0.2024.12.9.0.36.21\n",
            "astunparse==1.6.3\n",
            "async-timeout==4.0.3\n",
            "atpublic==4.1.0\n",
            "attrs==24.2.0\n",
            "audioread==3.0.1\n",
            "autograd==1.7.0\n",
            "babel==2.16.0\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.12.3\n",
            "bigframes==1.27.0\n",
            "bigquery-magics==0.4.0\n",
            "bleach==6.2.0\n",
            "blinker==1.9.0\n",
            "blis==0.7.11\n",
            "blosc2==2.7.1\n",
            "bokeh==3.6.2\n",
            "Bottleneck==1.4.2\n",
            "bqplot==0.12.43\n",
            "branca==0.8.0\n",
            "CacheControl==0.14.1\n",
            "cachetools==5.5.0\n",
            "catalogue==2.0.10\n",
            "certifi==2024.8.30\n",
            "cffi==1.17.1\n",
            "chardet==5.2.0\n",
            "charset-normalizer==3.4.0\n",
            "chex==0.1.87\n",
            "clarabel==0.9.0\n",
            "click==8.1.7\n",
            "cloudpathlib==0.20.0\n",
            "cloudpickle==3.1.0\n",
            "cmake==3.30.5\n",
            "cmdstanpy==1.2.4\n",
            "colorcet==3.1.0\n",
            "colorlover==0.3.0\n",
            "colour==0.1.5\n",
            "community==1.0.0b1\n",
            "confection==0.1.5\n",
            "cons==0.4.6\n",
            "contourpy==1.3.1\n",
            "cryptography==43.0.3\n",
            "cuda-python==12.2.1\n",
            "cudf-cu12 @ https://pypi.nvidia.com/cudf-cu12/cudf_cu12-24.10.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\n",
            "cufflinks==0.17.3\n",
            "cupy-cuda12x==12.2.0\n",
            "cvxopt==1.3.2\n",
            "cvxpy==1.5.4\n",
            "cycler==0.12.1\n",
            "cymem==2.0.10\n",
            "Cython==3.0.11\n",
            "dask==2024.10.0\n",
            "datascience==0.17.6\n",
            "db-dtypes==1.3.1\n",
            "dbus-python==1.2.18\n",
            "debugpy==1.8.0\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "Deprecated==1.2.15\n",
            "diffusers==0.31.0\n",
            "distro==1.9.0\n",
            "dlib==19.24.2\n",
            "dm-tree==0.1.8\n",
            "docker-pycreds==0.4.0\n",
            "docstring_parser==0.16\n",
            "docutils==0.21.2\n",
            "dopamine_rl==4.0.9\n",
            "duckdb==1.1.3\n",
            "earthengine-api==1.2.0\n",
            "easydict==1.13\n",
            "ecos==2.0.14\n",
            "editdistance==0.8.1\n",
            "eerepr==0.0.4\n",
            "einops==0.8.0\n",
            "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl#sha256=86cc141f63942d4b2c5fcee06630fd6f904788d2f0ab005cce45aadb8fb73889\n",
            "entrypoints==0.4\n",
            "et_xmlfile==2.0.0\n",
            "etils==1.11.0\n",
            "etuples==0.3.9\n",
            "eval_type_backport==0.2.0\n",
            "exceptiongroup==1.2.2\n",
            "fastai==2.7.18\n",
            "fastcore==1.7.25\n",
            "fastdownload==0.0.7\n",
            "fastjsonschema==2.21.1\n",
            "fastprogress==1.0.3\n",
            "fastrlock==0.8.2\n",
            "filelock==3.16.1\n",
            "firebase-admin==6.5.0\n",
            "Flask==3.0.3\n",
            "flatbuffers==24.3.25\n",
            "flax==0.8.5\n",
            "folium==0.18.0\n",
            "fonttools==4.55.2\n",
            "frozendict==2.4.6\n",
            "frozenlist==1.5.0\n",
            "fsspec==2024.10.0\n",
            "future==1.0.0\n",
            "gast==0.6.0\n",
            "gcsfs==2024.10.0\n",
            "GDAL==3.6.4\n",
            "gdown==5.2.0\n",
            "geemap==0.35.1\n",
            "gensim==4.3.3\n",
            "geocoder==1.38.1\n",
            "geographiclib==2.0\n",
            "geopandas==1.0.1\n",
            "geopy==2.4.1\n",
            "gin-config==0.5.0\n",
            "gitdb==4.0.11\n",
            "GitPython==3.1.43\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-ai-generativelanguage==0.6.10\n",
            "google-api-core==2.19.2\n",
            "google-api-python-client==2.151.0\n",
            "google-auth==2.27.0\n",
            "google-auth-httplib2==0.2.0\n",
            "google-auth-oauthlib==1.2.1\n",
            "google-cloud-aiplatform==1.73.0\n",
            "google-cloud-bigquery==3.25.0\n",
            "google-cloud-bigquery-connection==1.16.1\n",
            "google-cloud-bigquery-storage==2.27.0\n",
            "google-cloud-bigtable==2.27.0\n",
            "google-cloud-core==2.4.1\n",
            "google-cloud-datastore==2.20.1\n",
            "google-cloud-firestore==2.19.0\n",
            "google-cloud-functions==1.18.1\n",
            "google-cloud-iam==2.16.1\n",
            "google-cloud-language==2.15.1\n",
            "google-cloud-pubsub==2.27.1\n",
            "google-cloud-resource-manager==1.13.1\n",
            "google-cloud-storage==2.8.0\n",
            "google-cloud-translate==3.17.0\n",
            "google-colab @ file:///colabtools/dist/google_colab-1.0.0.tar.gz\n",
            "google-crc32c==1.6.0\n",
            "google-generativeai==0.8.3\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==2.7.2\n",
            "googleapis-common-protos==1.66.0\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.20.3\n",
            "greenlet==3.1.1\n",
            "grpc-google-iam-v1==0.13.1\n",
            "grpcio==1.68.1\n",
            "grpcio-status==1.62.3\n",
            "gspread==6.0.2\n",
            "gspread-dataframe==3.3.1\n",
            "gym==0.25.2\n",
            "gym-notices==0.0.8\n",
            "h11==0.14.0\n",
            "h5netcdf==1.4.1\n",
            "h5py==3.12.1\n",
            "holidays==0.62\n",
            "holoviews==1.20.0\n",
            "html5lib==1.1\n",
            "httpcore==1.0.7\n",
            "httpimport==1.4.0\n",
            "httplib2==0.22.0\n",
            "httpx==0.28.1\n",
            "huggingface-hub==0.26.5\n",
            "humanize==4.11.0\n",
            "hyperopt==0.2.7\n",
            "ibis-framework==9.2.0\n",
            "idna==3.10\n",
            "imageio==2.36.1\n",
            "imageio-ffmpeg==0.5.1\n",
            "imagesize==1.4.1\n",
            "imbalanced-learn==0.12.4\n",
            "imgaug==0.4.0\n",
            "immutabledict==4.2.1\n",
            "importlib_metadata==8.5.0\n",
            "importlib_resources==6.4.5\n",
            "imutils==0.5.4\n",
            "inflect==7.4.0\n",
            "iniconfig==2.0.0\n",
            "intel-cmplr-lib-ur==2025.0.3\n",
            "intel-openmp==2025.0.3\n",
            "ipyevents==2.0.2\n",
            "ipyfilechooser==0.6.0\n",
            "ipykernel==5.5.6\n",
            "ipyleaflet==0.19.2\n",
            "ipyparallel==8.8.0\n",
            "ipython==7.34.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.5.0\n",
            "ipytree==0.2.2\n",
            "ipywidgets==7.7.1\n",
            "itsdangerous==2.2.0\n",
            "jax==0.4.33\n",
            "jax-cuda12-pjrt==0.4.33\n",
            "jax-cuda12-plugin==0.4.33\n",
            "jaxlib==0.4.33\n",
            "jeepney==0.7.1\n",
            "jellyfish==1.1.2\n",
            "jieba==0.42.1\n",
            "Jinja2==3.1.4\n",
            "jiter==0.8.2\n",
            "joblib==1.4.2\n",
            "jsonlines==2.0.0\n",
            "jsonpatch==1.33\n",
            "jsonpickle==4.0.0\n",
            "jsonpointer==3.0.0\n",
            "jsonschema==4.23.0\n",
            "jsonschema-specifications==2024.10.1\n",
            "jupyter-client==6.1.12\n",
            "jupyter-console==6.1.0\n",
            "jupyter-leaflet==0.19.2\n",
            "jupyter-server==1.24.0\n",
            "jupyter_core==5.7.2\n",
            "jupyterlab_pygments==0.3.0\n",
            "jupyterlab_widgets==3.0.13\n",
            "kaggle==1.6.17\n",
            "kagglehub==0.3.4\n",
            "keras==3.5.0\n",
            "keyring==23.5.0\n",
            "kiwisolver==1.4.7\n",
            "langchain==0.3.10\n",
            "langchain-core==0.3.22\n",
            "langchain-text-splitters==0.3.2\n",
            "langcodes==3.5.0\n",
            "langsmith==0.1.147\n",
            "language_data==1.3.0\n",
            "launchpadlib==1.10.16\n",
            "lazr.restfulclient==0.14.4\n",
            "lazr.uri==1.0.6\n",
            "lazy_loader==0.4\n",
            "libclang==18.1.1\n",
            "libcudf-cu12 @ https://pypi.nvidia.com/libcudf-cu12/libcudf_cu12-24.10.1-py3-none-manylinux_2_28_x86_64.whl\n",
            "librosa==0.10.2.post1\n",
            "lightgbm==4.5.0\n",
            "linkify-it-py==2.0.3\n",
            "llvmlite==0.43.0\n",
            "locket==1.0.0\n",
            "logical-unification==0.4.6\n",
            "lxml==5.3.0\n",
            "marisa-trie==1.2.1\n",
            "Markdown==3.7\n",
            "markdown-it-py==3.0.0\n",
            "MarkupSafe==3.0.2\n",
            "matplotlib==3.8.0\n",
            "matplotlib-inline==0.1.7\n",
            "matplotlib-venn==1.1.1\n",
            "mdit-py-plugins==0.4.2\n",
            "mdurl==0.1.2\n",
            "miniKanren==1.0.3\n",
            "missingno==0.5.2\n",
            "mistune==3.0.2\n",
            "mizani==0.13.0\n",
            "mkl==2025.0.1\n",
            "ml-dtypes==0.4.1\n",
            "mlxtend==0.23.3\n",
            "more-itertools==10.5.0\n",
            "moviepy==1.0.3\n",
            "mpmath==1.3.0\n",
            "msgpack==1.1.0\n",
            "multidict==6.1.0\n",
            "multipledispatch==1.0.0\n",
            "multitasking==0.0.11\n",
            "murmurhash==1.0.11\n",
            "music21==9.3.0\n",
            "namex==0.0.8\n",
            "narwhals==1.16.0\n",
            "natsort==8.4.0\n",
            "nbclassic==1.1.0\n",
            "nbclient==0.10.1\n",
            "nbconvert==7.16.4\n",
            "nbformat==5.10.4\n",
            "ndindex==1.9.2\n",
            "nest-asyncio==1.6.0\n",
            "networkx==3.4.2\n",
            "nibabel==5.3.2\n",
            "nltk==3.9.1\n",
            "notebook==6.5.5\n",
            "notebook_shim==0.2.4\n",
            "numba==0.60.0\n",
            "numexpr==2.10.2\n",
            "numpy==1.26.4\n",
            "nvidia-cublas-cu12==12.6.4.1\n",
            "nvidia-cuda-cupti-cu12==12.6.80\n",
            "nvidia-cuda-nvcc-cu12==12.6.85\n",
            "nvidia-cuda-runtime-cu12==12.6.77\n",
            "nvidia-cudnn-cu12==9.6.0.74\n",
            "nvidia-cufft-cu12==11.3.0.4\n",
            "nvidia-curand-cu12==10.3.7.77\n",
            "nvidia-cusolver-cu12==11.7.1.2\n",
            "nvidia-cusparse-cu12==12.5.4.2\n",
            "nvidia-nccl-cu12==2.23.4\n",
            "nvidia-nvjitlink-cu12==12.6.85\n",
            "nvtx==0.2.10\n",
            "nx-cugraph-cu12 @ https://pypi.nvidia.com/nx-cugraph-cu12/nx_cugraph_cu12-24.10.0-py3-none-any.whl\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.2.2\n",
            "openai==1.54.5\n",
            "opencv-contrib-python==4.10.0.84\n",
            "opencv-python==4.10.0.84\n",
            "opencv-python-headless==4.10.0.84\n",
            "openpyxl==3.1.5\n",
            "opentelemetry-api==1.28.2\n",
            "opentelemetry-sdk==1.28.2\n",
            "opentelemetry-semantic-conventions==0.49b2\n",
            "opt_einsum==3.4.0\n",
            "optax==0.2.4\n",
            "optree==0.13.1\n",
            "orbax-checkpoint==0.6.4\n",
            "orjson==3.10.12\n",
            "osqp==0.6.7.post3\n",
            "packaging==24.2\n",
            "pandas==2.2.2\n",
            "pandas-datareader==0.10.0\n",
            "pandas-gbq==0.24.0\n",
            "pandas-stubs==2.2.2.240909\n",
            "pandocfilters==1.5.1\n",
            "panel==1.5.4\n",
            "param==2.1.1\n",
            "parso==0.8.4\n",
            "parsy==2.1\n",
            "partd==1.4.2\n",
            "pathlib==1.0.1\n",
            "patsy==1.0.1\n",
            "peewee==3.17.8\n",
            "peft==0.13.2\n",
            "pexpect==4.9.0\n",
            "pickleshare==0.7.5\n",
            "pillow==11.0.0\n",
            "platformdirs==4.3.6\n",
            "plotly==5.24.1\n",
            "plotnine==0.14.3\n",
            "pluggy==1.5.0\n",
            "ply==3.11\n",
            "polars==1.9.0\n",
            "pooch==1.8.2\n",
            "portpicker==1.5.2\n",
            "preshed==3.0.9\n",
            "prettytable==3.12.0\n",
            "proglog==0.1.10\n",
            "progressbar2==4.5.0\n",
            "prometheus_client==0.21.1\n",
            "promise==2.3\n",
            "prompt_toolkit==3.0.48\n",
            "propcache==0.2.1\n",
            "prophet==1.1.6\n",
            "proto-plus==1.25.0\n",
            "protobuf==4.25.5\n",
            "psutil==5.9.5\n",
            "psycopg2==2.9.10\n",
            "ptyprocess==0.7.0\n",
            "py-cpuinfo==9.0.0\n",
            "py4j==0.10.9.7\n",
            "pyarrow==17.0.0\n",
            "pyarrow-hotfix==0.6\n",
            "pyasn1==0.6.1\n",
            "pyasn1_modules==0.4.1\n",
            "pycocotools==2.0.8\n",
            "pycparser==2.22\n",
            "pydantic==2.10.3\n",
            "pydantic_core==2.27.1\n",
            "pydata-google-auth==1.9.0\n",
            "pydot==3.0.3\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "PyDrive2==1.21.3\n",
            "pyerfa==2.0.1.5\n",
            "pygame==2.6.1\n",
            "pygit2==1.16.0\n",
            "Pygments==2.18.0\n",
            "PyGObject==3.42.1\n",
            "PyJWT==2.10.1\n",
            "pylibcudf-cu12 @ https://pypi.nvidia.com/pylibcudf-cu12/pylibcudf_cu12-24.10.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\n",
            "pylibcugraph-cu12==24.10.0\n",
            "pylibraft-cu12==24.10.0\n",
            "pymc==5.18.2\n",
            "pymystem3==0.2.0\n",
            "pynvjitlink-cu12==0.4.0\n",
            "pyogrio==0.10.0\n",
            "Pyomo==6.8.2\n",
            "PyOpenGL==3.1.7\n",
            "pyOpenSSL==24.2.1\n",
            "pyparsing==3.2.0\n",
            "pyperclip==1.9.0\n",
            "pyproj==3.7.0\n",
            "pyshp==2.3.1\n",
            "PySocks==1.7.1\n",
            "pyspark==3.5.3\n",
            "pytensor==2.26.4\n",
            "pytest==8.3.4\n",
            "python-apt==0.0.0\n",
            "python-box==7.2.0\n",
            "python-dateutil==2.8.2\n",
            "python-louvain==0.16\n",
            "python-slugify==8.0.4\n",
            "python-utils==3.9.1\n",
            "pytz==2024.2\n",
            "pyviz_comms==3.0.3\n",
            "PyYAML==6.0.2\n",
            "pyzmq==24.0.1\n",
            "qdldl==0.1.7.post4\n",
            "ratelim==0.1.6\n",
            "referencing==0.35.1\n",
            "regex==2024.9.11\n",
            "requests==2.32.3\n",
            "requests-oauthlib==1.3.1\n",
            "requests-toolbelt==1.0.0\n",
            "requirements-parser==0.9.0\n",
            "rich==13.9.4\n",
            "rmm-cu12==24.10.0\n",
            "rpds-py==0.22.3\n",
            "rpy2==3.4.2\n",
            "rsa==4.9\n",
            "safetensors==0.4.5\n",
            "scikit-image==0.24.0\n",
            "scikit-learn==1.5.2\n",
            "scipy==1.13.1\n",
            "scooby==0.10.0\n",
            "scs==3.2.7\n",
            "seaborn==0.13.2\n",
            "SecretStorage==3.3.1\n",
            "Send2Trash==1.8.3\n",
            "sentence-transformers==3.2.1\n",
            "sentencepiece==0.2.0\n",
            "sentry-sdk==2.19.2\n",
            "setproctitle==1.3.4\n",
            "shap==0.46.0\n",
            "shapely==2.0.6\n",
            "shellingham==1.5.4\n",
            "simple-parsing==0.1.6\n",
            "six==1.17.0\n",
            "sklearn-pandas==2.2.0\n",
            "slicer==0.0.8\n",
            "smart-open==7.0.5\n",
            "smmap==5.0.1\n",
            "sniffio==1.3.1\n",
            "snowballstemmer==2.2.0\n",
            "soundfile==0.12.1\n",
            "soupsieve==2.6\n",
            "soxr==0.5.0.post1\n",
            "spacy==3.7.5\n",
            "spacy-legacy==3.0.12\n",
            "spacy-loggers==1.0.5\n",
            "Sphinx==8.1.3\n",
            "sphinxcontrib-applehelp==2.0.0\n",
            "sphinxcontrib-devhelp==2.0.0\n",
            "sphinxcontrib-htmlhelp==2.1.0\n",
            "sphinxcontrib-jsmath==1.0.1\n",
            "sphinxcontrib-qthelp==2.0.0\n",
            "sphinxcontrib-serializinghtml==2.0.0\n",
            "SQLAlchemy==2.0.36\n",
            "sqlglot==25.1.0\n",
            "sqlparse==0.5.2\n",
            "srsly==2.4.8\n",
            "stanio==0.5.1\n",
            "statsmodels==0.14.4\n",
            "StrEnum==0.4.15\n",
            "stringzilla==3.11.0\n",
            "sympy==1.13.1\n",
            "tables==3.10.1\n",
            "tabulate==0.9.0\n",
            "tbb==2022.0.0\n",
            "tcmlib==1.2.0\n",
            "tenacity==9.0.0\n",
            "tensorboard==2.17.1\n",
            "tensorboard-data-server==0.7.2\n",
            "tensorflow==2.17.1\n",
            "tensorflow-datasets==4.9.7\n",
            "tensorflow-hub==0.16.1\n",
            "tensorflow-io-gcs-filesystem==0.37.1\n",
            "tensorflow-metadata==1.13.1\n",
            "tensorflow-probability==0.24.0\n",
            "tensorstore==0.1.69\n",
            "termcolor==2.5.0\n",
            "terminado==0.18.1\n",
            "text-unidecode==1.3\n",
            "textblob==0.17.1\n",
            "tf-slim==1.1.0\n",
            "tf_keras==2.17.0\n",
            "thinc==8.2.5\n",
            "threadpoolctl==3.5.0\n",
            "tifffile==2024.9.20\n",
            "timm==1.0.12\n",
            "tinycss2==1.4.0\n",
            "tokenizers==0.20.3\n",
            "toml==0.10.2\n",
            "tomli==2.2.1\n",
            "toolz==0.12.1\n",
            "torch @ https://download.pytorch.org/whl/cu121_full/torch-2.5.1%2Bcu121-cp310-cp310-linux_x86_64.whl\n",
            "torchaudio @ https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp310-cp310-linux_x86_64.whl\n",
            "torchsummary==1.5.1\n",
            "torchvision @ https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp310-cp310-linux_x86_64.whl\n",
            "tornado==6.3.3\n",
            "tqdm==4.66.6\n",
            "traitlets==5.7.1\n",
            "traittypes==0.2.1\n",
            "transformers==4.46.3\n",
            "tweepy==4.14.0\n",
            "typeguard==4.4.1\n",
            "typer==0.15.1\n",
            "types-pytz==2024.2.0.20241003\n",
            "types-setuptools==75.6.0.20241126\n",
            "typing_extensions==4.12.2\n",
            "tzdata==2024.2\n",
            "tzlocal==5.2\n",
            "uc-micro-py==1.0.3\n",
            "umf==0.9.1\n",
            "uritemplate==4.1.1\n",
            "urllib3==2.2.3\n",
            "vega-datasets==0.9.0\n",
            "wadllib==1.3.6\n",
            "wandb==0.18.7\n",
            "wasabi==1.1.3\n",
            "wcwidth==0.2.13\n",
            "weasel==0.4.1\n",
            "webcolors==24.11.1\n",
            "webencodings==0.5.1\n",
            "websocket-client==1.8.0\n",
            "Werkzeug==3.1.3\n",
            "widgetsnbextension==3.6.10\n",
            "wordcloud==1.9.4\n",
            "wrapt==1.17.0\n",
            "xarray==2024.10.0\n",
            "xarray-einstats==0.8.0\n",
            "xgboost==2.1.3\n",
            "xlrd==2.0.1\n",
            "xyzservices==2024.9.0\n",
            "yarl==1.18.3\n",
            "yellowbrick==1.5\n",
            "yfinance==0.2.50\n",
            "zipp==3.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7C0wy5Dvtv2"
      },
      "source": [
        "\n",
        "# Conversational Entailment (CE) Results\n",
        "\n",
        "Code for the coherence experiments on CE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKxPGbnWbdIy"
      },
      "outputs": [],
      "source": [
        "if task_name != 'ce':\n",
        "  raise ValueError('Please configure task_name in first cell to \"ce\" to run CE results!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7MADzgfvtv3"
      },
      "source": [
        "## Load Conversational Entailment Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSnNY2zbvtv3"
      },
      "outputs": [],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import pickle\n",
        "cache_train = os.path.join(DRIVE_PATH, 'all_data/ConvEnt/ConvEnt_train_resplit.json')\n",
        "cache_dev = os.path.join(DRIVE_PATH,'all_data/ConvEnt/ConvEnt_dev_resplit.json')\n",
        "cache_test = os.path.join(DRIVE_PATH,'all_data/ConvEnt/ConvEnt_test_resplit.json')\n",
        "ConvEnt_train = json.load(open(cache_train))\n",
        "ConvEnt_dev = json.load(open(cache_dev))\n",
        "ConvEnt_test = json.load(open(cache_test))\n",
        "\n",
        "# Combine train and dev and do cross-validation\n",
        "cache_folds = os.path.join(DRIVE_PATH,'all_data/ConvEnt/ConvEnt_folds.pkl') # Folds used for results presented in paper\n",
        "ConvEnt_train = ConvEnt_train + ConvEnt_dev\n",
        "train_sources = list(set([ex['dialog_source'] for ex in ConvEnt_train]))\n",
        "print(\"Reserved %s dialog sources for training and validation.\" % len(train_sources))\n",
        "\n",
        "no_folds = 8\n",
        "if not os.path.exists(cache_folds):\n",
        "  folds = []\n",
        "  for k in range(no_folds):\n",
        "    folds.append(np.random.choice(train_sources, size=5, replace=False))\n",
        "    train_sources = [s for s in train_sources if s not in folds[-1]]\n",
        "  assert len(train_sources) == 0\n",
        "  print(folds)\n",
        "  pickle.dump(folds, open(cache_folds, 'wb'))\n",
        "else:\n",
        "  folds = pickle.load(open(cache_folds, 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBYhEsdovtv4"
      },
      "outputs": [],
      "source": [
        "print('train examples:', len(ConvEnt_train))\n",
        "print('dev examples:', len(ConvEnt_dev))\n",
        "print('test examples:', len(ConvEnt_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Msxt3xAhvtv6"
      },
      "source": [
        "## Featurize Conversational Entailment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBfqFw82vtv7"
      },
      "outputs": [],
      "source": [
        "from www.dataset.featurize import add_bert_features_ConvEnt, get_tensor_dataset\n",
        "import pickle\n",
        "seq_length = 128\n",
        "\n",
        "ConvEnt_train = add_bert_features_ConvEnt(ConvEnt_train, tokenizer, seq_length, add_segment_ids=True)\n",
        "ConvEnt_dev = add_bert_features_ConvEnt(ConvEnt_dev, tokenizer, seq_length, add_segment_ids=True)\n",
        "ConvEnt_test = add_bert_features_ConvEnt(ConvEnt_test, tokenizer, seq_length, add_segment_ids=True)\n",
        "\n",
        "ConvEnt_train_folds = [[] for _ in range(no_folds)]\n",
        "ConvEnt_dev_folds = [[] for _ in range(no_folds)]\n",
        "for k in range(no_folds):\n",
        "  ConvEnt_train_folds[k] = [ex for ex in ConvEnt_train if ex['dialog_source'] not in folds[k]]\n",
        "  ConvEnt_dev_folds[k] = [ex for ex in ConvEnt_train if ex['dialog_source'] in folds[k]]\n",
        "\n",
        "  if debug:\n",
        "    ConvEnt_train_folds[k] = ConvEnt_train_folds[k][:10]\n",
        "    ConvEnt_dev_folds[k] = ConvEnt_dev_folds[k][:10]\n",
        "\n",
        "if debug:\n",
        "  ConvEnt_train = ConvEnt_train[:10]\n",
        "  ConvEnt_dev = ConvEnt_dev[:10]\n",
        "  ConvEnt_test = ConvEnt_test[:10]\n",
        "\n",
        "ConvEnt_train_tensor = get_tensor_dataset(ConvEnt_train, label_key='label', add_segment_ids=True)\n",
        "ConvEnt_test_tensor = get_tensor_dataset(ConvEnt_test, label_key='label', add_segment_ids=True)\n",
        "\n",
        "# Training sets for each validation fold\n",
        "ConvEnt_train_folds_tensor = [get_tensor_dataset(ConvEnt_train_folds[k], label_key='label', add_segment_ids=True) for k in range(no_folds)]\n",
        "ConvEnt_dev_folds_tensor = [get_tensor_dataset(ConvEnt_dev_folds[k], label_key='label', add_segment_ids=True) for k in range(no_folds)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Wtek-Tmvtv7"
      },
      "outputs": [],
      "source": [
        "print('train examples:', len(ConvEnt_train))\n",
        "print('dev examples:', len(ConvEnt_dev))\n",
        "print('test examples:', len(ConvEnt_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn5Ywwvxvtv6"
      },
      "source": [
        "## Train Models on Conversational Entailment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ytbj9Uxxvtv7"
      },
      "source": [
        "### Train Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9YL5qnRvtv7"
      },
      "source": [
        "#### Configure Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fC5iz07Fvtv8"
      },
      "outputs": [],
      "source": [
        "batch_sizes = [config_batch_size]\n",
        "learning_rates = [config_lr]\n",
        "epochs = config_epochs\n",
        "eval_batch_size = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jss8T2xzvtv8"
      },
      "source": [
        "#### Grid Search and Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QOdgrufvtv8"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from www.model.train import train_epoch\n",
        "from www.model.eval import evaluate, save_results, save_preds\n",
        "from sklearn.metrics import accuracy_score\n",
        "from www.utils import print_dict, get_model_dir\n",
        "from collections import Counter\n",
        "\n",
        "seed_val = 22 # Save random seed for reproducibility\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "assert len(batch_sizes) == 1\n",
        "train_fold_sampler = [RandomSampler(f) for f in ConvEnt_train_folds_tensor]\n",
        "train_fold_dataloader = [DataLoader(f, sampler=train_fold_sampler[i], batch_size=batch_sizes[0]) for i, f in enumerate(ConvEnt_train_folds_tensor)]\n",
        "\n",
        "dev_fold_sampler = [SequentialSampler(f) for f in ConvEnt_dev_folds_tensor]\n",
        "dev_fold_dataloader = [DataLoader(f, sampler=dev_fold_sampler[i], batch_size=eval_batch_size) for i, f in enumerate(ConvEnt_dev_folds_tensor)]\n",
        "\n",
        "all_val_accs = Counter()\n",
        "print('Beginning grid search for ConvEnt over %s parameter combination(s)!' % (str(len(batch_sizes) * len(learning_rates))))\n",
        "for bs in batch_sizes:\n",
        "  for lr in learning_rates:\n",
        "    print('\\nTRAINING MODEL: bs=%s, lr=%s' % (str(bs), str(lr)))\n",
        "\n",
        "    for k in range(no_folds):\n",
        "      print('Beginning fold %s/%s...' % (str(k+1), str(no_folds)))\n",
        "\n",
        "      # Set up model\n",
        "      if 'mnli' not in mode:\n",
        "        model = model_class.from_pretrained(model_name,\n",
        "                                            cache_dir=os.path.join(DRIVE_PATH, 'cache'))\n",
        "      else:\n",
        "        config = config_class.from_pretrained(model_name.replace('-mnli',''),\n",
        "                                        num_labels=3,\n",
        "                                        cache_dir=os.path.join(DRIVE_PATH, 'cache'))\n",
        "        model = model_class.from_pretrained(model_name,\n",
        "                                            config=config,\n",
        "                                            cache_dir=os.path.join(DRIVE_PATH, 'cache'))\n",
        "        config.num_labels = 2\n",
        "        model.num_labels = 2\n",
        "        model.classifier = cls_head_class(config=config) # Need to bring in a classification head for only 2 labels\n",
        "\n",
        "      model.cuda()\n",
        "      device = model.device\n",
        "\n",
        "      # Set up optimizer\n",
        "      optimizer = AdamW(model.parameters(), lr=lr)\n",
        "      total_steps = len(train_fold_dataloader[k]) * epochs\n",
        "      scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps = total_steps)\n",
        "\n",
        "      for epoch in range(epochs):\n",
        "        # Train the model for one epoch\n",
        "        print('[%s] Beginning epoch...' % str(epoch))\n",
        "\n",
        "        epoch_loss, _ = train_epoch(model, optimizer, train_fold_dataloader[k], device, seg_mode=True if 'roberta' not in mode else False)\n",
        "\n",
        "        # Validate on dev set\n",
        "        results, _, _ = evaluate(model, dev_fold_dataloader[k], device, [(accuracy_score, 'accuracy')], seg_mode=True if 'roberta' not in mode else False)\n",
        "        print('[%s] Validation results:' % str(epoch))\n",
        "        print_dict(results)\n",
        "\n",
        "        # Save accuracy\n",
        "        acc = results['accuracy']\n",
        "        if (bs, lr, epoch) in all_val_accs:\n",
        "          all_val_accs[(bs, lr, epoch)] += acc\n",
        "        else:\n",
        "          all_val_accs[(bs, lr, epoch)] = acc\n",
        "\n",
        "      model.cpu()\n",
        "      del model\n",
        "      del optimizer\n",
        "      del results\n",
        "      del scheduler\n",
        "      del total_steps\n",
        "\n",
        "      print('[%s] Finished epoch.' % str(epoch))\n",
        "\n",
        "for k in all_val_accs:\n",
        "  all_val_accs[k] /= no_folds\n",
        "\n",
        "print('Top performing param combos:')\n",
        "print(all_val_accs.most_common(5))\n",
        "\n",
        "save_fname = os.path.join(DRIVE_PATH, 'saved_models/%s_ConvEnt_xval_%s.pkl' % (model_name.replace('/','-'), '_'.join([str(lr) for lr in learning_rates])))\n",
        "pickle.dump(all_val_accs, open(save_fname, 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XhSrDlpI0aH"
      },
      "source": [
        "#### Re-Train Best Model from Cross-Validation\n",
        "\n",
        "Re-train a model with the best parameters from the search above. If this isn't run directly after the above cell, replace `save_fname.split('/'[-1])` in `xval_fnames` with the name of the `pkl` file previously generated in the `saved_models` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RI_AWgyFIzUm"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from www.model.train import train_epoch\n",
        "from www.model.eval import evaluate, save_results, save_preds\n",
        "from sklearn.metrics import accuracy_score\n",
        "from www.utils import print_dict, get_model_dir\n",
        "from collections import Counter\n",
        "\n",
        "# Re-train the model with the best parameters from the grid search/cross-validation (with all folds)\n",
        "xval_fnames = []\n",
        "xval_fnames.append(save_fname.split('/')[-1])\n",
        "\n",
        "xval_results = Counter()\n",
        "for fname in xval_fnames:\n",
        "  xval_results += pickle.load(open(os.path.join(DRIVE_PATH, 'saved_models/', fname), 'rb'))\n",
        "\n",
        "batch_size, learning_rate, epochs = xval_results.most_common(1)[0][0]\n",
        "epochs += 1\n",
        "\n",
        "# Set up model\n",
        "if 'mnli' not in mode:\n",
        "  model = model_class.from_pretrained(model_name,\n",
        "                                      cache_dir=os.path.join(DRIVE_PATH, 'cache'))\n",
        "else:\n",
        "  config = config_class.from_pretrained(model_name.replace('-mnli',''),\n",
        "                                  num_labels=3,\n",
        "                                  cache_dir=os.path.join(DRIVE_PATH, 'cache'))\n",
        "  model = model_class.from_pretrained(model_name,\n",
        "                                      config=config,\n",
        "                                      cache_dir=os.path.join(DRIVE_PATH, 'cache'))\n",
        "  config.num_labels = 2\n",
        "  model.num_labels = 2\n",
        "  model.classifier = cls_head_class(config=config) # Need to bring in a classification head for only 2 labels\n",
        "\n",
        "model.cuda()\n",
        "device = model.device\n",
        "\n",
        "train_sampler = RandomSampler(ConvEnt_train_tensor)\n",
        "train_dataloader = DataLoader(ConvEnt_train_tensor, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Set up optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps = total_steps)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print('[%s] Beginning epoch...' % str(epoch))\n",
        "  epoch_loss, _ = train_epoch(model, optimizer, train_dataloader, device, seg_mode=True if 'roberta' not in mode else False)\n",
        "\n",
        "print('[%s] Saving model checkpoint...' % str(epoch))\n",
        "model_param_str = get_model_dir(model_name.replace('/','-'), 'ConvEnt', batch_size, learning_rate, epoch) + '_xval'\n",
        "output_dir = os.path.join(DRIVE_PATH, 'saved_models', model_param_str)\n",
        "if not os.path.exists(output_dir):\n",
        "  os.makedirs(output_dir)\n",
        "model = model.module if hasattr(model, 'module') else model\n",
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_vocabulary(output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CADDFieTvtv9"
      },
      "source": [
        "## Test Models on Conversational Entailment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NJAbMNRvtv9"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from www.model.eval import evaluate, save_results, save_preds\n",
        "from sklearn.metrics import accuracy_score\n",
        "from www.utils import print_dict, get_model_dir\n",
        "\n",
        "best_model = eval_model_dir\n",
        "\n",
        "\n",
        "best_model = os.path.join(DRIVE_PATH, 'saved_models', best_model)\n",
        "\n",
        "# Load the model\n",
        "model = model_class.from_pretrained(best_model)\n",
        "model.cuda()\n",
        "device = model.device\n",
        "\n",
        "# Select appropriate dataset\n",
        "if 'cloze' in best_model:\n",
        "  subtask = 'cloze'\n",
        "elif 'order' in best_model:\n",
        "  subtask = 'order'\n",
        "\n",
        "test_sampler = SequentialSampler(ConvEnt_test_tensor)\n",
        "test_dataloader = DataLoader(ConvEnt_test_tensor, sampler=test_sampler, batch_size=128)\n",
        "test_dataset_name = '%s_%s' % ('ConvEnt', 'test')\n",
        "test_ids = [str(ex['example_id']) for ex in ConvEnt_test]\n",
        "\n",
        "print('Testing model: %s.' % best_model.split('/')[-1])\n",
        "\n",
        "results, preds, labels = evaluate(model, test_dataloader, device, [(accuracy_score, 'accuracy')], seg_mode=True if 'roberta' not in mode else False)\n",
        "save_results(results, best_model, test_dataset_name)\n",
        "save_preds(test_ids, labels, preds, best_model, test_dataset_name)\n",
        "\n",
        "print('Results (%s):' % p)\n",
        "print_dict(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qy_A5hR9vtv9"
      },
      "source": [
        "## Coherence Checks on Conversational Entailment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GO1JOxnIvtv9"
      },
      "source": [
        "### Load and Featurize Span Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOsSHJnCvtv-"
      },
      "outputs": [],
      "source": [
        "from www.dataset.featurize import add_bert_features_ConvEnt, get_tensor_dataset\n",
        "from www.dataset.prepro import get_ConvEnt_spans\n",
        "import pickle\n",
        "seq_length = 128\n",
        "\n",
        "merged_file = os.path.join(DRIVE_PATH, 'all_data/ConvEnt/ConvEnt_test_annotation_merged2.json')\n",
        "ConvEnt_test = json.load(open(merged_file))\n",
        "\n",
        "ConvEnt_test = add_bert_features_ConvEnt(ConvEnt_test, tokenizer, seq_length, add_segment_ids=True)\n",
        "\n",
        "if debug:\n",
        "  ConvEnt_test = ConvEnt_test[:10]\n",
        "\n",
        "# Some of the annotated examples are no longer in the test set :(\n",
        "# ConvEnt_test = [ex for ex in ConvEnt_test if ex['id'] in test_ids]\n",
        "\n",
        "# Make span versions of the datasets\n",
        "ConvEnt_test_spans = get_ConvEnt_spans(ConvEnt_test)\n",
        "\n",
        "# Add BERT features\n",
        "ConvEnt_test_tensor = get_tensor_dataset(ConvEnt_test, label_key='label', add_segment_ids=True)\n",
        "ConvEnt_test_spans_tensor = get_tensor_dataset(ConvEnt_test_spans, label_key='label', add_segment_ids=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAtipHPtvtv-"
      },
      "source": [
        "### Load the Trained Model\n",
        "\n",
        "Load the trained model we want to probe and select the appropriate dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCssPtg_vtv-"
      },
      "outputs": [],
      "source": [
        "probe_model = eval_model_dir\n",
        "probe_model = os.path.join(DRIVE_PATH, 'saved_models', probe_model)\n",
        "\n",
        "# Load the model\n",
        "model = model_class.from_pretrained(probe_model)\n",
        "if torch.cuda.is_available():\n",
        "  model.cuda()\n",
        "device = model.device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIPh3HSXvtv-"
      },
      "source": [
        "#### Load Trained Model's Base Predictions\n",
        "\n",
        "For comparison, we also want the preds and labels for the previous level."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9lHmA2evtv-"
      },
      "outputs": [],
      "source": [
        "from www.model.eval import load_preds\n",
        "from www.utils import print_dict\n",
        "\n",
        "preds_base = {}\n",
        "preds_base['test'] = load_preds(os.path.join(probe_model, 'preds_ConvEnt_test.tsv'))\n",
        "print(preds_base['test'].keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maZGCMvMvtv-"
      },
      "source": [
        "### Check a Model\n",
        "\n",
        "Will print out strict and lenient coherence metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tl_M9hnqvtv-"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from www.model.eval import evaluate, save_results, save_preds, list_comparison\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "metrics = [(accuracy_score, 'accuracy'), (precision_score, 'precision'), (recall_score, 'recall'), (f1_score, 'f1')]\n",
        "import numpy as np\n",
        "from www.utils import print_dict\n",
        "\n",
        "def is_polarized(smax, thres):\n",
        "  return (abs(smax[0] - smax[1]) >= thres)\n",
        "\n",
        "print('Testing model: %s.' % probe_model)\n",
        "\n",
        "all_results = {}\n",
        "p = 'test'\n",
        "\n",
        "p_dataset = ConvEnt_test_spans\n",
        "p_tensor_dataset = ConvEnt_test_spans_tensor\n",
        "p_sampler = SequentialSampler(p_tensor_dataset)\n",
        "p_dataloader = DataLoader(p_tensor_dataset, sampler=p_sampler, batch_size=512)\n",
        "p_dataset_name = '%s_spans_%s' % ('ConvEnt', p)\n",
        "p_dataset_name_co = '%s_consistent_%s' % ('ConvEnt', p)\n",
        "p_dataset_name_bp = '%s_breakpoints_%s' % ('ConvEnt', p)\n",
        "p_dataset_name_ev = '%s_evidence_%s' % ('ConvEnt', p)\n",
        "p_dataset_name_coh = '%s_coherent_%s' % ('ConvEnt', p)\n",
        "p_ids = [str(ex['example_id']) for ex in ConvEnt_test_spans]\n",
        "p_labels = [ex['label'] for ex in ConvEnt_test_spans]\n",
        "\n",
        "# Get span preds and save metrics\n",
        "results, preds, labels = evaluate(model, p_dataloader, device, metrics, seg_mode=True if 'roberta' not in mode else False)\n",
        "save_results(results, probe_model, p_dataset_name)\n",
        "save_preds(p_ids, labels, preds, probe_model, p_dataset_name)\n",
        "\n",
        "# Convert substory preds into breakpoint preds for each example\n",
        "ids_base = [str(ex['example_id']) for ex in ConvEnt_test]\n",
        "\n",
        "id_to_pred = {k: v for k,v in zip(p_ids, preds)}\n",
        "id_to_label = {k: v for k,v in zip(p_ids, p_labels)}\n",
        "\n",
        "preds_entailment = []\n",
        "labels_entailment = []\n",
        "preds_consistent = []\n",
        "preds_breakpoint = []\n",
        "labels_breakpoint = []\n",
        "preds_evidence = []\n",
        "labels_evidence = []\n",
        "span_accuracies = []\n",
        "span_accuracies_strict = []\n",
        "preds_coherent = []\n",
        "\n",
        "for i, exid in enumerate(ids_base):\n",
        "  ex = ConvEnt_test[i]\n",
        "  ex['length'] = len(ex['turns'])\n",
        "\n",
        "  label_entailment = preds_base[p][exid]['label']\n",
        "  pred_entailment = preds_base[p][exid]['pred']\n",
        "  labels_entailment.append(label_entailment)\n",
        "  preds_entailment.append(pred_entailment)\n",
        "\n",
        "  # Get ground truth breakpoint and evidence\n",
        "  label_breakpoint = ex['conflict_pair'][1] if ex['conflict_pair'] is not None and len(ex['conflict_pair']) > 0 else 0\n",
        "  labels_breakpoint.append(label_breakpoint)\n",
        "  if label_breakpoint > 0:\n",
        "    label_ev = ex['conflict_pair'][0]\n",
        "  else:\n",
        "    label_ev = -1\n",
        "  labels_evidence.append(label_ev)\n",
        "\n",
        "  # Check consistency - any span that entails the hypothesis' superspans should also entail\n",
        "  pred_consistent = True\n",
        "  span_accuracy = 0.0\n",
        "  span_accuracy_strict = 0.0\n",
        "  pred_coherent = True\n",
        "\n",
        "  no_spans = 0\n",
        "  for sp1 in range(ex['length']):\n",
        "    if not pred_consistent:\n",
        "      break\n",
        "\n",
        "    for sp2 in range(sp1, ex['length']):\n",
        "      if not pred_consistent:\n",
        "        break\n",
        "\n",
        "      span_pred = id_to_pred[exid + '-sp%s:%s' % (str(sp1), str(sp2))]\n",
        "      span_label = id_to_label[exid + '-sp%s:%s' % (str(sp1), str(sp2))]\n",
        "\n",
        "      if span_pred == span_label:\n",
        "        span_accuracy += 1.0\n",
        "        if label_entailment == pred_entailment:\n",
        "            span_accuracy_strict += 1.0\n",
        "      else:\n",
        "        pred_coherent = False\n",
        "      no_spans += 1\n",
        "      # print('%s:%s\\t%s\\t(%s, %s)' % (str(sp1), str(sp2), str(span_pred), str(span_prob[0]), str(span_prob[1])))\n",
        "\n",
        "      if span_pred == 1:\n",
        "        if pred_entailment == 1:\n",
        "          for sp3 in range(sp1+1):\n",
        "            if not pred_consistent:\n",
        "              break\n",
        "\n",
        "            for sp4 in range(sp2, ex['length']):\n",
        "              if not pred_consistent:\n",
        "                break\n",
        "\n",
        "              sspan_pred = id_to_pred[exid + '-sp%s:%s' % (str(sp3), str(sp4))]\n",
        "\n",
        "              if sspan_pred == 0:\n",
        "                pred_consistent = False\n",
        "                break\n",
        "        elif pred_entailment == 0:\n",
        "          pred_consistent = False\n",
        "\n",
        "  preds_consistent.append(1 if pred_consistent else 0)\n",
        "  span_accuracies.append(span_accuracy / no_spans)\n",
        "  span_accuracies_strict.append(span_accuracy_strict / no_spans)\n",
        "  preds_coherent.append(1 if pred_coherent else 0)\n",
        "\n",
        "  # Check pred. breakpoint (verifiability) - will be first sentence where the model prediction becomes polarized, i.e., confidence > threshold\n",
        "  pred_breakpoint = 0 # For now, 0 means -1, i.e., stories are entirely plausible - this shouldn't happen but it will (inconsistent?)\n",
        "  for ss in range(1, ex['length']):\n",
        "    if id_to_pred[exid + '-sp%s:%s' % (str(0), str(ss))] == 1:\n",
        "      pred_breakpoint = ss\n",
        "      break\n",
        "  preds_breakpoint.append(pred_breakpoint)\n",
        "\n",
        "  # Check pred. evidence (verifiability)\n",
        "  if pred_breakpoint > 0:\n",
        "    pred_evidence = -1\n",
        "    for ss in range(0, pred_breakpoint+1):\n",
        "      if id_to_pred[exid + '-sp%s:%s' % (str(0), str(ss))] == 1:\n",
        "        pred_evidence = ss\n",
        "  else:\n",
        "    pred_evidence = -1 # This should never happen - it would be inconsistent if it did\n",
        "  preds_evidence.append(pred_evidence)\n",
        "\n",
        "# Calculate tiered accuracy for model\n",
        "acc = 0\n",
        "acc_con = 0\n",
        "acc_con_vbp = 0\n",
        "acc_con_vbp_vev = 0\n",
        "no_ex = len(ids_base)\n",
        "for p_plaus, l_plaus, con, p_bp, l_bp, p_ev, l_ev in zip(preds_entailment, labels_entailment, preds_consistent, preds_breakpoint, labels_breakpoint, preds_evidence, labels_evidence):\n",
        "  # Accuracy\n",
        "  if p_plaus == l_plaus:\n",
        "    acc += 1\n",
        "\n",
        "    # Consistency\n",
        "    if con == 1:\n",
        "      acc_con += 1\n",
        "\n",
        "      # Verifiability (breakpoint)\n",
        "      if p_bp == l_bp:\n",
        "        acc_con_vbp += 1\n",
        "\n",
        "        # Verifiability (evidence)\n",
        "        if p_ev == l_ev:\n",
        "          acc_con_vbp_vev += 1\n",
        "\n",
        "acc /= no_ex\n",
        "acc_con /= no_ex\n",
        "acc_con_vbp /= no_ex\n",
        "acc_con_vbp_vev /= no_ex\n",
        "\n",
        "# all_results['acc'] = acc\n",
        "# all_results['acc_con'] = acc_con\n",
        "# all_results['acc_con_vbp'] = acc_con_vbp\n",
        "# all_results['acc_con_vbp_vev'] = acc_con_vbp_vev\n",
        "# all_results['span_accuracy'] = np.mean(span_accuracies)\n",
        "\n",
        "all_results['lenient_coherence'] = np.mean(span_accuracies_strict)\n",
        "all_results['strict_coherence'] = np.mean(preds_coherent)\n",
        "\n",
        "best_preds_entailment = preds_entailment\n",
        "best_preds_consistent = preds_consistent\n",
        "best_preds_breakpoint = preds_breakpoint\n",
        "best_preds_evidence = preds_evidence\n",
        "best_preds_coherent = preds_coherent\n",
        "\n",
        "print('\\nPARTITION: %s' % p)\n",
        "print_dict(all_results)\n",
        "\n",
        "# Save preds for breakpoint and evidence\n",
        "save_preds(ids_base, np.array(labels_breakpoint), best_preds_breakpoint, probe_model, p_dataset_name_bp)\n",
        "save_preds(ids_base, np.array(labels_evidence), best_preds_evidence, probe_model, p_dataset_name_ev)\n",
        "save_preds(ids_base, np.array([1 for p in best_preds_coherent]), best_preds_coherent, probe_model, p_dataset_name_coh)\n",
        "\n",
        "p_dataset_name_agg = '%s_tiers_agg_nostates_lenient_%s' % ('ConvEnt', p)\n",
        "save_results(all_results, probe_model, p_dataset_name_agg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnWDvQG7vtv-"
      },
      "source": [
        "# ART Results\n",
        "\n",
        "Code for the coherence experiments on ART."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvqFFHXebfrI"
      },
      "outputs": [],
      "source": [
        "if task_name != 'art':\n",
        "  raise ValueError('Please configure task_name in first cell to \"art\" to run ART results!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxRnuX_fvtv_"
      },
      "source": [
        "## Load ART dataset\n",
        "\n",
        "ART is originally gathered from [HuggingFace datasets](https://huggingface.co/docs/datasets/), but we added some of our own annotations for the coherence evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGZGEObJvtv_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "fname = os.path.join(DRIVE_PATH, 'all_data/ART/art.json')\n",
        "with open(fname, 'r') as f:\n",
        "  art = json.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apGoBEp_vtv_"
      },
      "source": [
        "## Train Models on ART"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukLFJ-Mfvtv_"
      },
      "source": [
        "### Featurize ART"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LbWyaWKvtv_"
      },
      "outputs": [],
      "source": [
        "from www.dataset.featurize import add_bert_features_art, get_tensor_dataset\n",
        "seq_length = 32\n",
        "\n",
        "for p in art:\n",
        "  for i in range(len(art[p])):\n",
        "    art[p][i]['label'] -= 1 # Do this so labels start at 0\n",
        "\n",
        "  if debug:\n",
        "    # Take 20 examples that we've annotated as the debug set so we can run the coherence metrics\n",
        "    merged_file = os.path.join(DRIVE_PATH, 'all_data/ART/ART_test_rand200_annotation_merged2.json')\n",
        "    ann_ids = [ex['id'] for ex in json.load(open(merged_file))]\n",
        "\n",
        "    if p == 'train':\n",
        "      art[p] = art[p][:20]\n",
        "      art[p] = art[p][:20]\n",
        "    elif p == 'val':\n",
        "      art[p] = [ex for ex in art[p] if ex['id'] in ann_ids][:20]\n",
        "\n",
        "art_tensor = {}\n",
        "for p in art:\n",
        "  art[p] = add_bert_features_art(art[p], tokenizer, seq_length)\n",
        "  art_tensor[p] = get_tensor_dataset(art[p], label_key='label')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XERMrM56vtv_"
      },
      "source": [
        "### Train Models\n",
        "\n",
        "Train models on ART. Note that ART's test set is not public, so we cannot test the model (unless we submit to their [leaderboard](https://leaderboard.allenai.org/anli/submissions/public))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2u4dOjy4vtwA"
      },
      "source": [
        "#### Configure Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bz3-D5hVvtwA"
      },
      "outputs": [],
      "source": [
        "batch_sizes = [config_batch_size]\n",
        "learning_rates = [config_lr]\n",
        "epochs = config_epochs\n",
        "eval_batch_size = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-cs-hhJvtwA"
      },
      "source": [
        "#### Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRfuT81qvtwA",
        "outputId": "e6e8ad02-9836-49e8-b0f3-615960aa5d80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beginning grid search for ART over 1 parameter combination(s)!\n",
            "\n",
            "TRAINING MODEL: bs=1, lr=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForMultipleChoice: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[0] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.7,\n",
            "}\n",
            "\n",
            "\n",
            "[0] Saving model checkpoint...\n",
            "[0] Finished epoch.\n",
            "Finished grid search! :)\n",
            "Best validation accuracy 0.7 from model roberta-large_art_1_1e-05_0.\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import get_linear_schedule_with_warmup, RobertaForMultipleChoice, BertForMultipleChoice, RobertaConfig, BertConfig\n",
        "from www.model.train import train_epoch\n",
        "from www.model.eval import evaluate, save_results, save_preds\n",
        "from sklearn.metrics import accuracy_score\n",
        "from www.utils import print_dict, get_model_dir\n",
        "\n",
        "seed_val = 22 # Save random seed for reproducibility\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll keep the validation data here with a constant eval batch size\n",
        "dev_sampler = SequentialSampler(art_tensor['val'])\n",
        "dev_dataloader = DataLoader(art_tensor['val'], sampler=dev_sampler, batch_size=eval_batch_size)\n",
        "dev_dataset_name = 'art_val'\n",
        "dev_ids = [str(ex['example_id']) for ex in art['val']]\n",
        "\n",
        "all_losses = []\n",
        "param_combos = []\n",
        "combo_names = []\n",
        "all_val_accs = []\n",
        "output_dirs = []\n",
        "best_acc = 0.0\n",
        "\n",
        "print('Beginning grid search for ART over %s parameter combination(s)!' % (str(len(batch_sizes) * len(learning_rates))))\n",
        "for bs in batch_sizes:\n",
        "  for lr in learning_rates:\n",
        "    print('\\nTRAINING MODEL: bs=%s, lr=%s' % (str(bs), str(lr)))\n",
        "\n",
        "    loss_values = []\n",
        "    acc_values = []\n",
        "\n",
        "    # Set up training dataset with new batch size\n",
        "    train_sampler = RandomSampler(art_tensor['train'])\n",
        "    train_dataloader = DataLoader(art_tensor['train'], sampler=train_sampler, batch_size=bs)\n",
        "\n",
        "    # Set up model\n",
        "    config = config_class.from_pretrained(model_name,\n",
        "                                          num_labels=2,\n",
        "                                          cache_dir=os.path.join(DRIVE_PATH, 'cache'))\n",
        "    model = model_class.from_pretrained(model_name,\n",
        "                                        config=config,\n",
        "                                        cache_dir=os.path.join(DRIVE_PATH, 'cache'))\n",
        "\n",
        "    model.cuda()\n",
        "    device = model.device\n",
        "\n",
        "    # Set up optimizer\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps = total_steps)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      # Train the model for one epoch\n",
        "      print('[%s] Beginning epoch...' % str(epoch))\n",
        "\n",
        "      epoch_loss, _ = train_epoch(model, optimizer, train_dataloader, device)\n",
        "\n",
        "      # Save loss\n",
        "      loss_values.append(epoch_loss)\n",
        "\n",
        "      # Validate on dev set\n",
        "      results, preds, labels = evaluate(model, dev_dataloader, device, [(accuracy_score, 'accuracy')])\n",
        "      print('[%s] Validation results:' % str(epoch))\n",
        "      print_dict(results)\n",
        "\n",
        "      # Save accuracy\n",
        "      acc = results['accuracy']\n",
        "      acc_values.append(acc)\n",
        "\n",
        "      # Save model checkpoint\n",
        "      print('[%s] Saving model checkpoint...' % str(epoch))\n",
        "      model_param_str = get_model_dir(model_name.replace('/','-'), 'art', bs, lr, epoch)# + '_toy'\n",
        "      output_dir = os.path.join(DRIVE_PATH, 'saved_models', model_param_str)\n",
        "      output_dirs.append(output_dir)\n",
        "      if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "      save_results(results, output_dir, dev_dataset_name)\n",
        "      save_preds(dev_ids, labels, preds, output_dir, dev_dataset_name)\n",
        "      model = model.module if hasattr(model, 'module') else model\n",
        "      model.save_pretrained(output_dir)\n",
        "      tokenizer.save_vocabulary(output_dir)\n",
        "\n",
        "      if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        best_model = model_param_str\n",
        "        best_dir = output_dir\n",
        "\n",
        "      print('[%s] Finished epoch.' % str(epoch))\n",
        "\n",
        "    all_losses.append(loss_values)\n",
        "    all_val_accs.append(acc_values)\n",
        "    param_combos.append((bs, lr))\n",
        "    combo_names.append('bs=%s, lr=%s' % (str(bs), str(lr)))\n",
        "\n",
        "print('Finished grid search! :)')\n",
        "print('Best validation accuracy %s from model %s.' % (best_acc, best_model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPSVjSw9vtwB"
      },
      "source": [
        "Delete non-best model checkpoints:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-Pqf4g1vtwB"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "# Delete non-best model checkpoints\n",
        "for od in output_dirs:\n",
        "  if od != best_dir and os.path.exists(od):\n",
        "    shutil.rmtree(od)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrNuHxTEvtwB"
      },
      "source": [
        "## Coherence Checks on ART"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Egyx9BejvtwC"
      },
      "source": [
        "### Load and Featurize Span Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mD8HXC9vtwC"
      },
      "outputs": [],
      "source": [
        "from www.dataset.featurize import add_bert_features_art, get_tensor_dataset\n",
        "from www.dataset.prepro import get_art_spans\n",
        "import pickle\n",
        "seq_length = 128\n",
        "\n",
        "merged_file = os.path.join(DRIVE_PATH, 'all_data/ART/ART_test_rand200_annotation_merged2.json')\n",
        "art_anns = json.load(open(merged_file))\n",
        "\n",
        "if debug:\n",
        "  ann_ids = [ex['id'] for ex in art_anns]\n",
        "  debug_ids = [ex['id'] for ex in art[p] if ex['id'] in ann_ids][:20]\n",
        "  art = [ex for ex in art_anns if ex['id'] in debug_ids]\n",
        "\n",
        "# Make span versions of the datasets\n",
        "art_spans = get_art_spans(art)\n",
        "\n",
        "# Add BERT features\n",
        "art = add_bert_features_art(art, tokenizer, seq_length, add_segment_ids=True)\n",
        "art_spans = add_bert_features_art(art_spans, tokenizer, seq_length, add_segment_ids=True)\n",
        "\n",
        "# Add BERT features\n",
        "art_tensor = get_tensor_dataset(art, label_key='label', add_segment_ids=True)\n",
        "art_spans_tensor = get_tensor_dataset(art_spans, label_key='label', add_segment_ids=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auYYxFc6vtwC"
      },
      "source": [
        "### Load the Trained Model\n",
        "\n",
        "Load the trained model we want to probe and select the appropriate dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruiy_uXqvtwC"
      },
      "outputs": [],
      "source": [
        "probe_model = eval_model_dir\n",
        "probe_model = os.path.join(DRIVE_PATH, 'saved_models', probe_model)\n",
        "\n",
        "# Load the model\n",
        "model = model_class.from_pretrained(probe_model)\n",
        "if torch.cuda.is_available():\n",
        "  model.cuda()\n",
        "device = model.device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwznwL-MvtwC"
      },
      "source": [
        "#### Load Trained Model's Two-Story Classification Predictions\n",
        "\n",
        "For comparison, we also want the preds and labels for the previous level."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdIPP8oPvtwC"
      },
      "outputs": [],
      "source": [
        "from www.model.eval import load_preds\n",
        "from www.utils import print_dict\n",
        "\n",
        "preds_base = {}\n",
        "preds_base['val'] = load_preds(os.path.join(probe_model, 'preds_art_val.tsv'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYRfQG6LvtwC"
      },
      "source": [
        "### Calculate Coherence Metrics\n",
        "\n",
        "As ART is a multiple-choice task, we will need to tune the confidence threshold $\\rho$. This code will print out the strict and lenient coherence metrics, as well as the chosen $\\rho$ (`best_threshold`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCfpfrDXvtwD",
        "outputId": "3d4bf905-11f1-41a9-889b-cb55114e67bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing model: drive/My Drive/Colab Notebooks/Research/TRIP_replication/saved_models/roberta-large_art_1_1e-05_0.\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:03s.\n",
            "\n",
            "PARTITION: val \t METRIC: strict_coherence\n",
            "chosen threshold: 1.0\n",
            "{\n",
            "  lenient_coherence: \n",
            "    0.18246427120454473,\n",
            "  strict_coherence: \n",
            "    0.15,\n",
            "  best_threshold: \n",
            "    1.0,\n",
            "}\n",
            "\n",
            "\n",
            "\n",
            "PARTITION: val \t METRIC: lenient_coherence\n",
            "chosen threshold: 1.0\n",
            "{\n",
            "  lenient_coherence: \n",
            "    0.18246427120454473,\n",
            "  strict_coherence: \n",
            "    0.15,\n",
            "  best_threshold: \n",
            "    1.0,\n",
            "}\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from www.model.eval import evaluate, save_results, save_preds, list_comparison\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "metrics = [(accuracy_score, 'accuracy'), (precision_score, 'precision'), (recall_score, 'recall'), (f1_score, 'f1')]\n",
        "import numpy as np\n",
        "from www.utils import print_dict\n",
        "\n",
        "def is_polarized(smax, thres):\n",
        "  return (abs(smax[0] - smax[1]) >= thres)\n",
        "\n",
        "print('Testing model: %s.' % probe_model)\n",
        "\n",
        "subtask = 'art'\n",
        "p = 'val'\n",
        "all_results = {}\n",
        "\n",
        "p_dataset = art_spans\n",
        "p_tensor_dataset = art_spans_tensor\n",
        "p_sampler = SequentialSampler(p_tensor_dataset)\n",
        "p_dataloader = DataLoader(p_tensor_dataset, sampler=p_sampler, batch_size=128)\n",
        "p_dataset_name = '%s_spans_%s' % (subtask, p)\n",
        "p_dataset_name_co = '%s_consistent_%s' % (subtask, p)\n",
        "p_dataset_name_bp = '%s_breakpoints_%s' % (subtask, p)\n",
        "p_dataset_name_ev = '%s_evidence_%s' % (subtask, p)\n",
        "p_dataset_name_coh = '%s_coherence_%s' % (subtask, p)\n",
        "p_dataset_name_subset = '%s_rand200_%s' % (subtask, p)\n",
        "p_ids = [ex['example_id'] for ex in art_spans]\n",
        "p_labels = [ex['label'] for ex in art_spans]\n",
        "\n",
        "# Get span preds and save metrics\n",
        "results, preds, labels, probs = evaluate(model, p_dataloader, device, metrics, seg_mode=True if 'roberta' not in mode else False, return_softmax=True)\n",
        "save_results(results, probe_model, p_dataset_name)\n",
        "save_preds(p_ids, labels, preds, probe_model, p_dataset_name)\n",
        "\n",
        "# Convert substory preds into breakpoint preds for each example\n",
        "ids_base = [ex['example_id'] for ex in art]\n",
        "\n",
        "id_to_pred = {k: v for k,v in zip(p_ids, preds)}\n",
        "id_to_prob = {k: v for k,v in zip(p_ids, probs)}\n",
        "id_to_label = {k: v for k,v in zip(p_ids, p_labels)}\n",
        "\n",
        "for metric_to_optimize in ['strict_coherence', 'lenient_coherence']:\n",
        "  # Get results dict ready\n",
        "  # all_results['acc'] = 0.0\n",
        "  # all_results['acc_con'] = 0.0\n",
        "  # all_results['acc_con_vbp'] = 0.0\n",
        "  # all_results['acc_con_vbp_vev'] = 0.0\n",
        "  # all_results['span_accuracy'] = 0.0\n",
        "  all_results['lenient_coherence'] = 0.0\n",
        "  all_results['strict_coherence'] = 0.0\n",
        "  span_accuracy = 0.0\n",
        "  span_accuracy_strict = 0.0\n",
        "  no_spans = 0\n",
        "  for threshold in [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]:\n",
        "\n",
        "    preds_plausible = []\n",
        "    labels_plausible = []\n",
        "    preds_consistent = []\n",
        "    preds_breakpoint = []\n",
        "    labels_breakpoint = []\n",
        "    preds_evidence = []\n",
        "    labels_evidence = []\n",
        "    span_accuracies = []\n",
        "    span_accuracies_strict = []\n",
        "    preds_coherent = []\n",
        "\n",
        "    for i, exid in enumerate(ids_base):\n",
        "      ex = art[i]\n",
        "      ex['length'] = 3\n",
        "\n",
        "      label_plausible = preds_base[p][exid]['label']\n",
        "      pred_plausible = preds_base[p][exid]['pred']\n",
        "      labels_plausible.append(label_plausible)\n",
        "      preds_plausible.append(pred_plausible)\n",
        "\n",
        "      # Get ground truth breakpoint and evidence\n",
        "      label_breakpoint = ex['conflict_pair'][1] if ex['conflict_pair'] is not None else 0\n",
        "      labels_breakpoint.append(label_breakpoint)\n",
        "      if label_breakpoint > 0:\n",
        "        label_ev = ex['conflict_pair'][0]\n",
        "      else:\n",
        "        label_ev = -1\n",
        "      labels_evidence.append(label_ev)\n",
        "\n",
        "      # Check consistency - for every span we confidently choose story X, we should also confidently choose story X for any span containing it\n",
        "      pred_consistent = True\n",
        "      for sp1 in range(ex['length']-1):\n",
        "        if not pred_consistent:\n",
        "          break\n",
        "\n",
        "        for sp2 in range(sp1+1, ex['length']):\n",
        "          if not pred_consistent:\n",
        "            break\n",
        "\n",
        "          span_pred = int(id_to_pred[exid + '-sp%s:%s' % (str(sp1), str(sp2))])\n",
        "          span_prob = id_to_prob[exid + '-sp%s:%s' % (str(sp1), str(sp2))]\n",
        "          span_label = max(id_to_label[exid + '-sp%s:%s' % (str(sp1), str(sp2))] - 1, -1)\n",
        "\n",
        "          span_pred3 = span_pred\n",
        "          if not is_polarized(span_prob, threshold): # If not polarized, let's say -1\n",
        "            span_pred3 = -1\n",
        "\n",
        "          pred_coherent = True\n",
        "          if span_pred3 == span_label:\n",
        "            span_accuracy += 1.0\n",
        "            if label_plausible == pred_plausible:\n",
        "              span_accuracy_strict += 1.0\n",
        "          else:\n",
        "            pred_coherent = False\n",
        "          no_spans += 1\n",
        "\n",
        "          if is_polarized(span_prob, threshold):\n",
        "            for sp3 in range(sp1+1):\n",
        "              if not pred_consistent:\n",
        "                break\n",
        "\n",
        "              for sp4 in range(sp2, ex['length']):\n",
        "                if not pred_consistent:\n",
        "                  break\n",
        "\n",
        "                sspan_pred = id_to_pred[exid + '-sp%s:%s' % (str(sp3), str(sp4))]\n",
        "                sspan_prob = id_to_prob[exid + '-sp%s:%s' % (str(sp3), str(sp4))]\n",
        "\n",
        "                if not is_polarized(sspan_prob, threshold) or sspan_pred != span_pred:\n",
        "                  pred_consistent = False\n",
        "                  break\n",
        "\n",
        "      preds_consistent.append(1 if pred_consistent else 0)\n",
        "      span_accuracies.append(span_accuracy / no_spans)\n",
        "      span_accuracies_strict.append(span_accuracy_strict / no_spans)\n",
        "      preds_coherent.append(1 if pred_coherent else 0)\n",
        "\n",
        "      # Check pred. breakpoint (verifiability) - will be first sentence where the model prediction becomes polarized, i.e., confidence > threshold\n",
        "      pred_breakpoint  = 0 # For now, 0 means -1, i.e., stories are entirely plausible - this shouldn't happen but it will (inconsistent?)\n",
        "      for ss in range(1, ex['length']):\n",
        "        if is_polarized(id_to_prob[exid + '-sp%s:%s' % (str(0), str(ss))], threshold):\n",
        "          pred_breakpoint = ss\n",
        "          break\n",
        "      preds_breakpoint.append(pred_breakpoint)\n",
        "\n",
        "      # Check pred. evidence (verifiability)\n",
        "      if pred_breakpoint > 0:\n",
        "        pred_evidence = -1 # Does this make sense for default value?\n",
        "        for ss in range(0, pred_breakpoint):\n",
        "          if is_polarized(id_to_prob[exid + '-sp%s:%s' % (str(ss), str(pred_breakpoint))], threshold):\n",
        "            pred_evidence = ss\n",
        "      else:\n",
        "        pred_evidence = -1 # This should never happen - it would be inconsistent if it did?\n",
        "      preds_evidence.append(pred_evidence)\n",
        "\n",
        "    # Calculate tiered accuracy for model\n",
        "    acc = 0\n",
        "    acc_con = 0\n",
        "    acc_con_vbp = 0\n",
        "    acc_con_vbp_vev = 0\n",
        "    no_ex = len(ids_base)\n",
        "    for p_plaus, l_plaus, con, p_bp, l_bp, p_ev, l_ev in zip(preds_plausible, labels_plausible, preds_consistent, preds_breakpoint, labels_breakpoint, preds_evidence, labels_evidence):\n",
        "      # Accuracy\n",
        "      if p_plaus == l_plaus:\n",
        "        acc += 1\n",
        "\n",
        "        # Consistency\n",
        "        if con == 1:\n",
        "          acc_con += 1\n",
        "\n",
        "          # Verifiability (breakpoint)\n",
        "          if p_bp == l_bp:\n",
        "            acc_con_vbp += 1\n",
        "\n",
        "            # Verifiability (evidence)\n",
        "            if p_ev == l_ev:\n",
        "              acc_con_vbp_vev += 1\n",
        "\n",
        "    acc /= no_ex\n",
        "    acc_con /= no_ex\n",
        "    acc_con_vbp /= no_ex\n",
        "    acc_con_vbp_vev /= no_ex\n",
        "    span_acc = np.mean(span_accuracies)\n",
        "    span_acc_strict = np.mean(span_accuracies_strict)\n",
        "    coherence = np.mean(preds_coherent)\n",
        "    # if coherence > all_results['coherence']: # !!!! this line is important\n",
        "    # if span_acc > all_results['span_accuracy']: # !!!! this line is important\n",
        "    if span_acc_strict > all_results[metric_to_optimize]: # !!!! this line is important\n",
        "      # print('new best: %s' % str(acc_con_vbp_vev))\n",
        "      best_thres = threshold\n",
        "\n",
        "      # all_results['acc'] = acc\n",
        "      # all_results['acc_con'] = acc_con\n",
        "      # all_results['acc_con_vbp'] = acc_con_vbp\n",
        "      # all_results['acc_con_vbp_vev'] = acc_con_vbp_vev\n",
        "      # all_results['span_accuracy'] = span_acc\n",
        "      all_results['lenient_coherence'] = span_acc_strict\n",
        "      all_results['strict_coherence'] = coherence\n",
        "\n",
        "      best_preds_plausible = preds_plausible\n",
        "      best_preds_consistent = preds_consistent\n",
        "      best_preds_breakpoint = preds_breakpoint\n",
        "      best_preds_evidence = preds_evidence\n",
        "      best_preds_coherent = preds_coherent\n",
        "\n",
        "  all_results['best_threshold'] = best_thres\n",
        "  print('\\nPARTITION: %s \\t METRIC: %s' % (p, metric_to_optimize))\n",
        "  print('chosen threshold: %s' % str(best_thres))\n",
        "  print_dict(all_results)\n",
        "\n",
        "  # Save results\n",
        "  p_dataset_name_agg = '%s_%s_%s' % (subtask, metric_to_optimize, p)\n",
        "  save_results(all_results, probe_model, p_dataset_name_agg)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "aWFmGRhznl2T",
        "Rbvpm9irn3qL",
        "RfXiCTA9KPjG",
        "ON1UAnbc8OOE",
        "W7MADzgfvtv3",
        "Msxt3xAhvtv6",
        "rn5Ywwvxvtv6",
        "Ytbj9Uxxvtv7",
        "h9YL5qnRvtv7",
        "Jss8T2xzvtv8",
        "8XhSrDlpI0aH",
        "CADDFieTvtv9",
        "GO1JOxnIvtv9",
        "cAtipHPtvtv-",
        "maZGCMvMvtv-",
        "XnWDvQG7vtv-",
        "KxRnuX_fvtv_",
        "apGoBEp_vtv_",
        "ukLFJ-Mfvtv_",
        "XERMrM56vtv_",
        "Egyx9BejvtwC",
        "auYYxFc6vtwC",
        "fYRfQG6LvtwC"
      ],
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}